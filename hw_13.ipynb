{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled46.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1C07DMqnKQ0fksvcHixIGXwauAdcEV20O",
      "authorship_tag": "ABX9TyOVgH1twBEQ+3PrKiV3W4tz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssv273/Neural_Univesity/blob/main/hw_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMUXibzMLn9c",
        "outputId": "d828e4d0-6b70-4572-939a-53a15cbc770a"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install -q gputil\n",
        "!pip install -q psutil\n",
        "!pip install -q humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "process = psutil.Process(os.getpid())\n",
        "print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "print(\"GPU Model: \", gpu.name)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 117.9 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n",
            "GPU Model:  Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19w2z6_HL2XJ"
      },
      "source": [
        "# Возьмем за основу третий урок (распознавание марок машин)  \n",
        "В этом задании поставим задачу подобрать такую архитектуру сети, чтобы по качеству она была не хуже, как минимум, а по скорости быстрее той, которая была в третьем уроке."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsoUCx11L_pz"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential #Сеть прямого распространения\n",
        "#Базовые слои для счёрточных сетей\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator # работа с изображениями\n",
        "from tensorflow.keras.optimizers import Adam, Adadelta # оптимизаторы\n",
        "from tensorflow.keras import utils #Используем дял to_categoricall\n",
        "from tensorflow.keras.preprocessing import image #Для отрисовки изображений\n",
        "from google.colab import files #Для загрузки своей картинки\n",
        "import numpy as np #Библиотека работы с массивами\n",
        "import matplotlib.pyplot as plt #Для отрисовки графиков\n",
        "from PIL import Image #Для отрисовки изображений\n",
        "import random #Для генерации случайных чисел \n",
        "import math # Для округления\n",
        "import os #Для работы с файлами \n",
        "# подключем диск\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import time\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbirv_-6MEzd"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/Neural_Univesity/Автомобили.zip\" -d /content/cars #Указываем путь к базе в Google Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbrgN0MdMM55",
        "outputId": "4f7374bb-2f68-476a-9e1f-4094a4502c1e"
      },
      "source": [
        "os.listdir('cars')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Автомобили']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XgVoz-3Lp5E"
      },
      "source": [
        "train_path = '/content/cars/Автомобили' #Папка с папками картинок, рассортированных по категориям\n",
        "batch_size = 8 #Размер выборки\n",
        "img_width = 96 #Ширина изображения\n",
        "img_height = 54 #Высота изображения"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdWqVk3PNCXV"
      },
      "source": [
        "#Генератор изображений\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255, #Значения цвета меняем на дробные показания\n",
        "    rotation_range=10, #Поворачиваем изображения при генерации выборки\n",
        "    width_shift_range=0.1, #Двигаем изображения по ширине при генерации выборки\n",
        "    height_shift_range=0.1, #Двигаем изображения по высоте при генерации выборки\n",
        "    zoom_range=0.1, #Зумируем изображения при генерации выборки\n",
        "    horizontal_flip=True, #Включаем отзеркаливание изображений\n",
        "    fill_mode='nearest', #Заполнение пикселей вне границ ввода\n",
        "    validation_split=0.2 #Указываем разделение изображений на обучающую и тестовую выборку\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DryJ1DhtNZb4",
        "outputId": "3ce5d71d-d1f1-4a35-9043-09a47a54bdb9"
      },
      "source": [
        "# обучающая выборка\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_path, #Путь ко всей выборке выборке\n",
        "    target_size=(img_width, img_height), #Размер изображений\n",
        "    batch_size=batch_size, #Размер batch_size\n",
        "    class_mode='categorical', #Категориальный тип выборки. Разбиение выборки по маркам авто \n",
        "    shuffle=True, #Перемешивание выборки\n",
        "    subset='training' # устанавливаем как набор для обучения\n",
        ")\n",
        "\n",
        "# проверочная выборка\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    train_path, #Путь ко всей выборке выборке\n",
        "    target_size=(img_width, img_height), #Размер изображений\n",
        "    batch_size=batch_size, #Размер batch_size\n",
        "    class_mode='categorical', #Категориальный тип выборки. Разбиение выборки по маркам авто \n",
        "    shuffle=True, #Перемешивание выборки\n",
        "    subset='validation' # устанавливаем как валидационный набор\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2743 images belonging to 2 classes.\n",
            "Found 684 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSbOEM3kOE7Z"
      },
      "source": [
        "**Входной слой**\n",
        "\n",
        "*   0 - делаем ли нормализацию\n",
        "*   1 - размер первого свёрточного слоя\n",
        "*   2 - ядро первого свёрточного слоя \n",
        "*   3 - функция активации первого слоя\n",
        "*   4 - делаем ли MaxPooling0\n",
        "*   5 - размер MaxPooling0\n",
        "\n",
        "**Первый скрытый слой**\n",
        "\n",
        "*   6 - Делаем ли второй сверточный слой\n",
        "*   7 - размер второго сверточного слоя\n",
        "*   8 - ядро второго сверточного слоя\n",
        "*   9 - делаем ли MaxPooling1\n",
        "*   10 - размер MaxPooling1\n",
        "*   11 - функция активации\n",
        "\n",
        "**Второй скрытый слой**\n",
        "\n",
        "*   12 - Делаем ли третий сверточный слой\n",
        "*   13 - размер третьего сверточного слоя\n",
        "*   14 - ядро третьего сверточного слоя\n",
        "*   15 - делаем ли MaxPooling2\n",
        "*   16 - размер MaxPooling2\n",
        "*   17 - функция активации \n",
        "\n",
        "**Третий скрытый слой**\n",
        "\n",
        "*   18 - Делаем ли третий сверточный слой\n",
        "*   19 - размер третьего сверточного слоя\n",
        "*   20 - ядро третьего сверточного слоя\n",
        "*   21 - делаем ли MaxPooling2\n",
        "*   22 - размер MaxPooling2\n",
        "*   23 - функция активации \n",
        "\n",
        "**Четвертый скрытый слой**\n",
        "\n",
        "*   24 - Делаем ли четвертый сверточный слой\n",
        "*   25 - размер четвертого сверточного слоя\n",
        "*   26 - ядро четвертого сверточного слоя\n",
        "*   27 - делаем ли MaxPooling2\n",
        "*   28 - размер MaxPooling2\n",
        "*   29 - функция активации \n",
        "\n",
        "**Пятый скрытый слой**\n",
        "\n",
        "*   30 - Делаем ли пятый сверточный слой\n",
        "*   31 - размер пятого сверточного слоя\n",
        "*   32 - ядро пятого сверточного слоя\n",
        "*   33 - делаем ли MaxPooling2\n",
        "*   34 - размер MaxPooling2\n",
        "*   35 - функция активации \n",
        "\n",
        "**Шестой скрытый слой**\n",
        "*   36 - делаем ли шестой полносвязный слой\n",
        "----\n",
        "*   37 - функция активации шестого слоя\n",
        "*   38 - функция активации предпоследнего слоя\n",
        "*   39 - функция активации выходного слоя\n",
        "----\n",
        "**Шестой скрытый слой**\n",
        "\n",
        "*   40 - делаем ли нормализацию \n",
        "*   41 - размер полносвязного слоя\n",
        "\n",
        "**Седьмой (предпоследний) скрытый слой**\n",
        "\n",
        "*   42 - делаем ли нормализацию \n",
        "*   43 - размер полносвязного слоя"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FZDeEm1fYjd"
      },
      "source": [
        "### Задумка была такая, но колаб не даёт считать долго, поэтому от части параметров пришлось отказаться."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLwdSMiBNcuu"
      },
      "source": [
        "#Создаём сеть (net - список параметров)\n",
        "def createConvNet(net):\n",
        "\n",
        "  model = Sequential()             # Создаем моель Sequential\n",
        "  \n",
        "  makeFirstNormalization = net[0]  # Делаем ли нормализацию в начале\n",
        "  firstConvSize = 2 ** net[1]      # Размер входного вёрточного слоя\n",
        "  firstConvKernel = net[2]         # Ядро входного свёрточного слоя\n",
        "  activation0 = net[3]             # Функция активации входного слоя\n",
        "  makeMaxPooling0 = net[4]         # Делаем ли maxpooling для нулевого слоя\n",
        "  maxPoolingSize0 = net[5]         # Размер MaxPooling\n",
        "\n",
        "  makeSecondConv = net[6]          # Делаем ли первый свёрточный слой\n",
        "  secondConvSize = 2 ** net[7]     # Размер первого свёрточного слоя\n",
        "  secondConvKernel = net[8]        # Ядро второго свёрточного слоя\n",
        "  makeMaxPooling1 = net[9]         # Делаем ли MaxPooling\n",
        "  maxPoolingSize1 = net[10]        # Размер MaxPooling\n",
        "  activation1 = net[11]            # Функция активации\n",
        "\n",
        "  makeThirdConv = net[12]          # Делаем ли второй свёрточный слой\n",
        "  thirdConvSize = 2 ** net[13]     # Размер второго свёрточного слоя\n",
        "  thirdConvKernel = net[14]        # Ядро второго свёрточного слоя\n",
        "  makeMaxPooling2 = net[15]        # Делаем ли MaxPooling\n",
        "  maxPoolingSize2 = net[16]        # Размер MaxPooling\n",
        "  activation2 = net[17]            # Функция активации\n",
        "  \n",
        "#   makeFourthConv = net[18]          # Делаем ли третий свёрточный слой\n",
        "#   fourthConvSize = 2 ** net[19]     # Размер тертьего свёрточного слоя\n",
        "#   fourthConvKernel = net[20]        # Ядро третьего свёрточного слоя\n",
        "#   makeMaxPooling3 = net[21]        # Делаем ли MaxPooling\n",
        "#   maxPoolingSize3 = net[22]        # Размер MaxPooling\n",
        "#   activation3 = net[23]            # Функция активации\n",
        "\n",
        "#   makeFifthConv = net[24]          # Делаем ли четвертый свёрточный слой\n",
        "#   fifthConvSize = 2 ** net[25]     # Размер четвертого свёрточного слоя\n",
        "#   fifthConvKernel = net[26]        # Ядро четвертго свёрточного слоя\n",
        "#   makeMaxPooling4 = net[27]        # Делаем ли MaxPooling\n",
        "#   maxPoolingSize4 = net[28]        # Размер MaxPooling\n",
        "#   activation4 = net[29]            # Функция активации\n",
        "\n",
        "#   makeSixthhConv = net[30]          # Делаем ли пятый свёрточный слой\n",
        "#   sixthConvSize = 2 ** net[31]     # Размер пятого свёрточного слоя\n",
        "#   sixthConvKernel = net[32]        # Ядро пятого свёрточного слоя\n",
        "#   makeMaxPooling5 = net[33]        # Делаем ли MaxPooling\n",
        "#   maxPoolingSize5 = net[34]        # Размер MaxPooling\n",
        "#   activation5 = net[35]            # Функция активации\n",
        "\n",
        "  makeSeventhDense = net[18]          # Делаем ли шестой полносвязгый слой\n",
        "\n",
        "  activation6 = net[19]            # Функция активации для шестого слоя\n",
        "  activation7 = net[20]            # Функция активации для предпоследнего\n",
        "  activation8 = net[21]            # Функция активации для последнего слоя\n",
        "\n",
        "  makeSeventhNormalization = net[22] # Делаем ли нормализацию перед шестым слоем\n",
        "  seventhdenseSize = 2 ** net[23]          # Размер шестого полносвязного слоя\n",
        "\n",
        "  makeFinalNormalization = net[24] # Делаем ли финальную нормализацию\n",
        "  denseSize = 2 ** net[25]          # Размер полносвязного слоя\n",
        "\n",
        "  activation_list = ['linear','relu','tanh','softmax','sigmoid'] \n",
        "\n",
        "  if (makeFirstNormalization):      # Если делаем нормализацию в начале\n",
        "    # Добавляем слой BatchNormalization\n",
        "    model.add(BatchNormalization(input_shape=(img_width, img_height, 3)))\n",
        "    # Добавляем Conv1D-слой с firstConvSize нейронами и ядром (firstConvKernel)\n",
        "    model.add(Conv2D(firstConvSize, firstConvKernel, activation=activation_list[activation0], padding='same')) \n",
        "  else:\n",
        "    # Добавляем Conv1D-слой с firstConvSize нейронами и ядром (firstConvKernel)\n",
        "    model.add(Conv2D(firstConvSize, firstConvKernel, input_shape=(img_width, img_height, 3), activation=activation_list[activation0], padding='same')) \n",
        "  \n",
        "  if makeMaxPooling0:               # Если делаем maxpooling\n",
        "    model.add(MaxPooling2D(maxPoolingSize0))\n",
        "\n",
        "  if (makeSecondConv):              # Если делаем первый свёрточный слой\n",
        "    # Добавляем Conv2D-слой с secondConvSize нейронами и ядром (secondConvKernel)\n",
        "    model.add(Conv2D(secondConvSize, secondConvKernel, activation=activation_list[activation1], padding='same')) \n",
        "    \n",
        "    if (makeMaxPooling1):           # Если делаем MaxPooling\n",
        "      # Добавляем слой MaxPooling1D с размером (maxPoolingSize)\n",
        "      model.add(MaxPooling2D(pool_size=maxPoolingSize1)) \n",
        "\n",
        "  if (makeThirdConv):              # Если делаем второй свёрточный слой\n",
        "    # Добавляем Conv2D-слой с secondConvSize нейронами и ядром (secondConvKernel)\n",
        "    model.add(Conv2D(thirdConvSize, thirdConvKernel, activation=activation_list[activation2], padding='same')) \n",
        "    \n",
        "    if (makeMaxPooling2):           # Если делаем MaxPooling\n",
        "      # Добавляем слой MaxPooling1D с размером (maxPoolingSize)\n",
        "      model.add(MaxPooling2D(pool_size=maxPoolingSize2)) \n",
        "\n",
        "#   if (makeFourthConv):              # Если делаем третий свёрточный слой\n",
        "#     # Добавляем Conv2D-слой с secondConvSize нейронами и ядром (secondConvKernel)\n",
        "#     model.add(Conv2D(fourthConvSize, fourthConvKernel, activation=activation_list[activation3], padding='same')) \n",
        "    \n",
        "#     if (makeMaxPooling3):           # Если делаем MaxPooling\n",
        "#       # Добавляем слой MaxPooling1D с размером (maxPoolingSize)\n",
        "#       model.add(MaxPooling2D(pool_size=maxPoolingSize3)) \n",
        "\n",
        "#   if (makeFifthConv):              # Если делаем четвертый свёрточный слой\n",
        "#     # Добавляем Conv2D-слой с secondConvSize нейронами и ядром (secondConvKernel)\n",
        "#     model.add(Conv2D(fifthConvSize, fifthConvKernel, activation=activation_list[activation4], padding='same')) \n",
        "    \n",
        "#     if (makeMaxPooling4):           # Если делаем MaxPooling\n",
        "#       # Добавляем слой MaxPooling1D с размером (maxPoolingSize)\n",
        "#       model.add(MaxPooling2D(pool_size=maxPoolingSize4)) \n",
        "\n",
        "#   if (makeSixthhConv):              # Если делаем пятый свёрточный слой\n",
        "#     # Добавляем Conv2D-слой с secondConvSize нейронами и ядром (secondConvKernel)\n",
        "#     model.add(Conv2D(sixthConvSize, sixthConvKernel, activation=activation_list[activation5], padding='same')) \n",
        "    \n",
        "#     if (makeMaxPooling5):           # Если делаем MaxPooling\n",
        "#       # Добавляем слой MaxPooling1D с размером (maxPoolingSize)\n",
        "#       model.add(MaxPooling2D(pool_size=maxPoolingSize5)) \n",
        "\n",
        "  if (makeSeventhNormalization):\n",
        "    #   добавляем нормализацию\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Flatten())              # Добавляем слой Flatten\n",
        "  \n",
        "  if (makeSeventhDense):\n",
        "      model.add(Dense(seventhdenseSize, activation=activation_list[activation6]))\n",
        "  \n",
        "  if (makeFinalNormalization):\n",
        "    #   добавляем нормализацию\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(denseSize, activation=activation_list[activation7])) # Добавляем слой Dense с denseSize нейронами\n",
        "  model.add(Dense(len(train_generator.class_indices), activation=activation_list[activation8]))\n",
        "\n",
        "  return model                      # Возвращаем модель\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTkX_lKiZoEh"
      },
      "source": [
        "def evaluateNet(net, ep, verb):\n",
        "    '''\n",
        "    Функция вычисления результата работы сети\n",
        "    '''\n",
        "    val = 0\n",
        "    start = time.time()\n",
        "    model = createConvNet(net) # Создаем модель createConvNet\n",
        "\n",
        "    # Компилируем модель\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "                    loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(\n",
        "            train_generator,\n",
        "            steps_per_epoch = train_generator.samples // batch_size,\n",
        "            validation_data = validation_generator, \n",
        "            validation_steps = validation_generator.samples // batch_size,\n",
        "            epochs=5,\n",
        "            verbose=verb,\n",
        "        )\n",
        "        \n",
        "    val = history.history[\"val_accuracy\"][-1] - float(time.time() - start) / 1000 # Возвращаем точность на проверочной выборке с последней эпохи минус время, для наиболее точной и быстрой нейронки\n",
        "    \n",
        "    return val, model                      # Возвращаем точность"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-plW2zAaQmf"
      },
      "source": [
        "\n",
        "def createRandomNet():\n",
        "    '''\n",
        "    Функция создания списка случайных параметров\n",
        "    '''\n",
        "    net = []\n",
        "    net.append(random.randint(0,1)) #Делаем или нет нормализацию\n",
        "    net.append(random.randint(3,8)) #Первый свёрточный слой от 8 до 64 нейронов\n",
        "    net.append(random.randint(3,7)) #Ядро первого свёрточного слоя от 3 до 7\n",
        "    net.append(random.randint(0,4)) # Функция активации входного слоя\n",
        "    net.append(random.randint(0,1)) #Делаем ли MaxPooling\n",
        "    net.append(random.randint(2,3)) #Размер MaxPooling\n",
        "\n",
        "    net.append(random.randint(0,1)) # Сколько делаем еще сверточных слоев\n",
        "    net.append(random.randint(3,8)) # Второй свёрточный слой от 8 до 64 нейронов\n",
        "    net.append(random.randint(3,7)) # Ядро первого свёрточного слоя от 3 до 7\n",
        "    net.append(random.randint(0,1)) # Делаем ли MaxPooling\n",
        "    net.append(random.randint(2,3)) # Размер MaxPooling\n",
        "    net.append(random.randint(0,4)) # Функция активации первого слоя\n",
        "\n",
        "    net.append(random.randint(0,1)) # Сколько делаем еще сверточных слоев\n",
        "    net.append(random.randint(3,8)) # Второй свёрточный слой от 8 до 64 нейронов\n",
        "    net.append(random.randint(3,7)) # Ядро второго свёрточного слоя от 3 до 7\n",
        "    net.append(random.randint(0,1)) # Делаем ли MaxPooling\n",
        "    net.append(random.randint(2,3)) # Размер MaxPooling\n",
        "    net.append(random.randint(0,4)) # Функция активации второго слоя\n",
        "\n",
        "    # net.append(random.randint(0,1)) # Сколько делаем еще сверточных слоев\n",
        "    # net.append(random.randint(3,10)) # Второй свёрточный слой от 8 до 64 нейронов\n",
        "    # net.append(random.randint(3,7)) # Ядро третьего свёрточного слоя от 3 до 7\n",
        "    # net.append(random.randint(0,1)) # Делаем ли MaxPooling\n",
        "    # net.append(random.randint(2,3)) # Размер MaxPooling\n",
        "    # net.append(random.randint(0,4)) # Функция активации третьего слоя\n",
        "\n",
        "    # net.append(random.randint(0,1)) # Сколько делаем еще сверточных слоев\n",
        "    # net.append(random.randint(3,10)) # Второй свёрточный слой от 8 до 64 нейронов\n",
        "    # net.append(random.randint(3,7)) # Ядро четвертого свёрточного слоя от 3 до 7\n",
        "    # net.append(random.randint(0,1)) # Делаем ли MaxPooling\n",
        "    # net.append(random.randint(2,3)) # Размер MaxPooling\n",
        "    # net.append(random.randint(0,4)) # Функция активации четвертого слоя\n",
        "\n",
        "    # net.append(random.randint(0,1)) # Сколько делаем еще сверточных слоев\n",
        "    # net.append(random.randint(3,10)) # Пятый свёрточный слой от 8 до 64 нейронов\n",
        "    # net.append(random.randint(3,7)) # Ядро пятого свёрточного слоя от 3 до 7\n",
        "    # net.append(random.randint(0,1)) # Делаем ли MaxPooling\n",
        "    # net.append(random.randint(2,3)) # Размер MaxPooling\n",
        "    # net.append(random.randint(0,4)) # Функция активации пятого слоя\n",
        "\n",
        "    net.append(random.randint(0,1)) # Делаем или нет шестой полносвязный слой\n",
        "    \n",
        "    net.append(random.randint(0,4)) # Функция активации шестого dense слоя\n",
        "    net.append(random.randint(0,4)) # Функция активации предпоследнего dense слоя\n",
        "    net.append(random.randint(0,4)) # Функция активации последнего слоя\n",
        "\n",
        "    net.append(random.randint(0,1)) # Делаем ли нормализацию  перед шестым слоем\n",
        "    net.append(random.randint(3,10)) # Размер шестого полносвязного слоя от 8 до 64\n",
        "\n",
        "    net.append(random.randint(0,1)) # Делаем ли финальную нормализацию слой\n",
        "    net.append(random.randint(3,10)) # Размер полносвязного слоя от 8 до 64\n",
        "    \n",
        "    return net"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPE7iuxQs20Y",
        "outputId": "c2d81e8c-995c-4d5b-e835-aec75c689da7"
      },
      "source": [
        "len(createRandomNet())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycUVy49LODzz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c0c980-5a9b-472f-dd1e-a0daa3d3b415"
      },
      "source": [
        "n = 10              # Общее число ботов\n",
        "nsurv = 5          # Количество выживших (столько лучших переходит в новую популяцию)\n",
        "nnew = n - nsurv    # Количество новых (столько новых ботов создается)\n",
        "l = 26              # Размер бота\n",
        "epohs = 10          # количество эпох\n",
        "\n",
        "mut = 0.2          # коэфициент мутаций\n",
        "\n",
        "popul = []          # Массив популяции\n",
        "val = []            # Одномерный массив значений этих ботов\n",
        "\n",
        "#Создаём случайных ботов\n",
        "for i in range(n):\n",
        "  popul.append(createRandomNet())\n",
        "  \n",
        "for it in range(epohs):                 # Пробегаем по всем эпохам\n",
        "  val = []                              # Обнуляем значения бота\n",
        "  curr_time = time.time()\n",
        "  for i in range(n):                    # Пробегаем в цикле по всем ботам \n",
        "    bot = popul[i]                      # Берем очередного бота\n",
        "    f, model_sum = evaluateNet(bot, 5, 1) # Вычисляем точность текущего бота\n",
        "    val.append(f)                       # Добавляем полученное значение в список val\n",
        "  \n",
        "  sval = sorted(val, reverse=1)         # Сортируем val\n",
        "  # Выводим 5 лучших ботов\n",
        "  print(it, time.time() - curr_time, \" \", sval[0:5],popul[:5]) \n",
        "  \n",
        "  newpopul = []                         # Создаем пустой список под новую популяцию\n",
        "  for i in range(nsurv):                # Пробегаем по всем выжившим ботам\n",
        "    index = val.index(sval[i])          # Получаем индекс очередного бота из списка лучших в списке val\n",
        "    newpopul.append(popul[index])       # Добавляем в новую популяцию бота из popul с индексом index\n",
        "    \n",
        "  for i in range(nnew):                 # Проходимся в цикле nnew-раз  \n",
        "    indexp1 = random.randint(0,nsurv-1) # Случайный индекс первого родителя в диапазоне от 0 до nsurv - 1\n",
        "    indexp2 = random.randint(0,nsurv-1) # Случайный индекс первого родителя в диапазоне от 0 до nsurv - 1\n",
        "    botp1 = newpopul[indexp1]           # Получаем первого бота-родителя по indexp1\n",
        "    botp2 = newpopul[indexp2]           # Получаем второго бота-родителя по indexp2    \n",
        "    newbot = []                         # Создаем пустой список под значения нового бота    \n",
        "    net4Mut = createRandomNet()         # Создаем случайную сеть для мутаций\n",
        "    for j in range(l):                  # Пробегаем по всей длине размерности (784)      \n",
        "      x = 0      \n",
        "      pindex = random.random()          # Получаем случайное число в диапазоне от 0 до 1\n",
        "\n",
        "      # Если pindex меньше 0.5, то берем значения от первого бота, иначе от второго\n",
        "      if pindex < 0.5:\n",
        "        x = botp1[j]\n",
        "      else:\n",
        "        x = botp2[j]\n",
        "      \n",
        "      # С вероятностью mut устанавливаем значение бота из net4Mut\n",
        "      if (random.random() < mut):\n",
        "        x = net4Mut[j]\n",
        "        \n",
        "      newbot.append(x)                  # Добавляем очередное значение в нового бота      \n",
        "    newpopul.append(newbot)             # Добавляем бота в новую популяцию      \n",
        "  popul = newpopul                      # Записываем в popul новую посчитанную популяцию"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "342/342 [==============================] - 44s 35ms/step - loss: 2.6899 - accuracy: 0.7689 - val_loss: 1.8581 - val_accuracy: 0.7868\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 2.2315 - accuracy: 0.7839 - val_loss: 1.8197 - val_accuracy: 0.7941\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 2.1773 - accuracy: 0.7876 - val_loss: 1.9606 - val_accuracy: 0.7926\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 2.2177 - accuracy: 0.7828 - val_loss: 1.9302 - val_accuracy: 0.7794\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 2.1490 - accuracy: 0.7850 - val_loss: 1.8516 - val_accuracy: 0.7956\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 32s 92ms/step - loss: 0.8431 - accuracy: 0.7678 - val_loss: 0.6392 - val_accuracy: 0.7324\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 32s 92ms/step - loss: 0.5644 - accuracy: 0.7751 - val_loss: 0.5823 - val_accuracy: 0.7794\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 32s 95ms/step - loss: 0.5417 - accuracy: 0.7828 - val_loss: 0.5490 - val_accuracy: 0.7985\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 32s 94ms/step - loss: 0.5276 - accuracy: 0.7916 - val_loss: 0.5674 - val_accuracy: 0.7353\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 32s 95ms/step - loss: 0.5324 - accuracy: 0.7912 - val_loss: 0.5733 - val_accuracy: 0.7882\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 38ms/step - loss: 0.8174 - accuracy: 0.2190 - val_loss: 0.9232 - val_accuracy: 0.1971\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.7537 - accuracy: 0.3400 - val_loss: 0.7115 - val_accuracy: 0.3882\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.7262 - accuracy: 0.4731 - val_loss: 0.6415 - val_accuracy: 0.3632\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.6265 - accuracy: 0.3920 - val_loss: 0.5505 - val_accuracy: 0.4309\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.6001 - accuracy: 0.4135 - val_loss: 0.6637 - val_accuracy: 0.4735\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 3.2118 - accuracy: 0.8007 - val_loss: 3.1999 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 3.2236 - accuracy: 0.8000 - val_loss: 3.1999 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 3.2059 - accuracy: 0.8011 - val_loss: 3.1999 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 3.2177 - accuracy: 0.8004 - val_loss: 3.2236 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 3.2177 - accuracy: 0.8004 - val_loss: 3.1999 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 35ms/step - loss: 0.5344 - accuracy: 0.7985 - val_loss: 0.5793 - val_accuracy: 0.8029\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 0.5124 - accuracy: 0.8007 - val_loss: 0.5154 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5156 - accuracy: 0.8007 - val_loss: 0.5173 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 0.5059 - accuracy: 0.8007 - val_loss: 0.5022 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 0.5079 - accuracy: 0.8000 - val_loss: 0.5168 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 44ms/step - loss: 3.2059 - accuracy: 0.1989 - val_loss: 3.1762 - val_accuracy: 0.1971\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 45ms/step - loss: 3.2236 - accuracy: 0.2000 - val_loss: 3.1999 - val_accuracy: 0.1985\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 3.2177 - accuracy: 0.1996 - val_loss: 3.1999 - val_accuracy: 0.1985\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 3.2236 - accuracy: 0.2000 - val_loss: 3.2236 - val_accuracy: 0.2000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 3.2236 - accuracy: 0.2000 - val_loss: 3.1999 - val_accuracy: 0.1985\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 44ms/step - loss: 2.8558 - accuracy: 0.5320 - val_loss: 1.4789 - val_accuracy: 0.5206\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 1.7355 - accuracy: 0.4435 - val_loss: 2.6112 - val_accuracy: 0.3132\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 1.8362 - accuracy: 0.4574 - val_loss: 0.6894 - val_accuracy: 0.6765\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 1.8305 - accuracy: 0.6223 - val_loss: 0.7564 - val_accuracy: 0.7338\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 1.2672 - accuracy: 0.5952 - val_loss: 1.7423 - val_accuracy: 0.6088\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 42ms/step - loss: 0.5877 - accuracy: 0.7612 - val_loss: 0.5141 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 42ms/step - loss: 0.5015 - accuracy: 0.8004 - val_loss: 0.5013 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 42ms/step - loss: 0.5012 - accuracy: 0.7989 - val_loss: 0.5744 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.8382 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5009 - accuracy: 0.7996 - val_loss: 0.8745 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 44ms/step - loss: 0.5392 - accuracy: 0.7934 - val_loss: 0.5004 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 0.4994 - accuracy: 0.8004 - val_loss: 0.4984 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5008 - accuracy: 0.8004 - val_loss: 0.4984 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5006 - accuracy: 0.8004 - val_loss: 0.4986 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5010 - accuracy: 0.8004 - val_loss: 0.4942 - val_accuracy: 0.8044\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 42ms/step - loss: 2.2725 - accuracy: 0.4954 - val_loss: 1.2141 - val_accuracy: 0.3824\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 1.0933 - accuracy: 0.5108 - val_loss: 1.2583 - val_accuracy: 0.4397\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 1.0246 - accuracy: 0.5064 - val_loss: 1.2133 - val_accuracy: 0.3926\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 1.0370 - accuracy: 0.5038 - val_loss: 0.8455 - val_accuracy: 0.3676\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.9791 - accuracy: 0.4819 - val_loss: 0.7895 - val_accuracy: 0.4618\n",
            "0 1093.682121515274   [0.7152610883712769, 0.7092108612060547, 0.7071939380168915, 0.700987578868866, 0.6334423012733459] [[1, 4, 7, 4, 0, 3, 0, 4, 5, 0, 2, 3, 0, 4, 6, 1, 2, 3, 0, 2, 3, 0, 1, 3, 0, 3], [0, 8, 6, 2, 1, 2, 0, 6, 3, 1, 3, 4, 0, 3, 4, 0, 2, 3, 0, 0, 2, 3, 1, 9, 0, 9], [0, 5, 6, 2, 1, 3, 1, 3, 5, 0, 3, 0, 1, 8, 4, 1, 3, 0, 0, 3, 4, 0, 1, 3, 0, 6], [0, 5, 6, 3, 1, 2, 0, 5, 4, 1, 3, 0, 0, 5, 3, 1, 3, 0, 1, 0, 0, 1, 0, 4, 0, 10], [0, 5, 5, 0, 1, 3, 1, 3, 5, 1, 2, 3, 1, 7, 5, 0, 2, 1, 1, 3, 1, 4, 1, 3, 1, 6]]\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 36ms/step - loss: 0.5653 - accuracy: 0.7740 - val_loss: 0.5897 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5218 - accuracy: 0.8000 - val_loss: 0.5146 - val_accuracy: 0.8029\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5160 - accuracy: 0.8000 - val_loss: 0.5268 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5080 - accuracy: 0.8000 - val_loss: 0.5040 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5096 - accuracy: 0.8007 - val_loss: 0.5041 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 43ms/step - loss: 0.5913 - accuracy: 0.7682 - val_loss: 0.6066 - val_accuracy: 0.8029\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 42ms/step - loss: 0.5036 - accuracy: 0.7978 - val_loss: 0.5022 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5011 - accuracy: 0.7996 - val_loss: 0.4951 - val_accuracy: 0.8029\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.4994 - accuracy: 0.8007 - val_loss: 0.7383 - val_accuracy: 0.8029\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5020 - accuracy: 0.8000 - val_loss: 0.6093 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 3.2499 - accuracy: 0.7974 - val_loss: 3.2236 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 3.2236 - accuracy: 0.8000 - val_loss: 3.2236 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 3.2118 - accuracy: 0.8007 - val_loss: 3.2236 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 3.2118 - accuracy: 0.8007 - val_loss: 3.2236 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 3.2236 - accuracy: 0.8000 - val_loss: 3.2236 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 43ms/step - loss: 0.5326 - accuracy: 0.7861 - val_loss: 0.4970 - val_accuracy: 0.8029\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5004 - accuracy: 0.8000 - val_loss: 0.4991 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 0.4991 - accuracy: 0.8015 - val_loss: 0.5004 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5012 - accuracy: 0.8004 - val_loss: 0.4984 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.4991 - accuracy: 0.8007 - val_loss: 0.5040 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 36ms/step - loss: 4.9549 - accuracy: 0.5605 - val_loss: 3.2391 - val_accuracy: 0.6647\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 1.9995 - accuracy: 0.5455 - val_loss: 1.7490 - val_accuracy: 0.4235\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 1.4735 - accuracy: 0.4285 - val_loss: 1.5540 - val_accuracy: 0.4147\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 1.2014 - accuracy: 0.3901 - val_loss: 1.1122 - val_accuracy: 0.3676\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 1.0052 - accuracy: 0.3561 - val_loss: 0.9606 - val_accuracy: 0.3471\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 18s 49ms/step - loss: 0.5399 - accuracy: 0.2000 - val_loss: 0.5241 - val_accuracy: 0.2000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 16s 47ms/step - loss: 0.5003 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.2000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 16s 47ms/step - loss: 0.5002 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.2000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 16s 47ms/step - loss: 0.4998 - accuracy: 0.1993 - val_loss: 0.4983 - val_accuracy: 0.1985\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 16s 47ms/step - loss: 0.4996 - accuracy: 0.1993 - val_loss: 0.5009 - val_accuracy: 0.2000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 36ms/step - loss: 0.7045 - accuracy: 0.5971 - val_loss: 0.5091 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5860 - accuracy: 0.7473 - val_loss: 0.5532 - val_accuracy: 0.7912\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5023 - accuracy: 0.7993 - val_loss: 0.5205 - val_accuracy: 0.8029\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5173 - accuracy: 0.8000 - val_loss: 0.5235 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.4986 - accuracy: 0.7993 - val_loss: 0.5646 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 41ms/step - loss: 0.6707 - accuracy: 0.6654 - val_loss: 0.6166 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5790 - accuracy: 0.7901 - val_loss: 0.5539 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5323 - accuracy: 0.8000 - val_loss: 0.5162 - val_accuracy: 0.8029\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5119 - accuracy: 0.7982 - val_loss: 0.5260 - val_accuracy: 0.8029\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5096 - accuracy: 0.7989 - val_loss: 0.5179 - val_accuracy: 0.8029\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 36s 103ms/step - loss: 0.5284 - accuracy: 0.7971 - val_loss: 0.5311 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 34s 101ms/step - loss: 0.5040 - accuracy: 0.8000 - val_loss: 0.5016 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 35s 101ms/step - loss: 0.5004 - accuracy: 0.8007 - val_loss: 0.4943 - val_accuracy: 0.8044\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 35s 101ms/step - loss: 0.5014 - accuracy: 0.8000 - val_loss: 0.4984 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 35s 102ms/step - loss: 0.5003 - accuracy: 0.8004 - val_loss: 0.5004 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 37s 105ms/step - loss: nan - accuracy: 0.7250 - val_loss: nan - val_accuracy: 0.7882\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 36s 105ms/step - loss: nan - accuracy: 0.7978 - val_loss: nan - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 36s 104ms/step - loss: nan - accuracy: 0.5967 - val_loss: nan - val_accuracy: 0.6382\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 36s 104ms/step - loss: nan - accuracy: 0.7159 - val_loss: nan - val_accuracy: 0.8029\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 36s 104ms/step - loss: nan - accuracy: 0.7181 - val_loss: nan - val_accuracy: 0.7603\n",
            "1 1116.3488743305206   [0.7212227261066437, 0.7142445378303528, 0.7133020405769348, 0.7031682732105256, 0.6983944454193115] [[0, 5, 5, 0, 1, 3, 1, 3, 5, 1, 2, 3, 1, 7, 5, 0, 2, 1, 1, 3, 1, 4, 1, 3, 1, 6], [0, 3, 3, 0, 0, 3, 1, 5, 7, 0, 2, 2, 0, 4, 6, 0, 2, 4, 1, 2, 2, 3, 0, 7, 1, 9], [0, 5, 6, 3, 1, 2, 0, 5, 4, 1, 3, 0, 0, 5, 3, 1, 3, 0, 1, 0, 0, 1, 0, 4, 0, 10], [1, 6, 7, 0, 1, 3, 1, 6, 3, 0, 2, 4, 1, 6, 5, 0, 3, 3, 1, 3, 0, 4, 1, 10, 1, 4], [1, 4, 7, 4, 0, 3, 0, 4, 5, 0, 2, 3, 0, 4, 6, 1, 2, 3, 0, 2, 3, 0, 1, 3, 0, 3]]\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 35ms/step - loss: 3.2118 - accuracy: 0.8007 - val_loss: 3.2236 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 3.2295 - accuracy: 0.7996 - val_loss: 3.1999 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 3.2177 - accuracy: 0.8004 - val_loss: 3.1999 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 3.2295 - accuracy: 0.7996 - val_loss: 3.2236 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 3.2001 - accuracy: 0.8015 - val_loss: 3.1999 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 44ms/step - loss: 0.5277 - accuracy: 0.7861 - val_loss: 0.5022 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5019 - accuracy: 0.8004 - val_loss: 0.4983 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 0.5024 - accuracy: 0.8000 - val_loss: 0.5077 - val_accuracy: 0.8029\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5007 - accuracy: 0.8007 - val_loss: 0.4964 - val_accuracy: 0.8029\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5012 - accuracy: 0.8004 - val_loss: 0.5674 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 41ms/step - loss: 0.6733 - accuracy: 0.6636 - val_loss: 0.5759 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5651 - accuracy: 0.7923 - val_loss: 0.5400 - val_accuracy: 0.7912\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5248 - accuracy: 0.7985 - val_loss: 0.5121 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5077 - accuracy: 0.8000 - val_loss: 0.5061 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5028 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 42ms/step - loss: 0.5867 - accuracy: 0.7704 - val_loss: 0.5640 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5012 - accuracy: 0.7993 - val_loss: 0.5169 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.4998 - accuracy: 0.8000 - val_loss: 0.9438 - val_accuracy: 0.8029\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5010 - accuracy: 0.7996 - val_loss: 0.6699 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5010 - accuracy: 0.8000 - val_loss: 0.5062 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.7318 - accuracy: 0.2227 - val_loss: 0.5357 - val_accuracy: 0.1956\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5210 - accuracy: 0.2062 - val_loss: 0.5145 - val_accuracy: 0.2000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.4998 - accuracy: 0.2000 - val_loss: 0.5250 - val_accuracy: 0.1971\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5827 - accuracy: 0.2066 - val_loss: 0.5007 - val_accuracy: 0.1985\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5031 - accuracy: 0.1993 - val_loss: 0.5079 - val_accuracy: 0.1985\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 26s 74ms/step - loss: 0.5243 - accuracy: 0.7974 - val_loss: 0.4963 - val_accuracy: 0.8029\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 25s 74ms/step - loss: 0.4971 - accuracy: 0.7996 - val_loss: 0.5002 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 25s 73ms/step - loss: 0.4951 - accuracy: 0.8004 - val_loss: 0.5048 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 25s 73ms/step - loss: 0.4948 - accuracy: 0.8004 - val_loss: 0.4990 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 25s 73ms/step - loss: 0.4952 - accuracy: 0.8004 - val_loss: 0.5083 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 39ms/step - loss: 0.5409 - accuracy: 0.7887 - val_loss: 0.5121 - val_accuracy: 0.8044\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5109 - accuracy: 0.7938 - val_loss: 0.5117 - val_accuracy: 0.8029\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5086 - accuracy: 0.7993 - val_loss: 0.5134 - val_accuracy: 0.7941\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5150 - accuracy: 0.7963 - val_loss: 0.5195 - val_accuracy: 0.7779\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5121 - accuracy: 0.7901 - val_loss: 0.5211 - val_accuracy: 0.7956\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 38ms/step - loss: 0.6393 - accuracy: 0.7433 - val_loss: 0.6633 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5914 - accuracy: 0.8000 - val_loss: 0.5826 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5656 - accuracy: 0.8000 - val_loss: 0.5501 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5450 - accuracy: 0.8004 - val_loss: 0.5425 - val_accuracy: 0.8029\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5303 - accuracy: 0.8007 - val_loss: 0.5292 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 35ms/step - loss: 1.5290 - accuracy: 0.6578 - val_loss: 1.2552 - val_accuracy: 0.7397\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 1.2615 - accuracy: 0.7192 - val_loss: 1.0760 - val_accuracy: 0.6485\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.8833 - accuracy: 0.6238 - val_loss: 1.0240 - val_accuracy: 0.5897\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.9318 - accuracy: 0.6300 - val_loss: 0.9831 - val_accuracy: 0.6338\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.9578 - accuracy: 0.6388 - val_loss: 0.8955 - val_accuracy: 0.6353\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 36ms/step - loss: 0.5271 - accuracy: 0.2015 - val_loss: 0.5050 - val_accuracy: 0.1985\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5042 - accuracy: 0.2000 - val_loss: 0.5017 - val_accuracy: 0.2000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5024 - accuracy: 0.2000 - val_loss: 0.4981 - val_accuracy: 0.1985\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.4987 - accuracy: 0.1989 - val_loss: 0.4992 - val_accuracy: 0.1985\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.4995 - accuracy: 0.1996 - val_loss: 0.4992 - val_accuracy: 0.1985\n",
            "2 936.8288576602936   [0.7205072402954101, 0.7159621143341064, 0.7146980612277984, 0.7137861728668213, 0.713322551727295] [[0, 5, 6, 3, 1, 2, 0, 5, 4, 1, 3, 0, 0, 5, 3, 1, 3, 0, 1, 0, 0, 1, 0, 4, 0, 10], [1, 6, 7, 0, 1, 3, 1, 6, 3, 0, 2, 4, 1, 6, 5, 0, 3, 3, 1, 3, 0, 4, 1, 10, 1, 4], [1, 5, 7, 0, 1, 2, 0, 6, 3, 1, 3, 4, 1, 6, 5, 0, 3, 3, 1, 3, 0, 4, 1, 4, 1, 4], [0, 3, 3, 0, 0, 3, 1, 5, 7, 0, 2, 2, 0, 4, 6, 0, 2, 4, 1, 2, 2, 3, 0, 7, 1, 9], [0, 3, 5, 0, 1, 3, 1, 8, 4, 1, 2, 3, 0, 7, 6, 1, 3, 1, 1, 0, 0, 0, 1, 4, 0, 6]]\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 44ms/step - loss: 0.5357 - accuracy: 0.7978 - val_loss: 0.5004 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5009 - accuracy: 0.8000 - val_loss: 0.4963 - val_accuracy: 0.8029\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5015 - accuracy: 0.7996 - val_loss: 0.4984 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5007 - accuracy: 0.8004 - val_loss: 0.4974 - val_accuracy: 0.8029\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 0.5012 - accuracy: 0.7996 - val_loss: 0.5008 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5776 - accuracy: 0.7744 - val_loss: 0.5716 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5030 - accuracy: 0.7993 - val_loss: 0.5340 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.4999 - accuracy: 0.8000 - val_loss: 0.5223 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5033 - accuracy: 0.7996 - val_loss: 0.9803 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5006 - accuracy: 0.8004 - val_loss: 0.5390 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5193 - accuracy: 0.7982 - val_loss: 0.4989 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5119 - accuracy: 0.7996 - val_loss: 0.4999 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5045 - accuracy: 0.8007 - val_loss: 0.5015 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5040 - accuracy: 0.8004 - val_loss: 0.4987 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5022 - accuracy: 0.8000 - val_loss: 0.5004 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.5250 - accuracy: 0.7894 - val_loss: 0.5061 - val_accuracy: 0.7971\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5026 - accuracy: 0.7996 - val_loss: 0.5157 - val_accuracy: 0.7838\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.4984 - accuracy: 0.7978 - val_loss: 0.5159 - val_accuracy: 0.7971\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5064 - accuracy: 0.7982 - val_loss: 0.5104 - val_accuracy: 0.7985\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5031 - accuracy: 0.8000 - val_loss: 0.5034 - val_accuracy: 0.7985\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 38ms/step - loss: 0.6155 - accuracy: 0.7828 - val_loss: 0.6429 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5790 - accuracy: 0.8004 - val_loss: 0.5802 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5571 - accuracy: 0.8007 - val_loss: 0.5610 - val_accuracy: 0.8029\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5450 - accuracy: 0.8000 - val_loss: 0.5488 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5295 - accuracy: 0.8004 - val_loss: 0.5415 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5206 - accuracy: 0.7985 - val_loss: 0.5039 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5038 - accuracy: 0.8000 - val_loss: 0.4984 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5009 - accuracy: 0.8004 - val_loss: 0.5002 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5015 - accuracy: 0.8000 - val_loss: 0.4989 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 37ms/step - loss: 0.4999 - accuracy: 0.8011 - val_loss: 0.4991 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 36ms/step - loss: 12.8945 - accuracy: 0.2000 - val_loss: 12.8945 - val_accuracy: 0.2000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 12.8886 - accuracy: 0.2004 - val_loss: 12.8945 - val_accuracy: 0.2000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 12.9004 - accuracy: 0.1996 - val_loss: 12.9419 - val_accuracy: 0.1971\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 12.8945 - accuracy: 0.2000 - val_loss: 12.9182 - val_accuracy: 0.1985\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 12.9004 - accuracy: 0.1996 - val_loss: 12.9419 - val_accuracy: 0.1971\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 36ms/step - loss: 0.5338 - accuracy: 0.8000 - val_loss: 0.5025 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5107 - accuracy: 0.8000 - val_loss: 0.5007 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5113 - accuracy: 0.8007 - val_loss: 0.4983 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5157 - accuracy: 0.8007 - val_loss: 0.5031 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5172 - accuracy: 0.7996 - val_loss: 0.5025 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 36ms/step - loss: 0.5726 - accuracy: 0.7620 - val_loss: 0.5106 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5012 - accuracy: 0.7993 - val_loss: 0.5216 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5009 - accuracy: 0.8004 - val_loss: 0.5075 - val_accuracy: 0.8029\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.4970 - accuracy: 0.8000 - val_loss: 0.5119 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.4988 - accuracy: 0.8011 - val_loss: 0.5054 - val_accuracy: 0.8029\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 31s 86ms/step - loss: 0.5118 - accuracy: 0.7993 - val_loss: 0.4987 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 29s 86ms/step - loss: 0.5010 - accuracy: 0.8004 - val_loss: 0.4985 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 29s 84ms/step - loss: 0.5002 - accuracy: 0.8007 - val_loss: 0.5021 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 29s 85ms/step - loss: 0.5007 - accuracy: 0.8004 - val_loss: 0.5005 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 29s 84ms/step - loss: 0.5012 - accuracy: 0.8000 - val_loss: 0.4985 - val_accuracy: 0.8015\n",
            "3 975.1018018722534   [0.7323130657672882, 0.7163698878288269, 0.7144454097747803, 0.7114348826408387, 0.7107250044345855] [[1, 6, 7, 0, 1, 3, 1, 6, 3, 0, 2, 4, 1, 6, 5, 0, 3, 3, 1, 3, 0, 4, 1, 10, 1, 4], [0, 3, 3, 0, 0, 3, 1, 5, 7, 0, 2, 2, 0, 4, 6, 0, 2, 4, 1, 2, 2, 3, 0, 7, 1, 9], [0, 5, 6, 3, 1, 2, 0, 5, 4, 1, 3, 0, 0, 5, 3, 1, 3, 0, 1, 0, 0, 1, 0, 4, 0, 10], [0, 3, 3, 2, 0, 2, 1, 6, 7, 1, 3, 2, 0, 4, 6, 0, 2, 4, 1, 2, 0, 4, 1, 4, 0, 4], [1, 5, 7, 0, 1, 3, 0, 6, 3, 1, 3, 4, 1, 6, 5, 0, 3, 3, 1, 3, 3, 4, 1, 4, 1, 4]]\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 36ms/step - loss: 0.5708 - accuracy: 0.7561 - val_loss: 0.5056 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5027 - accuracy: 0.7982 - val_loss: 0.5381 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5004 - accuracy: 0.8000 - val_loss: 0.5235 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5016 - accuracy: 0.8007 - val_loss: 0.5092 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.4987 - accuracy: 0.8004 - val_loss: 0.5092 - val_accuracy: 0.7941\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.5353 - accuracy: 0.7868 - val_loss: 0.5260 - val_accuracy: 0.7838\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.5011 - accuracy: 0.8000 - val_loss: 0.5070 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.5113 - accuracy: 0.7985 - val_loss: 0.5068 - val_accuracy: 0.7971\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.5166 - accuracy: 0.7985 - val_loss: 0.5244 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5107 - accuracy: 0.8000 - val_loss: 0.5081 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 36ms/step - loss: 0.5384 - accuracy: 0.7993 - val_loss: 0.5014 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5108 - accuracy: 0.8004 - val_loss: 0.4983 - val_accuracy: 0.8029\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5125 - accuracy: 0.8004 - val_loss: 0.5052 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5112 - accuracy: 0.8007 - val_loss: 0.5032 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5126 - accuracy: 0.7996 - val_loss: 0.5095 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 40ms/step - loss: 0.6128 - accuracy: 0.7956 - val_loss: 0.6283 - val_accuracy: 0.8029\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5711 - accuracy: 0.8000 - val_loss: 0.5647 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5477 - accuracy: 0.8004 - val_loss: 0.5340 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5318 - accuracy: 0.7996 - val_loss: 0.5299 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5214 - accuracy: 0.8004 - val_loss: 0.5210 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.6034 - accuracy: 0.7583 - val_loss: 0.5731 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5013 - accuracy: 0.8007 - val_loss: 0.5310 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5018 - accuracy: 0.7996 - val_loss: 0.5404 - val_accuracy: 0.8029\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5021 - accuracy: 0.7996 - val_loss: 0.5059 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.4996 - accuracy: 0.8011 - val_loss: 0.5087 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 39ms/step - loss: 1.4927 - accuracy: 0.4146 - val_loss: 0.8268 - val_accuracy: 0.5353\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.9598 - accuracy: 0.4431 - val_loss: 0.8386 - val_accuracy: 0.4368\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.7698 - accuracy: 0.4417 - val_loss: 0.7075 - val_accuracy: 0.5324\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.6706 - accuracy: 0.4410 - val_loss: 0.6447 - val_accuracy: 0.5338\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.6543 - accuracy: 0.4607 - val_loss: 0.5394 - val_accuracy: 0.8044\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5736 - accuracy: 0.7448 - val_loss: 0.5034 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5029 - accuracy: 0.7996 - val_loss: 0.5012 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.4974 - accuracy: 0.8007 - val_loss: 0.5059 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5011 - accuracy: 0.7993 - val_loss: 0.5086 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5020 - accuracy: 0.7996 - val_loss: 0.5074 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 43ms/step - loss: 0.6411 - accuracy: 0.6161 - val_loss: 0.5652 - val_accuracy: 0.7000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5915 - accuracy: 0.6837 - val_loss: 0.5898 - val_accuracy: 0.6868\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5585 - accuracy: 0.7594 - val_loss: 0.5357 - val_accuracy: 0.7882\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 42ms/step - loss: 0.5340 - accuracy: 0.7835 - val_loss: 0.5373 - val_accuracy: 0.7765\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5296 - accuracy: 0.7850 - val_loss: 0.5129 - val_accuracy: 0.7971\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5655 - accuracy: 0.7795 - val_loss: 1.2480 - val_accuracy: 0.1985\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.4996 - accuracy: 0.8004 - val_loss: 0.5807 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5000 - accuracy: 0.8004 - val_loss: 1.7416 - val_accuracy: 0.2000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5018 - accuracy: 0.7996 - val_loss: 0.5862 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5004 - accuracy: 0.8004 - val_loss: 1.0747 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 38ms/step - loss: 0.6748 - accuracy: 0.7971 - val_loss: 0.6572 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.6393 - accuracy: 0.8011 - val_loss: 0.6212 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.6056 - accuracy: 0.8000 - val_loss: 0.5886 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5775 - accuracy: 0.8000 - val_loss: 0.5628 - val_accuracy: 0.8029\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5551 - accuracy: 0.8000 - val_loss: 0.5450 - val_accuracy: 0.8000\n",
            "4 877.0933094024658   [0.7303586387634278, 0.719437224149704, 0.7193113298416137, 0.7123792674541474, 0.7107574512958527] [[0, 3, 6, 0, 1, 3, 1, 5, 7, 1, 3, 2, 0, 4, 6, 1, 2, 1, 1, 2, 2, 3, 0, 4, 1, 10], [0, 3, 3, 2, 0, 2, 1, 6, 7, 1, 3, 2, 0, 4, 6, 0, 2, 4, 1, 2, 0, 4, 1, 4, 0, 4], [0, 3, 3, 0, 0, 2, 0, 4, 7, 0, 2, 2, 0, 3, 6, 0, 2, 4, 1, 2, 2, 3, 0, 7, 0, 9], [1, 5, 7, 0, 1, 3, 0, 6, 3, 1, 3, 4, 1, 6, 5, 0, 3, 3, 1, 3, 3, 4, 1, 4, 1, 4], [0, 3, 3, 0, 0, 3, 1, 5, 7, 0, 2, 2, 0, 4, 6, 0, 2, 4, 1, 2, 2, 3, 0, 7, 1, 9]]\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5402 - accuracy: 0.7920 - val_loss: 0.5191 - val_accuracy: 0.7985\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5133 - accuracy: 0.7963 - val_loss: 0.6665 - val_accuracy: 0.5088\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.5054 - accuracy: 0.7993 - val_loss: 0.4959 - val_accuracy: 0.8029\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.5010 - accuracy: 0.7989 - val_loss: 0.5164 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5010 - accuracy: 0.8011 - val_loss: 0.5168 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.6741 - accuracy: 0.8004 - val_loss: 0.6560 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 37ms/step - loss: 0.6381 - accuracy: 0.8007 - val_loss: 0.6185 - val_accuracy: 0.8044\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.6039 - accuracy: 0.8004 - val_loss: 0.5871 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5752 - accuracy: 0.8000 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5537 - accuracy: 0.8000 - val_loss: 0.5402 - val_accuracy: 0.8029\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 39ms/step - loss: 0.6077 - accuracy: 0.7989 - val_loss: 0.6294 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5760 - accuracy: 0.8004 - val_loss: 0.5812 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5550 - accuracy: 0.8000 - val_loss: 0.5630 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5388 - accuracy: 0.8000 - val_loss: 0.5334 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5262 - accuracy: 0.8000 - val_loss: 0.5237 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 36ms/step - loss: 0.5714 - accuracy: 0.7473 - val_loss: 0.5137 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5039 - accuracy: 0.8000 - val_loss: 0.5245 - val_accuracy: 0.7985\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5018 - accuracy: 0.8000 - val_loss: 0.4986 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.4985 - accuracy: 0.8007 - val_loss: 0.5069 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.4967 - accuracy: 0.7996 - val_loss: 0.5280 - val_accuracy: 0.7985\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 44ms/step - loss: 0.6669 - accuracy: 0.6413 - val_loss: 0.6662 - val_accuracy: 0.6456\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5870 - accuracy: 0.7236 - val_loss: 0.5645 - val_accuracy: 0.7500\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5653 - accuracy: 0.7492 - val_loss: 0.5893 - val_accuracy: 0.7147\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5546 - accuracy: 0.7572 - val_loss: 0.5378 - val_accuracy: 0.7588\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5387 - accuracy: 0.7854 - val_loss: 0.5413 - val_accuracy: 0.7794\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 41ms/step - loss: 0.6151 - accuracy: 0.7974 - val_loss: 0.4984 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.5013 - accuracy: 0.8000 - val_loss: 0.4957 - val_accuracy: 0.8029\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.4987 - accuracy: 0.8007 - val_loss: 0.4972 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.4952 - accuracy: 0.8004 - val_loss: 0.5003 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.4958 - accuracy: 0.8000 - val_loss: 0.5039 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 38ms/step - loss: 0.6457 - accuracy: 0.7104 - val_loss: 0.6711 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5851 - accuracy: 0.8004 - val_loss: 0.5766 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5568 - accuracy: 0.8004 - val_loss: 0.5446 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5400 - accuracy: 0.8007 - val_loss: 0.5285 - val_accuracy: 0.8029\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5289 - accuracy: 0.8004 - val_loss: 0.5207 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5099 - accuracy: 0.8000 - val_loss: 0.6917 - val_accuracy: 0.5132\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5057 - accuracy: 0.7996 - val_loss: 0.5132 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.4991 - accuracy: 0.8000 - val_loss: 0.5956 - val_accuracy: 0.6912\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.4982 - accuracy: 0.8004 - val_loss: 0.4985 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.4961 - accuracy: 0.7996 - val_loss: 0.4976 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5391 - accuracy: 0.7726 - val_loss: 0.5712 - val_accuracy: 0.7941\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5206 - accuracy: 0.7927 - val_loss: 0.5159 - val_accuracy: 0.7941\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5039 - accuracy: 0.7945 - val_loss: 0.5263 - val_accuracy: 0.7838\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.4956 - accuracy: 0.7960 - val_loss: 0.5071 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.4974 - accuracy: 0.7982 - val_loss: 0.5043 - val_accuracy: 0.8044\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 40ms/step - loss: 0.6544 - accuracy: 0.7656 - val_loss: 0.6501 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.6171 - accuracy: 0.7989 - val_loss: 0.6140 - val_accuracy: 0.7868\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5888 - accuracy: 0.8007 - val_loss: 0.5828 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5689 - accuracy: 0.8004 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5480 - accuracy: 0.7996 - val_loss: 0.5365 - val_accuracy: 0.8015\n",
            "5 894.7788419723511   [0.7286852674484253, 0.7256380317211151, 0.7157748820781707, 0.7125905466079712, 0.7114078869819641] [[0, 3, 3, 2, 0, 2, 1, 6, 7, 1, 3, 2, 0, 4, 6, 0, 2, 4, 1, 2, 0, 4, 1, 4, 0, 4], [1, 3, 3, 0, 1, 2, 1, 6, 3, 1, 3, 4, 0, 4, 3, 1, 3, 3, 1, 2, 3, 4, 1, 5, 1, 10], [1, 5, 7, 0, 1, 3, 0, 6, 3, 1, 3, 4, 1, 6, 5, 0, 3, 3, 1, 3, 3, 4, 1, 4, 1, 4], [0, 3, 3, 0, 1, 3, 0, 5, 3, 1, 2, 2, 0, 4, 6, 1, 2, 1, 1, 2, 2, 3, 1, 5, 1, 10], [0, 3, 3, 0, 0, 3, 1, 5, 7, 0, 2, 2, 0, 8, 7, 0, 2, 4, 1, 2, 2, 3, 1, 7, 1, 3]]\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 39ms/step - loss: 0.5956 - accuracy: 0.8004 - val_loss: 0.6025 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5606 - accuracy: 0.8000 - val_loss: 0.5568 - val_accuracy: 0.8029\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5405 - accuracy: 0.8011 - val_loss: 0.5335 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5278 - accuracy: 0.8004 - val_loss: 0.5227 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5180 - accuracy: 0.7996 - val_loss: 0.5189 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 36ms/step - loss: 0.5356 - accuracy: 0.7781 - val_loss: 0.5802 - val_accuracy: 0.7868\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5026 - accuracy: 0.7971 - val_loss: 0.5121 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5078 - accuracy: 0.7934 - val_loss: 0.5238 - val_accuracy: 0.7941\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.4958 - accuracy: 0.7985 - val_loss: 0.5104 - val_accuracy: 0.7941\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.4936 - accuracy: 0.7978 - val_loss: 0.5162 - val_accuracy: 0.7956\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 42ms/step - loss: 0.5197 - accuracy: 0.2011 - val_loss: 0.4999 - val_accuracy: 0.2000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.4976 - accuracy: 0.2000 - val_loss: 0.4992 - val_accuracy: 0.2000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5067 - accuracy: 0.1996 - val_loss: 0.4989 - val_accuracy: 0.2000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.4952 - accuracy: 0.1993 - val_loss: 0.4995 - val_accuracy: 0.1985\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.4936 - accuracy: 0.1993 - val_loss: 0.5087 - val_accuracy: 0.2000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5088 - accuracy: 0.8000 - val_loss: 0.6781 - val_accuracy: 0.6882\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5067 - accuracy: 0.8000 - val_loss: 0.4986 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5028 - accuracy: 0.8004 - val_loss: 0.5139 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.4998 - accuracy: 0.8007 - val_loss: 0.5055 - val_accuracy: 0.7985\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.4966 - accuracy: 0.7996 - val_loss: 0.5105 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 41ms/step - loss: 0.5446 - accuracy: 0.7872 - val_loss: 0.5263 - val_accuracy: 0.7824\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5044 - accuracy: 0.7978 - val_loss: 0.5196 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.4939 - accuracy: 0.8007 - val_loss: 0.5215 - val_accuracy: 0.8029\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.4971 - accuracy: 0.8004 - val_loss: 0.5021 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.4977 - accuracy: 0.8011 - val_loss: 0.4981 - val_accuracy: 0.8029\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5031 - accuracy: 0.8007 - val_loss: 0.5899 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5010 - accuracy: 0.8004 - val_loss: 0.5132 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.4984 - accuracy: 0.8000 - val_loss: 0.5135 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5004 - accuracy: 0.8004 - val_loss: 0.5130 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.4954 - accuracy: 0.7989 - val_loss: 0.5021 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 37ms/step - loss: 0.6159 - accuracy: 0.7667 - val_loss: 0.5788 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5636 - accuracy: 0.8007 - val_loss: 0.5497 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5417 - accuracy: 0.8007 - val_loss: 0.5324 - val_accuracy: 0.8029\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5287 - accuracy: 0.8004 - val_loss: 0.5179 - val_accuracy: 0.8044\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5198 - accuracy: 0.8004 - val_loss: 0.5133 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 22s 63ms/step - loss: nan - accuracy: 0.7989 - val_loss: nan - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 21s 62ms/step - loss: nan - accuracy: 0.8000 - val_loss: nan - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 21s 62ms/step - loss: nan - accuracy: 0.8004 - val_loss: nan - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 21s 62ms/step - loss: nan - accuracy: 0.8000 - val_loss: nan - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 21s 62ms/step - loss: nan - accuracy: 0.8000 - val_loss: nan - val_accuracy: 0.8044\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.6742 - accuracy: 0.7996 - val_loss: 0.6552 - val_accuracy: 0.8029\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.6381 - accuracy: 0.8004 - val_loss: 0.6177 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.6057 - accuracy: 0.8004 - val_loss: 0.5882 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5800 - accuracy: 0.7996 - val_loss: 0.5641 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5588 - accuracy: 0.8007 - val_loss: 0.5470 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 42ms/step - loss: 0.5201 - accuracy: 0.7956 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5000 - accuracy: 0.7996 - val_loss: 0.5425 - val_accuracy: 0.7882\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.4997 - accuracy: 0.7993 - val_loss: 0.5081 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.4959 - accuracy: 0.7985 - val_loss: 0.5086 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.4954 - accuracy: 0.8004 - val_loss: 0.5111 - val_accuracy: 0.7926\n",
            "6 944.532372713089   [0.7194433963298797, 0.7143400814533234, 0.7140417063236236, 0.7130736720561981, 0.7128646049499512] [[1, 3, 7, 0, 1, 2, 0, 6, 3, 1, 3, 4, 1, 4, 3, 1, 3, 3, 1, 3, 3, 4, 1, 5, 1, 4], [0, 3, 3, 3, 1, 3, 0, 6, 4, 1, 2, 2, 0, 4, 6, 0, 2, 1, 1, 2, 0, 4, 1, 4, 0, 4], [1, 7, 3, 0, 1, 3, 1, 6, 4, 1, 3, 4, 0, 4, 3, 1, 3, 2, 1, 2, 3, 2, 1, 5, 1, 10], [0, 3, 5, 4, 1, 2, 1, 6, 3, 1, 3, 4, 0, 4, 3, 1, 2, 4, 1, 2, 0, 4, 1, 5, 0, 10], [0, 3, 3, 2, 0, 2, 1, 6, 7, 1, 3, 2, 0, 4, 6, 0, 2, 4, 1, 2, 0, 4, 1, 4, 0, 4]]\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 39ms/step - loss: 0.6707 - accuracy: 0.5890 - val_loss: 0.6320 - val_accuracy: 0.7838\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.6130 - accuracy: 0.7931 - val_loss: 0.5823 - val_accuracy: 0.7985\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5784 - accuracy: 0.7989 - val_loss: 0.5580 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5535 - accuracy: 0.7996 - val_loss: 0.5396 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5378 - accuracy: 0.8000 - val_loss: 0.5271 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5071 - accuracy: 0.8007 - val_loss: 0.5703 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5039 - accuracy: 0.8000 - val_loss: 0.5036 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5005 - accuracy: 0.8004 - val_loss: 0.5025 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.4975 - accuracy: 0.7996 - val_loss: 0.4935 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.4925 - accuracy: 0.7993 - val_loss: 0.4970 - val_accuracy: 0.8044\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5045 - accuracy: 0.8004 - val_loss: 0.6403 - val_accuracy: 0.8029\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5047 - accuracy: 0.8004 - val_loss: 0.5008 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5017 - accuracy: 0.8000 - val_loss: 0.4969 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.4994 - accuracy: 0.8004 - val_loss: 0.5048 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.4964 - accuracy: 0.7989 - val_loss: 0.5013 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 41ms/step - loss: 0.5554 - accuracy: 0.7843 - val_loss: 0.5299 - val_accuracy: 0.7824\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5326 - accuracy: 0.7839 - val_loss: 0.5453 - val_accuracy: 0.7882\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5233 - accuracy: 0.7941 - val_loss: 0.5390 - val_accuracy: 0.7956\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5123 - accuracy: 0.7952 - val_loss: 0.5419 - val_accuracy: 0.7853\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5158 - accuracy: 0.7974 - val_loss: 0.5265 - val_accuracy: 0.7926\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 38ms/step - loss: 0.6694 - accuracy: 0.5207 - val_loss: 0.6855 - val_accuracy: 0.6779\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.6030 - accuracy: 0.7879 - val_loss: 0.5932 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5660 - accuracy: 0.8004 - val_loss: 0.5500 - val_accuracy: 0.7985\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5394 - accuracy: 0.8015 - val_loss: 0.5278 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5274 - accuracy: 0.8004 - val_loss: 0.5216 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 39ms/step - loss: 1.0384 - accuracy: 0.2227 - val_loss: 0.5064 - val_accuracy: 0.1985\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.6607 - accuracy: 0.2161 - val_loss: 0.7064 - val_accuracy: 0.2088\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5712 - accuracy: 0.2091 - val_loss: 0.5930 - val_accuracy: 0.2015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5741 - accuracy: 0.2048 - val_loss: 0.5416 - val_accuracy: 0.2015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5118 - accuracy: 0.2007 - val_loss: 0.6202 - val_accuracy: 0.2029\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 38ms/step - loss: 0.6335 - accuracy: 0.8004 - val_loss: 0.6183 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5956 - accuracy: 0.8000 - val_loss: 0.5810 - val_accuracy: 0.8029\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5714 - accuracy: 0.8004 - val_loss: 0.5608 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5529 - accuracy: 0.8007 - val_loss: 0.5457 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5391 - accuracy: 0.8004 - val_loss: 0.5336 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 38ms/step - loss: 0.6743 - accuracy: 0.8004 - val_loss: 0.6561 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.6387 - accuracy: 0.8000 - val_loss: 0.6197 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.6041 - accuracy: 0.8007 - val_loss: 0.5869 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5756 - accuracy: 0.8000 - val_loss: 0.5609 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5534 - accuracy: 0.8007 - val_loss: 0.5398 - val_accuracy: 0.8029\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 40ms/step - loss: 0.6670 - accuracy: 0.8007 - val_loss: 0.6426 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.6228 - accuracy: 0.7996 - val_loss: 0.6032 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5878 - accuracy: 0.8000 - val_loss: 0.5722 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5609 - accuracy: 0.8004 - val_loss: 0.5500 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5405 - accuracy: 0.8007 - val_loss: 0.5321 - val_accuracy: 0.8029\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 44ms/step - loss: 0.5692 - accuracy: 0.7737 - val_loss: 0.5046 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 0.5037 - accuracy: 0.8000 - val_loss: 0.4965 - val_accuracy: 0.8029\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 0.5025 - accuracy: 0.8000 - val_loss: 0.5403 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5009 - accuracy: 0.8007 - val_loss: 0.5048 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5019 - accuracy: 0.8000 - val_loss: 0.5105 - val_accuracy: 0.8000\n",
            "7 924.113844871521   [0.7224654250144958, 0.7200020496845245, 0.7174968450069428, 0.7126357853412628, 0.7076171233654023] [[1, 3, 3, 0, 1, 2, 0, 6, 3, 1, 3, 4, 1, 4, 6, 1, 3, 1, 1, 2, 3, 4, 1, 4, 1, 4], [0, 3, 5, 4, 1, 3, 1, 6, 3, 1, 3, 4, 0, 4, 3, 1, 2, 4, 1, 2, 0, 4, 1, 5, 0, 10], [0, 3, 5, 4, 1, 2, 1, 6, 3, 1, 3, 4, 0, 4, 3, 1, 2, 4, 1, 2, 0, 4, 1, 5, 0, 10], [0, 3, 3, 2, 0, 2, 1, 6, 7, 1, 3, 2, 0, 4, 6, 0, 2, 4, 1, 2, 0, 4, 1, 4, 0, 4], [1, 3, 7, 0, 1, 2, 0, 6, 3, 1, 3, 4, 1, 4, 3, 1, 3, 3, 1, 3, 3, 4, 1, 5, 1, 4]]\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 13s 36ms/step - loss: 0.6740 - accuracy: 0.8004 - val_loss: 0.6553 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.6377 - accuracy: 0.8007 - val_loss: 0.6196 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.6038 - accuracy: 0.7996 - val_loss: 0.5854 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5742 - accuracy: 0.8000 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5529 - accuracy: 0.8000 - val_loss: 0.5431 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 39ms/step - loss: 0.6147 - accuracy: 0.7909 - val_loss: 0.5822 - val_accuracy: 0.8029\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.5659 - accuracy: 0.7996 - val_loss: 0.5520 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5425 - accuracy: 0.7996 - val_loss: 0.5365 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5277 - accuracy: 0.8004 - val_loss: 0.5229 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5190 - accuracy: 0.8000 - val_loss: 0.5132 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 38ms/step - loss: 0.5061 - accuracy: 0.7993 - val_loss: 0.6790 - val_accuracy: 0.7382\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5011 - accuracy: 0.8004 - val_loss: 0.5154 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.4996 - accuracy: 0.8000 - val_loss: 0.5667 - val_accuracy: 0.7603\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.4981 - accuracy: 0.8007 - val_loss: 0.5007 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.4949 - accuracy: 0.8007 - val_loss: 0.5018 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 38ms/step - loss: 0.6388 - accuracy: 0.7068 - val_loss: 0.6647 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5780 - accuracy: 0.8000 - val_loss: 0.5741 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5485 - accuracy: 0.8004 - val_loss: 0.5437 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5350 - accuracy: 0.7996 - val_loss: 0.5261 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5230 - accuracy: 0.8004 - val_loss: 0.5189 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 44ms/step - loss: 0.5668 - accuracy: 0.7755 - val_loss: 0.5090 - val_accuracy: 0.8029\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 0.5007 - accuracy: 0.8011 - val_loss: 0.5316 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 0.5057 - accuracy: 0.8004 - val_loss: 0.5043 - val_accuracy: 0.8029\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 0.5046 - accuracy: 0.8000 - val_loss: 0.5105 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 0.5033 - accuracy: 0.8000 - val_loss: 0.5097 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 42ms/step - loss: 0.6441 - accuracy: 0.7166 - val_loss: 0.6029 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5859 - accuracy: 0.8004 - val_loss: 0.5648 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5567 - accuracy: 0.7996 - val_loss: 0.5483 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5372 - accuracy: 0.8000 - val_loss: 0.5345 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5249 - accuracy: 0.8000 - val_loss: 0.5252 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 42ms/step - loss: 0.5552 - accuracy: 0.7737 - val_loss: 0.5062 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5033 - accuracy: 0.8004 - val_loss: 0.4945 - val_accuracy: 0.8044\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5037 - accuracy: 0.7996 - val_loss: 0.5006 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5017 - accuracy: 0.8004 - val_loss: 0.5116 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5011 - accuracy: 0.7996 - val_loss: 0.4972 - val_accuracy: 0.8029\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 39ms/step - loss: 0.7345 - accuracy: 0.5843 - val_loss: 0.5637 - val_accuracy: 0.7324\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5985 - accuracy: 0.7013 - val_loss: 0.5498 - val_accuracy: 0.7574\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5501 - accuracy: 0.7678 - val_loss: 0.5469 - val_accuracy: 0.7529\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5295 - accuracy: 0.7803 - val_loss: 0.5113 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5127 - accuracy: 0.7879 - val_loss: 0.5178 - val_accuracy: 0.7882\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 38ms/step - loss: 1.7604 - accuracy: 0.5547 - val_loss: 0.9238 - val_accuracy: 0.7162\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.9842 - accuracy: 0.7093 - val_loss: 1.0937 - val_accuracy: 0.7088\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.7739 - accuracy: 0.7397 - val_loss: 0.8817 - val_accuracy: 0.7721\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 1.0808 - accuracy: 0.7046 - val_loss: 1.9613 - val_accuracy: 0.6912\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 1.4003 - accuracy: 0.7035 - val_loss: 1.2202 - val_accuracy: 0.7132\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 38ms/step - loss: 0.5670 - accuracy: 0.7605 - val_loss: 0.5246 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.4996 - accuracy: 0.8000 - val_loss: 0.5150 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.4969 - accuracy: 0.7993 - val_loss: 0.5048 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.4928 - accuracy: 0.8007 - val_loss: 0.5020 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.4910 - accuracy: 0.7996 - val_loss: 0.5136 - val_accuracy: 0.8015\n",
            "8 936.2291808128357   [0.712699009180069, 0.7122506673336029, 0.7118036608695983, 0.7110698637962342, 0.7076334195137024] [[0, 3, 6, 0, 1, 2, 0, 6, 4, 1, 3, 3, 0, 4, 3, 0, 3, 3, 1, 2, 3, 4, 1, 5, 1, 10], [1, 3, 3, 0, 1, 2, 0, 6, 3, 1, 3, 4, 1, 4, 6, 1, 3, 1, 1, 2, 3, 4, 1, 4, 1, 4], [0, 3, 5, 4, 1, 3, 1, 6, 3, 1, 3, 4, 0, 4, 3, 1, 2, 4, 1, 2, 0, 4, 1, 5, 0, 10], [1, 3, 7, 0, 1, 2, 0, 6, 3, 1, 3, 4, 1, 4, 3, 1, 3, 3, 1, 3, 3, 4, 1, 5, 1, 4], [1, 7, 3, 4, 0, 2, 1, 6, 3, 1, 3, 4, 0, 4, 3, 1, 2, 4, 1, 2, 0, 4, 1, 4, 1, 10]]\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 38ms/step - loss: 0.6738 - accuracy: 0.8007 - val_loss: 0.6553 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.6376 - accuracy: 0.8004 - val_loss: 0.6194 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.6041 - accuracy: 0.8000 - val_loss: 0.5876 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5747 - accuracy: 0.8000 - val_loss: 0.5606 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5541 - accuracy: 0.8004 - val_loss: 0.5403 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 39ms/step - loss: 0.5651 - accuracy: 0.7664 - val_loss: 0.5098 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.5010 - accuracy: 0.8000 - val_loss: 0.5012 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.4994 - accuracy: 0.8000 - val_loss: 0.5008 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.4979 - accuracy: 0.8011 - val_loss: 0.5059 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 39ms/step - loss: 0.4981 - accuracy: 0.8000 - val_loss: 0.5116 - val_accuracy: 0.8029\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 41ms/step - loss: 0.6318 - accuracy: 0.7620 - val_loss: 0.6409 - val_accuracy: 0.8029\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5741 - accuracy: 0.8007 - val_loss: 0.5657 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5464 - accuracy: 0.8007 - val_loss: 0.5292 - val_accuracy: 0.8044\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5260 - accuracy: 0.8004 - val_loss: 0.5248 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 37ms/step - loss: 0.5162 - accuracy: 0.8004 - val_loss: 0.5092 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 42ms/step - loss: 0.5637 - accuracy: 0.7694 - val_loss: 0.5017 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5045 - accuracy: 0.8000 - val_loss: 0.5114 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5030 - accuracy: 0.8000 - val_loss: 0.5107 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5014 - accuracy: 0.7996 - val_loss: 0.5241 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: 0.5008 - accuracy: 0.8004 - val_loss: 0.5079 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 17s 47ms/step - loss: 0.5623 - accuracy: 0.7751 - val_loss: 0.5047 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 16s 46ms/step - loss: 0.5010 - accuracy: 0.8004 - val_loss: 0.4985 - val_accuracy: 0.8015\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 16s 47ms/step - loss: 0.4997 - accuracy: 0.8007 - val_loss: 0.5009 - val_accuracy: 0.8000\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 16s 46ms/step - loss: 0.4996 - accuracy: 0.8007 - val_loss: 0.4988 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 16s 46ms/step - loss: 0.4998 - accuracy: 0.8007 - val_loss: 0.4987 - val_accuracy: 0.8015\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 16s 45ms/step - loss: 0.5283 - accuracy: 0.7938 - val_loss: 0.5236 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 42ms/step - loss: 0.5075 - accuracy: 0.7978 - val_loss: 0.5117 - val_accuracy: 0.8044\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5038 - accuracy: 0.7996 - val_loss: 0.5251 - val_accuracy: 0.7912\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 43ms/step - loss: 0.5066 - accuracy: 0.7971 - val_loss: 0.5279 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 0.5108 - accuracy: 0.7978 - val_loss: 0.5215 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 17s 46ms/step - loss: 0.6875 - accuracy: 0.5590 - val_loss: 0.7625 - val_accuracy: 0.2015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 45ms/step - loss: 0.6092 - accuracy: 0.7565 - val_loss: 0.5875 - val_accuracy: 0.8000\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 15s 45ms/step - loss: 0.5749 - accuracy: 0.7949 - val_loss: 0.5463 - val_accuracy: 0.7985\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 0.5534 - accuracy: 0.8000 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 45ms/step - loss: 0.5357 - accuracy: 0.7996 - val_loss: 0.5219 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 15s 41ms/step - loss: nan - accuracy: 0.7693 - val_loss: nan - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: nan - accuracy: 0.7982 - val_loss: nan - val_accuracy: 0.7985\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: nan - accuracy: 0.7386 - val_loss: 0.5893 - val_accuracy: 0.7971\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5372 - accuracy: 0.7989 - val_loss: 0.5641 - val_accuracy: 0.8015\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 14s 42ms/step - loss: nan - accuracy: 0.7982 - val_loss: 0.5148 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 14s 39ms/step - loss: 0.6749 - accuracy: 0.8007 - val_loss: 0.6575 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.6425 - accuracy: 0.8000 - val_loss: 0.6278 - val_accuracy: 0.8044\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.6154 - accuracy: 0.8000 - val_loss: 0.6023 - val_accuracy: 0.8029\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5919 - accuracy: 0.8007 - val_loss: 0.5826 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 13s 38ms/step - loss: 0.5720 - accuracy: 0.8004 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "342/342 [==============================] - 17s 46ms/step - loss: 0.6446 - accuracy: 0.7122 - val_loss: 0.5897 - val_accuracy: 0.8015\n",
            "Epoch 2/5\n",
            "342/342 [==============================] - 15s 44ms/step - loss: 0.5575 - accuracy: 0.8000 - val_loss: 0.5192 - val_accuracy: 0.8029\n",
            "Epoch 3/5\n",
            "342/342 [==============================] - 16s 45ms/step - loss: 0.5126 - accuracy: 0.8004 - val_loss: 0.5042 - val_accuracy: 0.8015\n",
            "Epoch 4/5\n",
            "342/342 [==============================] - 15s 45ms/step - loss: 0.5024 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "342/342 [==============================] - 15s 45ms/step - loss: 0.5003 - accuracy: 0.8004 - val_loss: 0.4964 - val_accuracy: 0.8029\n",
            "9 968.8006708621979   [0.7117156295776367, 0.709115187883377, 0.707660523891449, 0.7064091799259186, 0.7045248320102692] [[0, 3, 6, 0, 1, 2, 0, 6, 4, 1, 3, 3, 0, 4, 3, 0, 3, 3, 1, 2, 3, 4, 1, 5, 1, 10], [1, 3, 3, 3, 1, 2, 1, 7, 3, 1, 3, 4, 0, 4, 4, 1, 2, 4, 1, 2, 0, 4, 1, 4, 1, 10], [1, 3, 7, 0, 1, 2, 0, 6, 3, 1, 3, 4, 1, 4, 3, 1, 3, 3, 1, 3, 3, 4, 1, 5, 1, 4], [0, 7, 3, 0, 0, 2, 1, 5, 3, 1, 3, 4, 0, 4, 3, 1, 3, 4, 1, 2, 0, 4, 1, 4, 1, 10], [1, 7, 3, 4, 0, 2, 1, 6, 3, 1, 3, 4, 0, 4, 3, 1, 2, 4, 1, 2, 0, 4, 1, 4, 1, 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA9J9_xraxa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1db83a-7395-4e18-a37f-cf2485825145"
      },
      "source": [
        "model_new = createConvNet(popul[0])\n",
        "model_new.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_101\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_188 (Conv2D)          (None, 96, 54, 8)         872       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_120 (MaxPoolin (None, 48, 27, 8)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_185 (Bat (None, 48, 27, 8)         32        \n",
            "_________________________________________________________________\n",
            "flatten_101 (Flatten)        (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_294 (Dense)            (None, 32)                331808    \n",
            "_________________________________________________________________\n",
            "batch_normalization_186 (Bat (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_295 (Dense)            (None, 1024)              33792     \n",
            "_________________________________________________________________\n",
            "dense_296 (Dense)            (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 368,682\n",
            "Trainable params: 368,602\n",
            "Non-trainable params: 80\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWmDAhtNZta_",
        "outputId": "0bec31fc-90e1-4131-ca3a-d9380cb310cd"
      },
      "source": [
        "#Комипилируем и обучаем\n",
        "start = time.time()\n",
        "model_new.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_new.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = train_generator.samples // batch_size,\n",
        "        validation_data = validation_generator, \n",
        "        validation_steps = validation_generator.samples // batch_size,\n",
        "        epochs=20,\n",
        "        verbose=1,\n",
        "    )\n",
        "print('Выполнено за ', time.time() - start)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "342/342 [==============================] - 32s 34ms/step - loss: 0.5431 - accuracy: 0.8007 - val_loss: 0.5350 - val_accuracy: 0.8015\n",
            "Epoch 2/20\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 0.5326 - accuracy: 0.8000 - val_loss: 0.5247 - val_accuracy: 0.8000\n",
            "Epoch 3/20\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 0.5243 - accuracy: 0.7996 - val_loss: 0.5187 - val_accuracy: 0.8015\n",
            "Epoch 4/20\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5170 - accuracy: 0.8004 - val_loss: 0.5131 - val_accuracy: 0.8000\n",
            "Epoch 5/20\n",
            "342/342 [==============================] - 11s 33ms/step - loss: 0.5133 - accuracy: 0.8004 - val_loss: 0.5092 - val_accuracy: 0.8015\n",
            "Epoch 6/20\n",
            "342/342 [==============================] - 11s 33ms/step - loss: 0.5079 - accuracy: 0.8004 - val_loss: 0.5091 - val_accuracy: 0.8000\n",
            "Epoch 7/20\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 0.5066 - accuracy: 0.8007 - val_loss: 0.5048 - val_accuracy: 0.8000\n",
            "Epoch 8/20\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5055 - accuracy: 0.8004 - val_loss: 0.5035 - val_accuracy: 0.8000\n",
            "Epoch 9/20\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 0.5040 - accuracy: 0.7996 - val_loss: 0.5003 - val_accuracy: 0.8029\n",
            "Epoch 10/20\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5041 - accuracy: 0.8004 - val_loss: 0.5034 - val_accuracy: 0.8000\n",
            "Epoch 11/20\n",
            "342/342 [==============================] - 12s 36ms/step - loss: 0.5034 - accuracy: 0.8000 - val_loss: 0.5005 - val_accuracy: 0.8015\n",
            "Epoch 12/20\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5024 - accuracy: 0.8000 - val_loss: 0.4988 - val_accuracy: 0.8029\n",
            "Epoch 13/20\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 0.5011 - accuracy: 0.8004 - val_loss: 0.4982 - val_accuracy: 0.8029\n",
            "Epoch 14/20\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 0.5010 - accuracy: 0.8004 - val_loss: 0.5019 - val_accuracy: 0.8000\n",
            "Epoch 15/20\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5000 - accuracy: 0.8000 - val_loss: 0.5032 - val_accuracy: 0.8000\n",
            "Epoch 16/20\n",
            "342/342 [==============================] - 12s 35ms/step - loss: 0.5004 - accuracy: 0.8007 - val_loss: 0.4998 - val_accuracy: 0.8015\n",
            "Epoch 17/20\n",
            "342/342 [==============================] - 11s 33ms/step - loss: 0.5000 - accuracy: 0.8007 - val_loss: 0.5003 - val_accuracy: 0.8015\n",
            "Epoch 18/20\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 0.5006 - accuracy: 0.8004 - val_loss: 0.4980 - val_accuracy: 0.8015\n",
            "Epoch 19/20\n",
            "342/342 [==============================] - 12s 34ms/step - loss: 0.4991 - accuracy: 0.8007 - val_loss: 0.4955 - val_accuracy: 0.8044\n",
            "Epoch 20/20\n",
            "342/342 [==============================] - 11s 34ms/step - loss: 0.4994 - accuracy: 0.8004 - val_loss: 0.5025 - val_accuracy: 0.8000\n",
            "Выполнено за  333.7540371417999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D7MHm5oaXbV"
      },
      "source": [
        "# Предыдущая архитектура"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJnGuHabacWn"
      },
      "source": [
        "#Создаем последовательную модель\n",
        "model = Sequential()\n",
        "#Первый сверточный слой\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu', input_shape=(img_width, img_height, 3)))\n",
        "#Второй сверточный слой\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "#Третий сверточный слой\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "#Слой регуляризации Dropout\n",
        "model.add(Dropout(0.2))\n",
        "#Четвертый сверточный слой\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "#Слой регуляризации Dropout\n",
        "model.add(Dropout(0.2))\n",
        "#Пятый сверточный слой\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "#Шестой сверточный слой\n",
        "model.add(Conv2D(1024, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "#Слой регуляризации Dropout\n",
        "model.add(Dropout(0.2))\n",
        "#Слой преобразования двумерных данных в одномерные \n",
        "model.add(Flatten())\n",
        "#Полносвязный слой\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "#Полносвязный слой\n",
        "model.add(Dense(2048, activation='relu'))\n",
        "#Вызодной полносвязный слой\n",
        "model.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4BAPFRyaWL1",
        "outputId": "d6929edc-acb1-4655-d0db-cd16b0dc060f"
      },
      "source": [
        "#Комипилируем и обучаем\n",
        "start = time.time()\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = train_generator.samples // batch_size,\n",
        "        validation_data = validation_generator, \n",
        "        validation_steps = validation_generator.samples // batch_size,\n",
        "        epochs=20,\n",
        "        verbose=1,\n",
        "    )\n",
        "print('Выполнено за ', time.time() - start)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "342/342 [==============================] - 41s 111ms/step - loss: 0.5218 - accuracy: 0.7978 - val_loss: 0.4998 - val_accuracy: 0.8029\n",
            "Epoch 2/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.5061 - accuracy: 0.8004 - val_loss: 0.5018 - val_accuracy: 0.8000\n",
            "Epoch 3/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.5032 - accuracy: 0.8007 - val_loss: 0.5130 - val_accuracy: 0.8000\n",
            "Epoch 4/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.5041 - accuracy: 0.8004 - val_loss: 0.5020 - val_accuracy: 0.8015\n",
            "Epoch 5/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.5012 - accuracy: 0.8007 - val_loss: 0.4968 - val_accuracy: 0.8015\n",
            "Epoch 6/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.5030 - accuracy: 0.8004 - val_loss: 0.5005 - val_accuracy: 0.8000\n",
            "Epoch 7/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.5011 - accuracy: 0.8000 - val_loss: 0.5093 - val_accuracy: 0.8000\n",
            "Epoch 8/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.5029 - accuracy: 0.8004 - val_loss: 0.5005 - val_accuracy: 0.8000\n",
            "Epoch 9/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.4979 - accuracy: 0.8000 - val_loss: 0.5031 - val_accuracy: 0.8000\n",
            "Epoch 10/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.4963 - accuracy: 0.8000 - val_loss: 0.5016 - val_accuracy: 0.8015\n",
            "Epoch 11/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.4950 - accuracy: 0.8004 - val_loss: 0.5021 - val_accuracy: 0.8029\n",
            "Epoch 12/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.4980 - accuracy: 0.8000 - val_loss: 0.5034 - val_accuracy: 0.8029\n",
            "Epoch 13/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.4970 - accuracy: 0.8015 - val_loss: 0.4986 - val_accuracy: 0.8000\n",
            "Epoch 14/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.4951 - accuracy: 0.8000 - val_loss: 0.4964 - val_accuracy: 0.8015\n",
            "Epoch 15/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.4941 - accuracy: 0.8007 - val_loss: 0.4982 - val_accuracy: 0.8015\n",
            "Epoch 16/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.4918 - accuracy: 0.8011 - val_loss: 0.5009 - val_accuracy: 0.8029\n",
            "Epoch 17/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.4875 - accuracy: 0.8004 - val_loss: 0.5485 - val_accuracy: 0.8000\n",
            "Epoch 18/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.4897 - accuracy: 0.8004 - val_loss: 0.4984 - val_accuracy: 0.8000\n",
            "Epoch 19/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.4864 - accuracy: 0.8004 - val_loss: 0.4996 - val_accuracy: 0.8000\n",
            "Epoch 20/20\n",
            "342/342 [==============================] - 36s 106ms/step - loss: 0.4891 - accuracy: 0.8000 - val_loss: 0.5235 - val_accuracy: 0.8000\n",
            "Выполнено за  782.8846774101257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzkkkgr4f_dq",
        "outputId": "1444919f-0132-4dca-d0d6-00a2cd9b88a0"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_102\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_189 (Conv2D)          (None, 96, 54, 256)       7168      \n",
            "_________________________________________________________________\n",
            "conv2d_190 (Conv2D)          (None, 96, 54, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_121 (MaxPoolin (None, 32, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_191 (Conv2D)          (None, 32, 18, 256)       590080    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_192 (Conv2D)          (None, 32, 18, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_122 (MaxPoolin (None, 10, 6, 256)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 6, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_193 (Conv2D)          (None, 10, 6, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_194 (Conv2D)          (None, 10, 6, 1024)       4719616   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_123 (MaxPoolin (None, 3, 2, 1024)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 2, 1024)        0         \n",
            "_________________________________________________________________\n",
            "flatten_102 (Flatten)        (None, 6144)              0         \n",
            "_________________________________________________________________\n",
            "dense_297 (Dense)            (None, 4096)              25169920  \n",
            "_________________________________________________________________\n",
            "dense_298 (Dense)            (None, 2048)              8390656   \n",
            "_________________________________________________________________\n",
            "dense_299 (Dense)            (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 41,241,858\n",
            "Trainable params: 41,241,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPokHSn9frQc"
      },
      "source": [
        "## Итог: при одинаковом качестве архитектура, подобранная с помощью генетического алгоритма, обучается в 2.5 раза быстрее имея всего 368 682 параметров против 41 241 858"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1nMkNFhbUWO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}