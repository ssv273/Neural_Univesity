{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled51.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcDjaaAmI9H+KmsF8xoacf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssv273/Neural_Univesity/blob/main/hw_18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "8AXAtRJVCb_4",
        "outputId": "8f3008d6-11c5-4e5c-aad1-3ea5e07640f5"
      },
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files \n",
        "files.upload()\n",
        "! mkdir ~/.kaggle \n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d dataturks/resume-entities-for-ner\n",
        "! mkdir Data\n",
        "! unzip resume-entities-for-ner.zip -d Data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-54918b0b-7952-472b-91c4-2ae388802499\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-54918b0b-7952-472b-91c4-2ae388802499\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading resume-entities-for-ner.zip to /content\n",
            "  0% 0.00/323k [00:00<?, ?B/s]\n",
            "100% 323k/323k [00:00<00:00, 44.4MB/s]\n",
            "Archive:  resume-entities-for-ner.zip\n",
            "  inflating: Data/Entity Recognition in Resumes.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R16wtD4xF41e"
      },
      "source": [
        "import json\n",
        "import re\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmt1T-eeDJPX"
      },
      "source": [
        "# JSON formatting functions\n",
        "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
        "    training_data = []\n",
        "    lines=[]\n",
        "    with open(dataturks_JSON_FilePath, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        data = json.loads(line)\n",
        "        text = data['content'].replace(\"\\n\", \" \")\n",
        "        entities = []\n",
        "        data_annotations = data['annotation']\n",
        "        if data_annotations is not None:\n",
        "            for annotation in data_annotations:\n",
        "                #only a single point in text annotation.\n",
        "                point = annotation['points'][0]\n",
        "                labels = annotation['label']\n",
        "                # handle both list of labels or a single label.\n",
        "                if not isinstance(labels, list):\n",
        "                    labels = [labels]\n",
        "\n",
        "                for label in labels:\n",
        "                    point_start = point['start']\n",
        "                    point_end = point['end']\n",
        "                    point_text = point['text']\n",
        "\n",
        "                    lstrip_diff = len(point_text) - len(point_text.lstrip())\n",
        "                    rstrip_diff = len(point_text) - len(point_text.rstrip())\n",
        "                    if lstrip_diff != 0:\n",
        "                        point_start = point_start + lstrip_diff\n",
        "                    if rstrip_diff != 0:\n",
        "                        point_end = point_end - rstrip_diff\n",
        "                    entities.append((point_start, point_end + 1 , label))\n",
        "        training_data.append((text, {\"entities\" : entities}))\n",
        "    return training_data\n",
        "\n",
        "def trim_entity_spans(data: list) -> list:\n",
        "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
        "\n",
        "    Args:\n",
        "        data (list): The data to be cleaned in spaCy JSON format.\n",
        "\n",
        "    Returns:\n",
        "        list: The cleaned data.\n",
        "    \"\"\"\n",
        "    invalid_span_tokens = re.compile(r'\\s')\n",
        "\n",
        "    cleaned_data = []\n",
        "    for text, annotations in data:\n",
        "        entities = annotations['entities']\n",
        "        valid_entities = []\n",
        "        for start, end, label in entities:\n",
        "            valid_start = start\n",
        "            valid_end = end\n",
        "            while valid_start < len(text) and invalid_span_tokens.match(\n",
        "                    text[valid_start]):\n",
        "                valid_start += 1\n",
        "            while valid_end > 1 and invalid_span_tokens.match(\n",
        "                    text[valid_end - 1]):\n",
        "                valid_end -= 1\n",
        "            valid_entities.append([valid_start, valid_end, label])\n",
        "        cleaned_data.append([text, {'entities': valid_entities}])\n",
        "    return cleaned_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gvkD87CDl4I",
        "outputId": "431aa57a-722b-4964-8a7c-8de241248455"
      },
      "source": [
        "data = trim_entity_spans(convert_dataturks_to_spacy(\"Data/Entity Recognition in Resumes.json\"))\n",
        "data[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Abhishek Jha Application Development Associate - Accenture  Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a  • To work for an organization which provides me the opportunity to improve my skills and knowledge for my individual and company's growth in best possible ways.  Willing to relocate to: Bangalore, Karnataka  WORK EXPERIENCE  Application Development Associate  Accenture -  November 2017 to Present  Role: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries for the Bot which will be triggered based on given input. Also, Training the bot for different possible utterances (Both positive and negative), which will be given as input by the user.  EDUCATION  B.E in Information science and engineering  B.v.b college of engineering and technology -  Hubli, Karnataka  August 2013 to June 2017  12th in Mathematics  Woodbine modern school  April 2011 to March 2013  10th  Kendriya Vidyalaya  April 2001 to March 2011  SKILLS  C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year), Database Management System (Less than 1 year), Java (Less than 1 year)  ADDITIONAL INFORMATION  Technical Skills  https://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN   • Programming language: C, C++, Java • Oracle PeopleSoft • Internet Of Things • Machine Learning • Database Management System • Computer Networks • Operating System worked on: Linux, Windows, Mac  Non - Technical Skills  • Honest and Hard-Working • Tolerant and Flexible to Different Situations • Polite and Calm • Team-Player\",\n",
              " {'entities': [[1296, 1622, 'Skills'],\n",
              "   [993, 1154, 'Skills'],\n",
              "   [939, 957, 'College Name'],\n",
              "   [883, 905, 'College Name'],\n",
              "   [856, 860, 'Graduation Year'],\n",
              "   [771, 814, 'College Name'],\n",
              "   [727, 769, 'Designation'],\n",
              "   [407, 416, 'Companies worked at'],\n",
              "   [372, 405, 'Designation'],\n",
              "   [95, 145, 'Email Address'],\n",
              "   [60, 69, 'Location'],\n",
              "   [49, 58, 'Companies worked at'],\n",
              "   [13, 46, 'Designation'],\n",
              "   [0, 12, 'Name']]}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jDphaYaEF9lb",
        "outputId": "69318204-02bb-40f1-dbeb-6659d4adabd3"
      },
      "source": [
        "data[0][0][0:12]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Abhishek Jha'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqA55H4uENne",
        "outputId": "3c9fa42f-7129-4146-ce7b-592f9d42f2f0"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-rLAJsKGjDb"
      },
      "source": [
        "entity_dict = {\n",
        "    'Name': 's0', \n",
        "    'College Name': 's1',\n",
        "    'Degree': 's2',\n",
        "    'Graduation Year': 's3',\n",
        "    'Years of Experience': 's4',\n",
        "    'Companies worked at': 's5',\n",
        "    'Designation': 's6',\n",
        "    'Skills': 's7',\n",
        "    'Location': 's8',\n",
        "    'Email Address': 's9',\n",
        "    'UNKNOWN':'s10'\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLq5E2-KKe14",
        "outputId": "aaf20d8d-c0e2-4158-8b30-c106d015960b"
      },
      "source": [
        "data[0][1]['entities'][::-1]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 12, 'Name'],\n",
              " [13, 46, 'Designation'],\n",
              " [49, 58, 'Companies worked at'],\n",
              " [60, 69, 'Location'],\n",
              " [95, 145, 'Email Address'],\n",
              " [372, 405, 'Designation'],\n",
              " [407, 416, 'Companies worked at'],\n",
              " [727, 769, 'Designation'],\n",
              " [771, 814, 'College Name'],\n",
              " [856, 860, 'Graduation Year'],\n",
              " [883, 905, 'College Name'],\n",
              " [939, 957, 'College Name'],\n",
              " [993, 1154, 'Skills'],\n",
              " [1296, 1622, 'Skills']]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "mSrKLNiHKeyc",
        "outputId": "5f67c46f-01ea-4ffa-c3d9-379d08d34653"
      },
      "source": [
        "data[0][0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Abhishek Jha Application Development Associate - Accenture  Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a  • To work for an organization which provides me the opportunity to improve my skills and knowledge for my individual and company's growth in best possible ways.  Willing to relocate to: Bangalore, Karnataka  WORK EXPERIENCE  Application Development Associate  Accenture -  November 2017 to Present  Role: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries for the Bot which will be triggered based on given input. Also, Training the bot for different possible utterances (Both positive and negative), which will be given as input by the user.  EDUCATION  B.E in Information science and engineering  B.v.b college of engineering and technology -  Hubli, Karnataka  August 2013 to June 2017  12th in Mathematics  Woodbine modern school  April 2011 to March 2013  10th  Kendriya Vidyalaya  April 2001 to March 2011  SKILLS  C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year), Database Management System (Less than 1 year), Java (Less than 1 year)  ADDITIONAL INFORMATION  Technical Skills  https://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN   • Programming language: C, C++, Java • Oracle PeopleSoft • Internet Of Things • Machine Learning • Database Management System • Computer Networks • Operating System worked on: Linux, Windows, Mac  Non - Technical Skills  • Honest and Hard-Working • Tolerant and Flexible to Different Situations • Polite and Calm • Team-Player\""
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZnGD4pYLpA3"
      },
      "source": [
        "example = data[0][0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFbXONSHKzD_"
      },
      "source": [
        "def set_tags(string, entities):\n",
        "    other_symbols_index = 0\n",
        "    new_string = ''\n",
        "    for i in entities[::-1]:\n",
        "        # print(\"Левый текст\", example[other_symbols_index:i[0]])\n",
        "        # print(example[i[0]:i[1]])\n",
        "        new_string = new_string + \" \" + string[other_symbols_index:i[0]] + \" \" + \"<\" + entity_dict[i[2]] + \">\" + string[i[0]:i[1]] + \"</\" + entity_dict[i[2]] + \">\"\n",
        "        other_symbols_index = i[1]\n",
        "        # print(\"-\"* 20)\n",
        "\n",
        "    return new_string"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "rUbTQR14TdIA",
        "outputId": "05adea2e-c0fb-414a-806a-7b8a2805eea0"
      },
      "source": [
        "set_tags(data[0][0], data[0][1]['entities'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"  <s0>Abhishek Jha</s0>   <s6>Application Development Associate</s6>  -  <s5>Accenture</s5>    <s8>Bengaluru</s8> , Karnataka - Email me on  <s9>Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a</s9>   • To work for an organization which provides me the opportunity to improve my skills and knowledge for my individual and company's growth in best possible ways.  Willing to relocate to: Bangalore, Karnataka  WORK EXPERIENCE   <s6>Application Development Associate</s6>    <s5>Accenture</s5>  -  November 2017 to Present  Role: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries for the Bot which will be triggered based on given input. Also, Training the bot for different possible utterances (Both positive and negative), which will be given as input by the user.  EDUCATION   <s6>B.E in Information science and engineering</s6>    <s1>B.v.b college of engineering and technology</s1>  -  Hubli, Karnataka  August 2013 to June  <s3>2017</s3>   12th in Mathematics   <s1>Woodbine modern school</s1>   April 2011 to March 2013  10th   <s1>Kendriya Vidyalaya</s1>   April 2001 to March 2011  SKILLS   <s7>C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year), Database Management System (Less than 1 year), Java (Less than 1 year)</s7>   ADDITIONAL INFORMATION  Technical Skills  https://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN    <s7>• Programming language: C, C++, Java • Oracle PeopleSoft • Internet Of Things • Machine Learning • Database Management System • Computer Networks • Operating System worked on: Linux, Windows, Mac  Non - Technical Skills  • Honest and Hard-Working • Tolerant and Flexible to Different Situations • Polite and Calm • Team-Player</s7>\""
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cypgRZRbIkp0"
      },
      "source": [
        "new_texts = []\n",
        "for i in range(len(data)):\n",
        "    new_texts.append(set_tags(data[i][0], data[i][1]['entities']))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5x83cbEUJ3T",
        "outputId": "dcf4feb9-3437-4267-f054-25fcee85e7c2"
      },
      "source": [
        "new_texts[10:11]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  <s0>Asish Ratha</s0>   <s6>Subject matter Expert</s6>  -  <s5>Accenture</s5>    <s8>Chennai</s8> , Tamil Nadu - Email me on Indeed:  <s8>indeed.com/r/Asish-Ratha/853988e0e0e236a3</s8>   WORK EXPERIENCE   <s6>Subject matter Expert</s6>    <s5>Accenture</s5>  -  March 2012 to Present  Subject matter expert  EDUCATION   <s1>Berhampur university</s1> ,  <s1>Khallikote autonomous college</s1>  -  Brahmapur, Orissa  SKILLS   <s7>Invoice (5 years), posting. (5 years), TRAINING (4 years)  ADDITIONAL INFORMATION  SKILLS Invoice processing, Team handling, new joiners training.sap posting,vendor call attend and resolve the issue,meet SLA tat,working with client tool.</s7>']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUHEAk1gIkr7"
      },
      "source": [
        "# Считываем текст из файла и удаляем пунктуационные знаки препинания и еще дополнительные ненужные нам знаки\n",
        "def readText(text):\n",
        "  # Определяем, какие знаки будут удалены\n",
        "  delSymbols = ['\\n', \"\\t\", \"\\ufeff\", \".\", \"_\", \"-\", \",\", \"!\", \"?\", \"–\", \"(\", \")\", \"«\", \"»\", \"№\", \";\",'•','%']\n",
        "\n",
        "  for dS in delSymbols: # Каждый знак из нашего списка будет удалён из списка\n",
        "    text = text.replace(dS, \" \") # Удаляем знак, посредством замены этого знака на пробел\n",
        "\n",
        "  # Выискиваем дополнительные знаки в текстах посредством паттернов и определяем на что их заменять\n",
        "  text = re.sub(\"[.]\", \" \", text)\n",
        "  text = re.sub(\":\", \" \", text)\n",
        "  text = re.sub(\"<\", \" <\", text)\n",
        "  text = re.sub(\">\", \"> \", text)\n",
        "\n",
        "  # split  метод разделит текст на последовательность слов при помощи пробелов\n",
        "  # (а их может быть в одном месте очень много после наших удалений знаков), которые будет являться разделителями.\n",
        "  # Используя join метод, мы обратно соберём последовательности слов в текст\n",
        "  text = ' '.join(text.split()) \n",
        "\n",
        "  text = text.lower() # Конвертируем текст к нижнему регистру\n",
        "  return text # Возвращаем текст\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "GrgwJEXTVgRL",
        "outputId": "56fa8027-431c-458f-ecbb-5a3773c7c554"
      },
      "source": [
        "readText(new_texts[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<s0> abhishek jha </s0> <s6> application development associate </s6> <s5> accenture </s5> <s8> bengaluru </s8> karnataka email me on <s9> indeed indeed com/r/abhishek jha/10e7a8cb732bc43a </s9> to work for an organization which provides me the opportunity to improve my skills and knowledge for my individual and company's growth in best possible ways willing to relocate to bangalore karnataka work experience <s6> application development associate </s6> <s5> accenture </s5> november 2017 to present role currently working on chat bot developing backend oracle peoplesoft queries for the bot which will be triggered based on given input also training the bot for different possible utterances both positive and negative which will be given as input by the user education <s6> b e in information science and engineering </s6> <s1> b v b college of engineering and technology </s1> hubli karnataka august 2013 to june <s3> 2017 </s3> 12th in mathematics <s1> woodbine modern school </s1> april 2011 to march 2013 10th <s1> kendriya vidyalaya </s1> april 2001 to march 2011 skills <s7> c less than 1 year database less than 1 year database management less than 1 year database management system less than 1 year java less than 1 year </s7> additional information technical skills https //www indeed com/r/abhishek jha/10e7a8cb732bc43a isid=rex download&ikw=download top&co=in <s7> programming language c c++ java oracle peoplesoft internet of things machine learning database management system computer networks operating system worked on linux windows mac non technical skills honest and hard working tolerant and flexible to different situations polite and calm team player </s7>\""
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "DQ3UmmRuYGRZ",
        "outputId": "362c4d9b-0e9b-49aa-9bf1-a9ba877bddb5"
      },
      "source": [
        "new_texts[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"  <s0>Abhishek Jha</s0>   <s6>Application Development Associate</s6>  -  <s5>Accenture</s5>    <s8>Bengaluru</s8> , Karnataka - Email me on  <s9>Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a</s9>   • To work for an organization which provides me the opportunity to improve my skills and knowledge for my individual and company's growth in best possible ways.  Willing to relocate to: Bangalore, Karnataka  WORK EXPERIENCE   <s6>Application Development Associate</s6>    <s5>Accenture</s5>  -  November 2017 to Present  Role: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries for the Bot which will be triggered based on given input. Also, Training the bot for different possible utterances (Both positive and negative), which will be given as input by the user.  EDUCATION   <s6>B.E in Information science and engineering</s6>    <s1>B.v.b college of engineering and technology</s1>  -  Hubli, Karnataka  August 2013 to June  <s3>2017</s3>   12th in Mathematics   <s1>Woodbine modern school</s1>   April 2011 to March 2013  10th   <s1>Kendriya Vidyalaya</s1>   April 2001 to March 2011  SKILLS   <s7>C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year), Database Management System (Less than 1 year), Java (Less than 1 year)</s7>   ADDITIONAL INFORMATION  Technical Skills  https://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN    <s7>• Programming language: C, C++, Java • Oracle PeopleSoft • Internet Of Things • Machine Learning • Database Management System • Computer Networks • Operating System worked on: Linux, Windows, Mac  Non - Technical Skills  • Honest and Hard-Working • Tolerant and Flexible to Different Situations • Polite and Calm • Team-Player</s7>\""
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE4uumexIkt_"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "import nltk"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RrxNHvIIpGo",
        "outputId": "134a0dee-95dd-4123-e49a-a9be219328c8"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDydxTPtWxI1"
      },
      "source": [
        "# Конвертируем исходный текст в лист слов с начальной формой \n",
        "def text2Words(text):\n",
        "  lemmatizer = nltk.stem.wordnet.WordNetLemmatizer() # Инициализируем инструмент для работы с морфемами и более\n",
        "  words = text.split(' ') #  Разделяем текст по средством пробелов\n",
        "  docs = [lemmatizer.lemmatize(word, wordnet.VERB) for word in words]\n",
        "#   docs = [morph.parse(word)[0].normal_form for word in words] # Превращаем каждое слово в элемент списка\n",
        "  return docs # Возвращаем полученный документ"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo1O5VFqXywY",
        "outputId": "aadebafc-9745-4869-9711-7f9eb1365997"
      },
      "source": [
        "docs_full = [] # Лист будет содержать все договоры как списки документов\n",
        "curTime = time.time() # Запоминаем текущее время\n",
        "for i in range(len(new_texts)): # Проходимся по каждому договору\n",
        "  docs_full.append(text2Words(readText(new_texts[i]))) # Превращаем договор в лист слов и добавляем его в docs_full\n",
        "print('Превращение заняло: ', round(time.time() - curTime, 2), 's.')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Превращение заняло:  1.91 s.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9ApuEMaX6sA",
        "outputId": "0c535e0d-b13d-4817-d440-ef53eb076fa9"
      },
      "source": [
        "docs_full[0][:10]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s0>',\n",
              " 'abhishek',\n",
              " 'jha',\n",
              " '</s0>',\n",
              " '<s6>',\n",
              " 'application',\n",
              " 'development',\n",
              " 'associate',\n",
              " '</s6>',\n",
              " '<s5>']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi1q0O57YnhB",
        "outputId": "ce14b008-2bc8-42ee-9839-b2ce2dd3153a"
      },
      "source": [
        "print(len(docs_full)) # Выводим число записей в наборе данных \n",
        "\n",
        "# Выбираем итоговое количество данных для обучающей/проверочной и тестовой выборках\n",
        "docs = docs_full[0:-10]\n",
        "docsToTest = docs_full[-10:]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg-KFS1AY78w",
        "outputId": "b3b2c313-01eb-41a0-ee34-72706dbc5b97"
      },
      "source": [
        "print('Число текстов в для тестовой проверки в конце ноутбука:', len(docsToTest)) \n",
        "print('Число договоров для обучающей и проверочной выборках:',len(docs)) \n",
        "print('Число слов в первом договоре:', len(docs[10]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Число текстов в для тестовой проверки в конце ноутбука: 10\n",
            "Число договоров для обучающей и проверочной выборках: 210\n",
            "Число слов в первом договоре: 93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAo7eA6DZAB6",
        "outputId": "deecab7b-9725-434d-9e39-ebe07fa4961e"
      },
      "source": [
        "print('Пример текста обычного:')\n",
        "print(new_texts[4][:62], '\\n')\n",
        "print('Тот же текст, но представленный ввиде лемм:')\n",
        "print(docs[4][:10])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример текста обычного:\n",
            "  <s0>Ananya Chavan</s0>   <s6>lecturer</s6>  -  <s5>oracle tu \n",
            "\n",
            "Тот же текст, но представленный ввиде лемм:\n",
            "['<s0>', 'ananya', 'chavan', '</s0>', '<s6>', 'lecturer', '</s6>', '<s5>', 'oracle', 'tutorials']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq6amsqsZSZi"
      },
      "source": [
        "# Превращение текстов в последовтельность индексов: создание xTrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn6o5Bd9ZYwL"
      },
      "source": [
        "import numpy as np # Библиотека для работы с массивами данных\n",
        "from tensorflow.keras.models import Model, load_model # Импортируем Model, load_model - метод, что загружает предобученную сеть\n",
        "import re # Имортируем чтобы работать с строками\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # Метод, который поволяет работать с текстами и конвертирует их в последовательности (индексов)\n",
        "# Импорт слоёв нейронных сетей\n",
        "from tensorflow.keras.layers import Dense, Embedding, Input, concatenate, Activation, MaxPooling1D, Conv1D, BatchNormalization, Dropout, Conv2DTranspose, Conv1DTranspose, Lambda\n",
        "from tensorflow.keras import backend as K # Импортируем, чтобы высчитать dice_coef(ошибку)\n",
        "from tensorflow.keras.optimizers import Adam, Adadelta # Импортируем оптимизаторы\n",
        "from tensorflow.keras import utils # Импортируем для работы с категориальными данными\n",
        "import tensorflow\n",
        "from google.colab import files # Импорт для работы с файлами\n",
        "import matplotlib.pyplot as plt # Импорт для отрисовывания графиков\n",
        "from gensim.models import word2vec # Импортируем gensim\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD2AjPr5ZHjj"
      },
      "source": [
        "# lower=True - приводит к нижнему регистру все слова\n",
        "# char_level=False - говорит токенайзеру не инициализировать отдельно каждую букву как токен  \n",
        "tokenizer = Tokenizer(lower=True, filters = '', char_level=False)\n",
        "\n",
        "tokenizer.fit_on_texts(docs_full) # Скармливаем тексты токенайзеру\n",
        "clean_voc = {}                    # Создаем пустой словарь\n",
        "\n",
        "for item in tokenizer.word_index.items(): # Превращаем лист в словарь\n",
        "  clean_voc[item[0]] = item[1]            # Мы меняем местами элеметны кортежа"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZw_DM83ZpjC",
        "outputId": "13e1533c-15c7-42e1-e06c-7cd00edd35e2"
      },
      "source": [
        "print('Словарь все слов по их частотноти:') \n",
        "print(clean_voc, '\\n')\n",
        "print('Длина словаря:', len(clean_voc))\n",
        "\n",
        "tag = '<s0>'\n",
        "print('Индекс тега', tag, ':' ,clean_voc[tag])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Словарь все слов по их частотноти:\n",
            "{'and': 1, 'the': 2, 'to': 3, 'in': 4, 'of': 5, 'for': 6, 'on': 7, 'work': 8, 'with': 9, 'test': 10, '<s5>': 11, '</s5>': 12, 'indeed': 13, 'be': 14, 'a': 15, 'management': 16, 'experience': 17, 'use': 18, 'project': 19, 'as': 20, 'team': 21, '<s6>': 22, '</s6>': 23, '<s7>': 24, '</s7>': 25, 'skills': 26, '<s8>': 27, '</s8>': 28, 'microsoft': 29, '➢': 30, '1': 31, 'data': 32, 'report': 33, 'engineer': 34, 'years': 35, 'support': 36, 'service': 37, 'tool': 38, 'year': 39, 'oracle': 40, '<s1>': 41, '</s1>': 42, '&': 43, 'process': 44, 'from': 45, 'client': 46, 'application': 47, '<s2>': 48, '</s2>': 49, 'business': 50, 'by': 51, 'technical': 52, 'system': 53, 'sql': 54, 'design': 55, 'than': 56, 'issue': 57, 'it': 58, 'software': 59, 'have': 60, 'email': 61, '*': 62, 'https': 63, '<s3>': 64, '</s3>': 65, '//www': 66, '<s9>': 67, '</s9>': 68, 'me': 69, 'server': 70, 'all': 71, 'sap': 72, 'development': 73, 'develop': 74, 'infosys': 75, 'less': 76, 'knowledge': 77, '<s0>': 78, '</s0>': 79, 'education': 80, 'karnataka': 81, 'create': 82, 'information': 83, '2': 84, 'i': 85, 'isid=rex': 86, 'download&ikw=download': 87, 'new': 88, 'top&co=in': 89, 'provide': 90, 'systems': 91, '2016': 92, 'web': 93, 'windows': 94, 'customer': 95, 'present': 96, 'involve': 97, 'java': 98, 'end': 99, 'applications': 100, 'base': 101, 'lead': 102, 'database': 103, 'like': 104, 'technology': 105, 'at': 106, 'an': 107, 'responsibilities': 108, 'will': 109, '2015': 110, 'manage': 111, 'plan': 112, 'that': 113, 'program': 114, 'build': 115, '●': 116, 'india': 117, 'environment': 118, '3': 119, 'network': 120, 'handle': 121, 'good': 122, 'automation': 123, 'train': 124, 'implement': 125, '❖': 126, '2017': 127, '&amp': 128, 'which': 129, 'cisco': 130, '2013': 131, '4': 132, 'ms': 133, 'order': 134, 'various': 135, 'my': 136, 'limit': 137, 'additional': 138, 'monitor': 139, '2014': 140, 'university': 141, 'maintain': 142, 'quality': 143, 'case': 144, 'analysis': 145, 'this': 146, 'technologies': 147, 'requirements': 148, 'consultant': 149, 'user': 150, 'implementation': 151, 'manager': 152, '2012': 153, 'script': 154, 'june': 155, 'maharashtra': 156, 'document': 157, 'bengaluru': 158, 'perform': 159, 'performance': 160, 'office': 161, 'functional': 162, 'responsible': 163, 'change': 164, 'ltd': 165, 'cloud': 166, 'b': 167, 'production': 168, 'configuration': 169, 'sales': 170, 'azure': 171, 'up': 172, '5': 173, 'net': 174, 'time': 175, 'communication': 176, '2010': 177, 'bangalore': 178, 'college': 179, '6': 180, 'bank': 181, 'developer': 182, 'track': 183, 'product': 184, 'company': 185, '2011': 186, 'security': 187, 'relate': 188, 'computer': 189, 'understand': 190, 'senior': 191, '◦': 192, 'level': 193, 'role': 194, 'job': 195, 'july': 196, 'or': 197, '✓': 198, '2008': 199, 'automate': 200, 'release': 201, 'different': 202, 'troubleshoot': 203, 'include': 204, 'activities': 205, 'market': 206, 'operate': 207, 'integration': 208, 'relocate': 209, 'solution': 210, 'account': 211, 'organization': 212, 'pune': 213, 'prepare': 214, 'tamil': 215, 'solutions': 216, 'linux': 217, 'excel': 218, 'per': 219, 'c': 220, 'ensure': 221, 'through': 222, 'may': 223, 'other': 224, 'group': 225, '7': 226, '/': 227, 'nadu': 228, 'requirement': 229, 'platform': 230, 'can': 231, 'etc': 232, 'e': 233, 'meet': 234, 'code': 235, 'configure': 236, 'deployment': 237, 'telangana': 238, 'high': 239, 'give': 240, 'languages': 241, 'review': 242, 'hyderabad': 243, 'customers': 244, 'delivery': 245, 'associate': 246, 'also': 247, 'description': 248, 'professional': 249, 'defect': 250, 'analyst': 251, 'roles': 252, 'detail': 253, 'resolve': 254, 'science': 255, 'maintenance': 256, 'january': 257, 'set': 258, 'daily': 259, 'creation': 260, 'operations': 261, 's': 262, 'complete': 263, 'school': 264, 'multiple': 265, 'december': 266, 'pradesh': 267, 'access': 268, 'products': 269, 'september': 270, 'file': 271, 'clients': 272, 'framework': 273, 'tech': 274, 'global': 275, 'do': 276, 'update': 277, 'help': 278, 'august': 279, 'ability': 280, 'problem': 281, 'ticket': 282, 'call': 283, 'october': 284, 'learn': 285, 'key': 286, 'administration': 287, 'their': 288, 'servers': 289, 'store': 290, 'bi': 291, 'take': 292, 'control': 293, 'deploy': 294, 'core': 295, 'april': 296, 'users': 297, 'request': 298, 'agile': 299, 'march': 300, 'well': 301, 'jenkins': 302, 'power': 303, 'make': 304, 'write': 305, 'feature': 306, 'html': 307, 'qa': 308, 'purchase': 309, 'basis': 310, 'center': 311, 'institute': 312, 'february': 313, 'master': 314, '2007': 315, 'domain': 316, 'identify': 317, '2005': 318, 'expertise': 319, 'post': 320, 'model': 321, 'manual': 322, 'log': 323, 'need': 324, 'require': 325, 'november': 326, 'environments': 327, 'strong': 328, 'board': 329, 'object': 330, 'python': 331, 'chennai': 332, 'c++': 333, 'across': 334, 'partner': 335, 'architecture': 336, 'incident': 337, 'excellent': 338, 'bachelor': 339, 'solve': 340, 'part': 341, 'pvt': 342, 'selenium': 343, 'any': 344, 'asp': 345, 'check': 346, 'months': 347, 'internal': 348, 'jira': 349, 'over': 350, 'sharepoint': 351, 'schedule': 352, 'module': 353, 'point': 354, '0': 355, 'c#': 356, 'migration': 357, 'basic': 358, 'award': 359, 'aws': 360, 'query': 361, 'member': 362, 'studio': 363, 'conduct': 364, '10': 365, 'executive': 366, 'crm': 367, 'task': 368, 'them': 369, 'such': 370, 'integrate': 371, 'ui': 372, 'get': 373, 'resource': 374, '2018': 375, 'hr': 376, 'members': 377, 'api': 378, 'continuous': 379, 'skill': 380, 'ibm': 381, 'day': 382, 'where': 383, 'within': 384, 'coordinate': 385, 'receive': 386, 'hand': 387, 'result': 388, 'list': 389, 'language': 390, 'record': 391, 'o': 392, 'invoice': 393, 'deliver': 394, 'abap': 395, 'enterprise': 396, '8': 397, 'analyze': 398, 'into': 399, 'date': 400, 'hp': 401, 'source': 402, 'git': 403, 'm': 404, '<s4>': 405, '</s4>': 406, 'online': 407, 'execute': 408, 'form': 409, 'unit': 410, 'exchange': 411, 'out': 412, '2009': 413, 'risk': 414, 'best': 415, 'fix': 416, 'status': 417, 'upgrade': 418, 'mobile': 419, 'duration': 420, 'anywhere': 421, 'orient': 422, 'till': 423, 'delhi': 424, 'switch': 425, 'infrastructure': 426, 'when': 427, 'maximo': 428, 'size': 429, 'installation': 430, 'setup': 431, 'visual': 432, 'regression': 433, 'state': 434, 'javascript': 435, 'field': 436, 'areas': 437, 'cycle': 438, 'cod': 439, 'generate': 440, 'branch': 441, 'devops': 442, 'growth': 443, '〓': 444, 'function': 445, 'offer': 446, 'maven': 447, 'define': 448, 'unix': 449, 'bug': 450, 'svn': 451, 'share': 452, 'its': 453, 'eclipse': 454, 'load': 455, 'financial': 456, 'employees': 457, 'view': 458, 'modules': 459, 'improve': 460, 'more': 461, 'procedures': 462, 'under': 463, 'drive': 464, 'analytics': 465, 'monthly': 466, 'each': 467, 'life': 468, 'complex': 469, 'vendor': 470, 'one': 471, 'active': 472, 'exposure': 473, 'run': 474, 'we': 475, 'site': 476, 'css': 477, 'word': 478, 'exist': 479, 'certify': 480, 'protocols': 481, 'rout': 482, 'follow': 483, 'both': 484, 'documentation': 485, 'corporate': 486, 'databases': 487, 'amazon': 488, 'concepts': 489, 'employee': 490, 'storage': 491, 'accenture': 492, 'link': 493, 'incidents': 494, 'finance': 495, 'challenge': 496, 'card': 497, 'about': 498, 'communicate': 499, 'multi': 500, 'db': 501, 'interface': 502, 'uttar': 503, 'analytical': 504, 'backup': 505, 'http': 506, 'travel': 507, 'components': 508, 'execution': 509, 'escalation': 510, 'participate': 511, 'during': 512, 'upload': 513, 'fusion': 514, 'inventory': 515, 'achieve': 516, 'mysql': 517, 'retail': 518, 'corporation': 519, 'name': 520, 'cost': 521, 'message': 522, 'area': 523, 'payment': 524, 'gather': 525, 'asset': 526, 'type': 527, 'traffic': 528, 'content': 529, 'number': 530, 'xml': 531, 'major': 532, 'utilize': 533, 'back': 534, 'functionality': 535, 'effective': 536, 'co': 537, 'overall': 538, 'interpersonal': 539, 'leadership': 540, '9': 541, 'audit': 542, 'search': 543, 'industry': 544, 'flow': 545, 'send': 546, 'dashboards': 547, 'real': 548, 'currently': 549, 'front': 550, 'version': 551, 'phase': 552, 'problems': 553, 'total': 554, 'mentor': 555, 'private': 556, 'hardware': 557, 'strategies': 558, 'bill': 559, 'video': 560, 'r': 561, 'page': 562, 'uat': 563, 'reduce': 564, 'along': 565, 'electronics': 566, 'keep': 567, 'find': 568, 'international': 569, 'custom': 570, 'attend': 571, 'us': 572, 'effectively': 573, 'reward': 574, 'live': 575, 'target': 576, 'standard': 577, 'line': 578, 'regard': 579, 'join': 580, 'architect': 581, 'admin': 582, 'google': 583, '♦': 584, 'player': 585, 'approach': 586, 'weekly': 587, 'assign': 588, 'own': 589, 'assist': 590, 'personal': 591, 'improvement': 592, 'same': 593, 'care': 594, 'andhra': 595, 'methodologies': 596, 'resources': 597, '2004': 598, 'highly': 599, 'class': 600, 'not': 601, 'transactions': 602, 'logic': 603, 'add': 604, 'package': 605, 'table': 606, 'critical': 607, 'current': 608, 'mumbai': 609, 'intelligence': 610, 'dev': 611, 'look': 612, 'structure': 613, 'supplier': 614, 'website': 615, '10+': 616, 'if': 617, 'kerala': 618, 'estimation': 619, 'raise': 620, 'transfer': 621, 'apply': 622, 'com': 623, 'self': 624, 'uk': 625, 'successfully': 626, 'soap': 627, 'trade': 628, 'sd': 629, 'enable': 630, 'offshore': 631, 'display': 632, 'west': 633, 'carry': 634, 'devices': 635, 'warehouse': 636, 'career': 637, 'secondary': 638, 'open': 639, 'scope': 640, 'map': 641, 'gcp': 642, 'inc': 643, 'between': 644, 'cross': 645, 'finacle': 646, 'impact': 647, 'activity': 648, 'portal': 649, 'app': 650, 'resolution': 651, 'instal': 652, 'title': 653, 'price': 654, 'coordinator': 655, 'timely': 656, 'profile': 657, '2006': 658, 'summary': 659, 'shell': 660, 'x': 661, 'many': 662, 'methodology': 663, 'plant': 664, 'apps': 665, 'address': 666, 'bengal': 667, 'mule': 668, 'openstack': 669, 'organize': 670, 'availability': 671, 'alert': 672, 'public': 673, 'remote': 674, 'pl/sql': 675, 'position': 676, 'goals': 677, 'research': 678, 'cash': 679, 'deal': 680, 'big': 681, 'etl': 682, 'go': 683, 'middleware': 684, 'p': 685, 'designer': 686, 'escalations': 687, 'non': 688, 'debug': 689, 'world': 690, 'cluster': 691, 'while': 692, 'seek': 693, 'apache': 694, 'regular': 695, 'practice': 696, 'credit': 697, 'specifications': 698, 'towards': 699, 'entire': 700, 'g': 701, 'contact': 702, 'telecom': 703, 'no': 704, 'accord': 705, 'docker': 706, 'chandigarh': 707, 'interact': 708, 'our': 709, 'strategy': 710, 'splunk': 711, 'outlook': 712, 'directory': 713, 'administrator': 714, 'contribution': 715, 'recruitment': 716, 'v': 717, '[…]': 718, '2003': 719, 'mail': 720, 'coordination': 721, 'frameworks': 722, 'month': 723, 'stock': 724, 'android': 725, 'linkedin': 726, 'preparation': 727, 'webdriver': 728, 'rest': 729, 'proficient': 730, 'prove': 731, 'mvc': 732, 'pre': 733, 'generation': 734, 'sla': 735, 'increase': 736, 'platforms': 737, 'extensively': 738, 'clear': 739, 'channel': 740, 'so': 741, 'extensive': 742, 'scale': 743, 'contribute': 744, 'success': 745, 'customize': 746, 'kolkata': 747, 'esb': 748, 'machine': 749, 'expert': 750, 'higher': 751, 'license': 752, 'small': 753, 'department': 754, 'hana': 755, 'secure': 756, 'countries': 757, 'scrum': 758, 'dashboard': 759, 'action': 760, 'soft': 761, 'face': 762, 'domains': 763, 'chef': 764, 'router': 765, 'digital': 766, 'progress': 767, 'people': 768, 'possess': 769, 'enhancement': 770, 'enhancements': 771, 'range': 772, 'compute': 773, '2000': 774, 'engine': 775, 'national': 776, 'feedback': 777, 'auto': 778, 'win': 779, 'transaction': 780, 'enhance': 781, 'developers': 782, 'compliance': 783, 'vendors': 784, 'show': 785, 'there': 786, 'opportunities': 787, 'specific': 788, 'metrics': 789, 'appropriate': 790, 'fi': 791, 'sr': 792, 'around': 793, 'location': 794, 'waas': 795, 'individual': 796, 'cause': 797, 'patch': 798, 'wide': 799, 'recovery': 800, 'distribute': 801, 'able': 802, 'responsibility': 803, 'hold': 804, 'first': 805, 'every': 806, 'h': 807, 'routers': 808, 'events': 809, 'insurance': 810, 'event': 811, 'deployments': 812, 'weblogic': 813, 'presentation': 814, 'ssis': 815, 'what': 816, 'value': 817, 'box': 818, 'allow': 819, 'closely': 820, 'erp': 821, 'consult': 822, 'ecc': 823, 'coimbatore': 824, 'local': 825, 'xp': 826, 'soa': 827, 'external': 828, 'attendance': 829, 'port': 830, 'sit': 831, 'opportunity': 832, 'internet': 833, 'operational': 834, 'managers': 835, 'house': 836, 'memory': 837, 'sc': 838, 'd': 839, 'course': 840, 'centre': 841, 'star': 842, 'assurance': 843, 'commerce': 844, 'organizational': 845, 'period': 846, 'screen': 847, 'dhcp': 848, 'single': 849, 'console': 850, '11g': 851, 'start': 852, 'response': 853, 'filter': 854, 'successful': 855, 'side': 856, 'gl': 857, 'very': 858, 'stakeholders': 859, 'ansible': 860, 'lan': 861, 'suite': 862, 'policies': 863, 'play': 864, 'ca': 865, 'book': 866, 'bihar': 867, 'input': 868, 'positive': 869, 'php': 870, 'effort': 871, 'root': 872, 'party': 873, 'connectivity': 874, 'proficiency': 875, 'head': 876, 'component': 877, 'spring': 878, 'tomcat': 879, 'collaborate': 880, 'image': 881, 'due': 882, '☑': 883, 'specialist': 884, 'satisfaction': 885, 'productivity': 886, 'hire': 887, 'achievements': 888, 'some': 889, 'os': 890, 'select': 891, 'shop': 892, 'motivate': 893, 'large': 894, 'certificate': 895, 'approval': 896, 'noida': 897, 'they': 898, 'insights': 899, 'focus': 900, 'grow': 901, 'n': 902, 'smooth': 903, 'vlan': 904, 'ethernet': 905, 'mpls': 906, 'establish': 907, 'mis': 908, 'gas': 909, 'excellence': 910, 'quick': 911, 'hyderbad': 912, 'sessions': 913, 'workflows': 914, 'direct': 915, 'objective': 916, 'electrical': 917, 'dr': 918, 'optimize': 919, 'usa': 920, 'firewall': 921, 'hcl': 922, 'full': 923, 't': 924, 'jquery': 925, 'intern': 926, 'know': 927, 'via': 928, 'protocol': 929, 'ip': 930, 'independently': 931, 'lab': 932, 'since': 933, 'communications': 934, 'ant': 935, 'efforts': 936, 'usage': 937, 'count': 938, 'trend': 939, '11': 940, 'close': 941, 'after': 942, 'rajasthan': 943, 'english': 944, 'print': 945, 'mysore': 946, 'provision': 947, 'verification': 948, 'smart': 949, 'ospf': 950, 'transition': 951, 'connection': 952, 'officer': 953, 'student': 954, 'hard': 955, 'manufacture': 956, 'space': 957, 'j2ee': 958, 'html5': 959, 'js': 960, 'diploma': 961, 'facilitate': 962, 'joiners': 963, 'tester': 964, '15': 965, 'come': 966, 'functionalities': 967, 'advance': 968, 'government': 969, 'interfaces': 970, 'sheet': 971, 'desktop': 972, 'candidate': 973, 'forward': 974, 'madhya': 975, 'above': 976, 'benefit': 977, 'tax': 978, 'relationship': 979, 'dynamic': 980, 'workflow': 981, 'two': 982, 'modify': 983, 'vb': 984, 'distribution': 985, 'learner': 986, 'staff': 987, 'batch': 988, 'strategic': 989, 'ui5': 990, 'r12': 991, 'provider': 992, 'central': 993, 'volume': 994, 'exit': 995, 'wan': 996, 'r2': 997, 're': 998, 'phone': 999, 'express': 1000, 'architecting': 1001, 'flexible': 1002, 'third': 1003, 'act': 1004, 'now': 1005, 'interaction': 1006, 'authentication': 1007, '\"': 1008, 'internship': 1009, 'human': 1010, 'payroll': 1011, 'hadoop': 1012, 'shift': 1013, 'escalate': 1014, 'improvements': 1015, 'orissa': 1016, 'junit': 1017, 'presentations': 1018, 'specification': 1019, 'validation': 1020, '30': 1021, 'several': 1022, 'flexibility': 1023, 'gui': 1024, 'efficiently': 1025, 'basics': 1026, 'cbse': 1027, 'powerpoint': 1028, 'stream': 1029, 'u': 1030, 'error': 1031, 'algorithms': 1032, '12': 1033, 'tata': 1034, 'blue': 1035, 'health': 1036, 'haryana': 1037, 'who': 1038, 'adobe': 1039, 'general': 1040, 'way': 1041, 'industrial': 1042, 'workshop': 1043, 'estimate': 1044, 'study': 1045, 'analyse': 1046, 'oct': 1047, 'before': 1048, 'dns': 1049, 'these': 1050, 'quickly': 1051, 'launch': 1052, 'urban': 1053, 'policy': 1054, 'return': 1055, 'jan': 1056, 'portfolio': 1057, 'light': 1058, 'pipeline': 1059, 'apple': 1060, 'situations': 1061, 'mainframe': 1062, 'subject': 1063, 'teradata': 1064, 'methods': 1065, 'disk': 1066, 'brand': 1067, 'interest': 1068, 'labs': 1069, 'capital': 1070, 'background': 1071, 'mba': 1072, 'transport': 1073, 'score': 1074, 'contract': 1075, 'scenarios': 1076, 'region': 1077, 'expense': 1078, 'export': 1079, 'format': 1080, 'your': 1081, 'budget': 1082, 'innovative': 1083, 'import': 1084, 'po': 1085, 'tier': 1086, 'inter': 1087, 'alm': 1088, 'procurement': 1089, 'operation': 1090, 'media': 1091, 'sell': 1092, 'only': 1093, 'toad': 1094, 'micro': 1095, 'desk': 1096, 'standards': 1097, 'template': 1098, 'stage': 1099, 'pattern': 1100, '♣': 1101, 'ace': 1102, 'wcf': 1103, 'committee': 1104, 'objectives': 1105, '10g': 1106, 'matter': 1107, 'peer': 1108, 'most': 1109, 'host': 1110, 'dba': 1111, 'pack': 1112, 'transactional': 1113, 'disaster': 1114, 'angular': 1115, 'dell': 1116, 'city': 1117, 'instance': 1118, 'balance': 1119, 'techniques': 1120, 'tally': 1121, 'physical': 1122, 'involvement': 1123, 'ap': 1124, 'bring': 1125, 'place': 1126, 'quarterly': 1127, 'supervisor': 1128, '20': 1129, 'step': 1130, 'segment': 1131, 'better': 1132, 'subversion': 1133, 'bsc': 1134, 'goods': 1135, 'adapt': 1136, 'hub': 1137, 'chart': 1138, 'transformation': 1139, 'inside': 1140, 'gateway': 1141, 'gurgaon': 1142, 'then': 1143, 'mahindra': 1144, 'principal': 1145, 'proper': 1146, 'organisation': 1147, 'progressive': 1148, 'fabric': 1149, 'layer': 1150, 'ipv6': 1151, 'wipro': 1152, 'eigrp': 1153, 'bgp': 1154, 'ios': 1155, 'engage': 1156, 'red': 1157, 'middle': 1158, 'formalities': 1159, 'tcp': 1160, 'kumar': 1161, 'campaign': 1162, 'hcm': 1163, 'revenue': 1164, 'placement': 1165, 'wm': 1166, 'creative': 1167, 'smartform': 1168, 'engagement': 1169, 'expansion': 1170, 'aci': 1171, 'assessment': 1172, 'pi': 1173, 'rptdesign': 1174, 'pan': 1175, 'atm': 1176, 'possible': 1177, 'initiative': 1178, 'right': 1179, 'decision': 1180, 'deadlines': 1181, 'respective': 1182, 'cse': 1183, 'jdbc': 1184, 'hibernate': 1185, 'ide': 1186, 'migrate': 1187, 'acceptance': 1188, 'top': 1189, 'graduate': 1190, 'utilization': 1191, 'allocation': 1192, 'against': 1193, 'nov': 1194, 'payments': 1195, 'backlog': 1196, 'candidates': 1197, 'putty': 1198, 'gap': 1199, 'outstanding': 1200, 'punjab': 1201, 'potential': 1202, 'dedicate': 1203, 'unify': 1204, 'sprint': 1205, 'would': 1206, 'libraries': 1207, 'tracker': 1208, 'further': 1209, 'virtual': 1210, 'jmeter': 1211, 'materials': 1212, 'priority': 1213, 'depth': 1214, 'nexus': 1215, 'scm': 1216, 'primary': 1217, 'canada': 1218, 'bar': 1219, 'st': 1220, 'optimization': 1221, 'capabilities': 1222, 'term': 1223, 'note': 1224, 'degree': 1225, 'off': 1226, 'id': 1227, 'mangalore': 1228, 'down': 1229, 'session': 1230, 'highest': 1231, 'tcl': 1232, 'pass': 1233, '11i': 1234, 'qc': 1235, 'assets': 1236, 'letter': 1237, 'reconciliation': 1238, 'rich': 1239, 'hrms': 1240, 'conversion': 1241, 'leave': 1242, 'effectiveness': 1243, 'liaise': 1244, 'ewm': 1245, 'vmware': 1246, 'remedy': 1247, 'ownership': 1248, 'srm': 1249, 'article': 1250, 'trainer': 1251, '@': 1252, 'once': 1253, \"atm's\": 1254, '2001': 1255, 'ship': 1256, 'e2e': 1257, 'mca': 1258, 'apis': 1259, 'estate': 1260, 'trainee': 1261, 'boomi': 1262, 'pick': 1263, 'ec2': 1264, 'visualization': 1265, 'how': 1266, 'should': 1267, 'bpo': 1268, 'six': 1269, 'bulk': 1270, 'k': 1271, 'fetch': 1272, 'highlight': 1273, 'browse': 1274, 'competencies': 1275, 'login': 1276, 'abilities': 1277, 'myself': 1278, 'true': 1279, 'represent': 1280, 'move': 1281, 'electronic': 1282, 'onsite': 1283, 'wise': 1284, 'participation': 1285, 'triage': 1286, 'ci': 1287, 'latest': 1288, 'australia': 1289, 'technology/tools': 1290, 'million': 1291, 'connect': 1292, 'salesforce': 1293, 'sdlc': 1294, 'stlc': 1295, 'forecast': 1296, 'home': 1297, 'publish': 1298, 'simple': 1299, 'block': 1300, 'ar': 1301, 'rule': 1302, 'consultants': 1303, 'skilled': 1304, 'initiate': 1305, 'capture': 1306, 'technological': 1307, 'relevant': 1308, 'san': 1309, 'equipment': 1310, 'device': 1311, 'speed': 1312, 'wireless': 1313, 'demand': 1314, 'premise': 1315, 'powershell': 1316, 'future': 1317, 'github': 1318, 'available': 1319, 'pay': 1320, 'legacy': 1321, 'country': 1322, 'scenario': 1323, 'onshore': 1324, 'short': 1325, 'apac': 1326, 'technically': 1327, 'container': 1328, 'assignment': 1329, 'password': 1330, 'common': 1331, 'patna': 1332, 'hat': 1333, 'collect': 1334, 'iam': 1335, 'director': 1336, 'customization': 1337, 'sector': 1338, 'asia': 1339, 'coverage': 1340, 'bound': 1341, 'multimedia': 1342, '➔': 1343, \"user's\": 1344, 'scan': 1345, 'dynamics': 1346, 'te': 1347, 'mac': 1348, 'orchestration': 1349, 'logical': 1350, 'largest': 1351, 'db2': 1352, 'permissions': 1353, 'utilities': 1354, 'american': 1355, 'window': 1356, 'backups': 1357, 'jsp': 1358, 'ftp': 1359, 'sanity': 1360, 'recognition': 1361, 'certification': 1362, 'agents': 1363, 'initiatives': 1364, 'closure': 1365, 'community': 1366, '~': 1367, 'necessary': 1368, 'goal': 1369, 'telephone': 1370, 'demonstrate': 1371, 'appreciation': 1372, 'submit': 1373, 'solid': 1374, 'cucumber': 1375, 'confluence': 1376, 'capability': 1377, 'reach': 1378, 'telecommunication': 1379, 'inbound': 1380, 'manner': 1381, 'deliveries': 1382, 'supply': 1383, 'repository': 1384, 'identity': 1385, 'discuss': 1386, 'earn': 1387, 'transform': 1388, 'gujarat': 1389, 'pl': 1390, 'qtp': 1391, 'interactive': 1392, 'utility': 1393, 'hsc': 1394, 'ssc': 1395, 'fico': 1396, 'sound': 1397, 'mm': 1398, 'lsmw': 1399, 'leader': 1400, 'automatic': 1401, 'oss': 1402, 'extend': 1403, 'organizations': 1404, 'stake': 1405, 'notifications': 1406, 'validate': 1407, 'division': 1408, 'readiness': 1409, 'billion': 1410, 'owner': 1411, 'tcs': 1412, 'r/3': 1413, 'students': 1414, 'pressure': 1415, 'trouble': 1416, 'oops': 1417, 'poc': 1418, 'sapui5': 1419, 'alv': 1420, 'ipsec': 1421, '2002': 1422, 'discoverer': 1423, 'fast': 1424, 'virtualization': 1425, 'bus': 1426, 'stories': 1427, 'b2b': 1428, 'next': 1429, 'prime': 1430, 'capacity': 1431, 'django': 1432, 'days': 1433, 'udeploy': 1434, 'prod': 1435, 'want': 1436, 'option': 1437, 'pmo': 1438, 'oil': 1439, 'respect': 1440, 'bt': 1441, '13': 1442, 'stp': 1443, 'nat': 1444, 'induction': 1445, 'com/r/soumya': 1446, 'sure': 1447, 'birt': 1448, 'jaipur': 1449, 'ls': 1450, 'arabic': 1451, 'nunit': 1452, 'aurangabad': 1453, '1st': 1454, 'nagpur': 1455, 'aia': 1456, 'trigger': 1457, 'deliverables': 1458, 'long': 1459, 'pro': 1460, 'stag': 1461, 'tune': 1462, 'configurations': 1463, 'particular': 1464, 'command': 1465, 'chain': 1466, 'f': 1467, 'visit': 1468, 'ajax': 1469, 'universe': 1470, 'perforce': 1471, '50': 1472, 'paper': 1473, 'past': 1474, 'voice': 1475, 'force': 1476, 'match': 1477, 'leaders': 1478, 'orientation': 1479, 'evaluate': 1480, 'manipal': 1481, 'serve': 1482, 'lithium': 1483, 'connector': 1484, 'presales': 1485, 'final': 1486, 'firm': 1487, 'three': 1488, 'portals': 1489, 'hardworking': 1490, 'efficient': 1491, 'suit': 1492, 'entry': 1493, 'claim': 1494, 'ideas': 1495, 'efficiency': 1496, 'rdbms': 1497, 'save': 1498, 'notification': 1499, 'text': 1500, 'leverage': 1501, 'obtain': 1502, 'failure': 1503, 'tag': 1504, 'material': 1505, 'config': 1506, 'options': 1507, 'factory': 1508, 'tableau': 1509, 'edge': 1510, 'tour': 1511, 'refresh': 1512, 'icoe': 1513, 'download': 1514, 'apex': 1515, 'versions': 1516, 'feb': 1517, 'familiar': 1518, 'securities': 1519, 'rat': 1520, 'accomplish': 1521, 'frame': 1522, 'aspects': 1523, 'payable': 1524, 'output': 1525, 'actively': 1526, 'elements': 1527, 'itil': 1528, 'mpt': 1529, 'prioritize': 1530, 'stakeholder': 1531, 'expectations': 1532, 'ordinate': 1533, 'informatica': 1534, 'guide': 1535, 'manually': 1536, 'sciences': 1537, 'others': 1538, 'pool': 1539, 'jr': 1540, 'verify': 1541, 'bcp': 1542, 'vista': 1543, 'waterfall': 1544, 'definition': 1545, 'convergys': 1546, 'combine': 1547, 'kind': 1548, 'hsbc': 1549, 'websites': 1550, '60': 1551, 'reset': 1552, 'scalable': 1553, 'publisher': 1554, 'lease': 1555, 'restore': 1556, 'proposal': 1557, 'compensation': 1558, 'saas': 1559, 'promote': 1560, 'nagarjuna': 1561, '100': 1562, 'propose': 1563, 'sale': 1564, 'discussions': 1565, 'stack': 1566, 'indicators': 1567, 'logistics': 1568, 'anna': 1569, 'junior': 1570, 'browser': 1571, 'guidelines': 1572, 'significant': 1573, 'thoughtworks': 1574, 'vpn': 1575, 'aricent': 1576, 'affect': 1577, 'mft': 1578, 'adapter': 1579, 'tfs': 1580, 'igtsc': 1581, 'anytime': 1582, 'think': 1583, 'bada': 1584, 'cspc': 1585, 'ssl': 1586, 'landscape': 1587, 'v7': 1588, 'cognos': 1589, 'technician': 1590, 'btramr0001sbb': 1591, 'educati': 1592, 'skil': 1593, 'archive': 1594, 'resume': 1595, 'vsts': 1596, 'synopsis': 1597, 'discount': 1598, 'room': 1599, 'campus': 1600, 'interview': 1601, 'bi4': 1602, 'ax': 1603, 'chat': 1604, 'backend': 1605, 'peoplesoft': 1606, 'engg': 1607, 'replication': 1608, 'adherence': 1609, 'duties': 1610, 'merchandise': 1611, 'suggest': 1612, 'rational': 1613, 'sri': 1614, 'v6': 1615, 'nehru': 1616, 'tat': 1617, 'relationships': 1618, 'timelines': 1619, 'bid': 1620, 'flexcube': 1621, 'ccna': 1622, 'person': 1623, 'determine': 1624, '16': 1625, 'comprehensive': 1626, 'authorization': 1627, 'become': 1628, 'allocate': 1629, 'buy': 1630, 'independent': 1631, 'span': 1632, 'correct': 1633, 'scalability': 1634, 'criteria': 1635, 'actual': 1636, 'lifecycle': 1637, 'assistance': 1638, 'winscp': 1639, 'matlab': 1640, 'kvm': 1641, 'mongodb': 1642, 'strength': 1643, 'bloomberg': 1644, 'flex': 1645, 'ii': 1646, 'purpose': 1647, 'investment': 1648, 'loan': 1649, 'pilani': 1650, 'thread': 1651, 'consumer': 1652, 'warranty': 1653, 'intermediate': 1654, 'holders': 1655, 'rca': 1656, 'designation': 1657, 'approvals': 1658, 'appreciate': 1659, 'grasp': 1660, 'com/r/karthik': 1661, 'engagements': 1662, 'hindi': 1663, 'dec': 1664, 'www': 1665, 'road': 1666, 'ops': 1667, 'academy': 1668, 'dedication': 1669, 'align': 1670, 'permission': 1671, 'tcp/ip': 1672, 'reference': 1673, 'json': 1674, 'layout': 1675, 'directly': 1676, 'special': 1677, 'calculate': 1678, 'l3': 1679, 'attitude': 1680, 'vivekananda': 1681, 'register': 1682, 'uft': 1683, 'cicd': 1684, 'singh': 1685, 'four': 1686, 'annual': 1687, 'computers': 1688, 'deep': 1689, 'extract': 1690, 'pr': 1691, 'stand': 1692, 'ubuntu': 1693, 'sdn': 1694, 'dojo': 1695, 'slas': 1696, 'errors': 1697, 'conference': 1698, 'bridge': 1699, 'centralize': 1700, 'photoshop': 1701, 'flash': 1702, 'proactively': 1703, 'academic': 1704, 'ce': 1705, 'nt': 1706, 'goa': 1707, 'social': 1708, 'globally': 1709, 'outbound': 1710, 'property': 1711, 'orchestrator': 1712, 'hyper': 1713, 'quote': 1714, 'amount': 1715, 'category': 1716, 'com/r/sai': 1717, 'legal': 1718, 'main': 1719, 'kt': 1720, 'jms': 1721, 'contributor': 1722, 'alcatel': 1723, 'l': 1724, 'rep': 1725, 'tp': 1726, 'avoid': 1727, 'automatically': 1728, 'steel': 1729, 'revenues': 1730, 'employ': 1731, 'otc': 1732, 'velocity': 1733, 'regions': 1734, 'french': 1735, 'crystal': 1736, 'ubs': 1737, 'london': 1738, 'tnt': 1739, 'audio': 1740, 'slp': 1741, 'prasad': 1742, 'introduce': 1743, 'madurai': 1744, 'aug': 1745, 'occur': 1746, 'rebuild': 1747, 'detect': 1748, '31': 1749, 'sync': 1750, 'helpdesk': 1751, 'label': 1752, 'hours': 1753, 'sterling': 1754, 'entity': 1755, 'salary': 1756, 'moq': 1757, 'ng': 1758, 'medical': 1759, 'openshift': 1760, 'minor': 1761, 'decisions': 1762, 'trace': 1763, 'priorities': 1764, 'multinational': 1765, 'divisions': 1766, 'guidance': 1767, 'wholesale': 1768, 'restoration': 1769, 'cpu': 1770, 'mainly': 1771, 'businesses': 1772, 'lecturer': 1773, 'y': 1774, 'york': 1775, 'spark': 1776, 's3': 1777, 'route': 1778, 'educational': 1779, 'great': 1780, 'interactions': 1781, 'ongoing': 1782, 'commit': 1783, 'read': 1784, 'tile': 1785, 'negotiation': 1786, 'among': 1787, 'mine': 1788, 'easily': 1789, 'items': 1790, \"client's\": 1791, 'dot': 1792, 'nature': 1793, 'hsrp': 1794, 'commitment': 1795, 'declare': 1796, 'carrier': 1797, 'appreciations': 1798, 'competent': 1799, 'mortgage': 1800, 'rate': 1801, 'stress': 1802, 'collection': 1803, 'bonus': 1804, 'groovy': 1805, 'comparison': 1806, 'severity': 1807, 'failures': 1808, 'fully': 1809, 'sonarqube': 1810, 'infotech': 1811, 'aim': 1812, 'simplify': 1813, 'com/r/dushyant': 1814, 'bhatt/140749dace5dc26f': 1815, 'lake': 1816, 'ssrs': 1817, 'drill': 1818, 'quiz': 1819, 'picture': 1820, 'prism': 1821, 'accessibility': 1822, '17': 1823, 'he': 1824, 'basel': 1825, 'regulations': 1826, 'much': 1827, 'station': 1828, 'undergo': 1829, 'proxy': 1830, 'undertake': 1831, 'classical': 1832, 'confidence': 1833, 'shoot': 1834, 'association': 1835, 'ledger': 1836, 'ordination': 1837, '25': 1838, 'inform': 1839, 'initial': 1840, 'workshops': 1841, 'sign': 1842, 'miss': 1843, 'upon': 1844, 'last': 1845, 'certain': 1846, 'constantly': 1847, 'concern': 1848, 'qlikview': 1849, 'button': 1850, 'respond': 1851, 'indian': 1852, 'pursue': 1853, 'certifications/licenses': 1854, \"i'm\": 1855, 'family': 1856, 'websphere': 1857, 'bitbucket': 1858, 'library': 1859, 'selection': 1860, 'circuit': 1861, 'consumption': 1862, 'desire': 1863, 'sagar': 1864, 'l2/l3': 1865, 'l2': 1866, 'ixia': 1867, 'rstp': 1868, 'snmp': 1869, 'sme': 1870, 'templates': 1871, 'uipath': 1872, '>': 1873, 'vision': 1874, 'owners': 1875, 'produce': 1876, 'lucknow': 1877, 'visio': 1878, 'al': 1879, 'sccm': 1880, 'un': 1881, 'proof': 1882, 'requisition': 1883, 'pending': 1884, 'fulfillment': 1885, 'tosca': 1886, 'sequence': 1887, 'cart': 1888, 'edit': 1889, 'customizations': 1890, 'responsive': 1891, 'currency': 1892, 'those': 1893, 'perf': 1894, 'dump': 1895, 'exception': 1896, 'acquire': 1897, 'presently': 1898, 'manpower': 1899, 'settlement': 1900, 'communicator': 1901, 'playbooks': 1902, 'experien': 1903, 'viz': 1904, 'estimations': 1905, '1998': 1906, '1999': 1907, 'throughout': 1908, 'investigate': 1909, 'supervise': 1910, '1996': 1911, 'convert': 1912, 'charge': 1913, 'healthcare': 1914, 'bp': 1915, 'mohali': 1916, 'cache': 1917, 'jose': 1918, 'anypoint': 1919, '01': 1920, 'artificial': 1921, 'exceptional': 1922, 'onboarding': 1923, 'performer': 1924, 'translation': 1925, 'controller': 1926, 'cpt': 1927, 'evc': 1928, 'bite': 1929, 'cognizant': 1930, 'implementations': 1931, 'trust': 1932, 'modules/': 1933, 'east': 1934, 'bond': 1935, \"'bapi\": 1936, 'verbal': 1937, 'blog': 1938, 'typepad': 1939, 'disparity': 1940, 'chhattisgarh': 1941, 'bpel': 1942, 'balan/97ead9542c575355': 1943, 'politically': 1944, 'heuristic': 1945, 'a*': 1946, 'algorithm': 1947, 'mawa*': 1948, 'repair': 1949, 'swift': 1950, 'runner': 1951, 'iso': 1952, 'outsource': 1953, 'workforce': 1954, 'obp': 1955, 'samsung': 1956, 'gdb': 1957, 'tizen': 1958, 'native': 1959, 'preventive': 1960, 'enthusiastic': 1961, 'wos': 1962, 'btramr0001mlm': 1963, 'queue': 1964, 'kronos': 1965, 'anchor': 1966, 'citrix': 1967, 'loss': 1968, 'printers': 1969, 'essential': 1970, 'edu': 1971, 'cation': 1972, 'police': 1973, 'continuity': 1974, 'akamai': 1975, 'synthetic': 1976, 'broker': 1977, 'protractor': 1978, 'copy': 1979, 'approve': 1980, 'comp': 1981, 'hostel': 1982, 'leisure': 1983, 'allegro': 1984, 'pentium': 1985, 'desktops': 1986, 'ways': 1987, '10th': 1988, 'iit': 1989, 'cdac': 1990, 'cobol': 1991, 'relational': 1992, 'agent': 1993, 'without': 1994, 'redmond': 1995, 'standardize': 1996, 'worldwide': 1997, '22': 1998, 'medium': 1999, 'css3': 2000, 'netbeans': 2001, 'restful': 2002, 'capable': 2003, 'individually': 2004, 'professionals': 2005, 'coach': 2006, 'personality': 2007, 'accuracy': 2008, 'sigma': 2009, 'mar': 2010, 'situation': 2011, 'translate': 2012, '000': 2013, 'average': 2014, 'principles': 2015, 'analysts': 2016, 'explore': 2017, 'sincere': 2018, 'teach': 2019, 'worker': 2020, 'hybrid': 2021, 'bdd': 2022, 'barclays': 2023, 'ask': 2024, 'question': 2025, 'definitions': 2026, '14': 2027, 'tools/environments': 2028, 'containment': 2029, 'expect': 2030, 'attempt': 2031, 'menu': 2032, 'smoke': 2033, 'mechanisms': 2034, 'sun': 2035, 'compatibility': 2036, 'recent': 2037, 'prompt': 2038, 'broad': 2039, 'cover': 2040, 'artifacts': 2041, 'break': 2042, 'hereby': 2043, 'containers': 2044, 'static': 2045, 'loyalty': 2046, 'xbox': 2047, 'plus': 2048, 'registration': 2049, 'second': 2050, 'lend': 2051, 'jdeveloper': 2052, 'consultancy': 2053, 'osmania': 2054, 'statistics': 2055, 'whether': 2056, 'attack': 2057, '18': 2058, 'street': 2059, \"world's\": 2060, 'completion': 2061, 'section': 2062, 'procedure': 2063, 'achievement': 2064, 'supervision': 2065, 'expose': 2066, 'birla': 2067, 'debugger': 2068, 'hot': 2069, '03': 2070, 'acharya': 2071, 'specialty': 2072, 'auditor': 2073, 'assistant': 2074, 'adept': 2075, 'periodically': 2076, 'kpi': 2077, 'foundation': 2078, 'sec': 2079, 'scoping': 2080, 'mitigation': 2081, 'direction': 2082, 'fire': 2083, 'addition': 2084, '3+': 2085, 'em7': 2086, 'solver': 2087, 'california': 2088, 'ca7': 2089, 'stipulate': 2090, 'hdl': 2091, 'determination': 2092, 'dbms': 2093, 'official': 2094, 'bapi': 2095, 'bdc': 2096, 'dhule': 2097, 'atlassian': 2098, 'redhat': 2099, 'streamline': 2100, 'slave': 2101, 'registry': 2102, 'mention': 2103, 'se': 2104, 'browsers': 2105, 'odata': 2106, 'fiori': 2107, 'grid': 2108, 'feel': 2109, 'water': 2110, 'found': 2111, 'extension': 2112, \"customer's\": 2113, 'productive': 2114, '7600': 2115, 'cdets': 2116, 'bed': 2117, 'clean': 2118, 'merge': 2119, 'governance': 2120, '2+': 2121, 'sv': 2122, 'emergency': 2123, 'ad': 2124, 'personnel': 2125, 'zone': 2126, 'modification': 2127, 'easy': 2128, 'bootstrap': 2129, 'consist': 2130, 'later': 2131, 'until': 2132, 'completely': 2133, 'metadata': 2134, '24/7': 2135, 'kintana': 2136, 'duration/size': 2137, 'compare': 2138, 'aid': 2139, 'influence': 2140, 'recruit': 2141, '\\\\': 2142, 'series': 2143, 'north': 2144, 'conventions': 2145, 'informatics': 2146, 'bpm': 2147, 'alternatives': 2148, 'british': 2149, 'motivation': 2150, 'obiee': 2151, '12c': 2152, 'designers': 2153, 'black': 2154, 'facility': 2155, 'bin': 2156, 'bo': 2157, 'pp': 2158, 'scom': 2159, 'plc': 2160, 'aqc': 2161, 'clm': 2162, 'signal': 2163, 'thorough': 2164, 'scheme': 2165, 'reason': 2166, 'age': 2167, 'compile': 2168, 'concurrent': 2169, 'demo': 2170, 'rally': 2171, 'resilient': 2172, 'winner': 2173, 'marketo': 2174, 'regional': 2175, 'south': 2176, 'conferences': 2177, 'distributors': 2178, 'domestic': 2179, 'ring': 2180, 'ucsd': 2181, '802': 2182, 'metro': 2183, 'quotation': 2184, 'she': 2185, 'novo': 2186, 'nordisk': 2187, 'arcelormittal': 2188, 'operator': 2189, 'cent': 2190, 'subsidiary': 2191, 'pm': 2192, 'diabetes': 2193, 'millions': 2194, 'ore': 2195, 'certifications': 2196, 'recently': 2197, '3rd': 2198, 'adapters': 2199, 'administrative': 2200, 'hospitality': 2201, 'octopus': 2202, 'l1': 2203, 'pertain': 2204, 'recognize': 2205, 'o365': 2206, 'curricular': 2207, 'women': 2208, 'calicut': 2209, 'sslc': 2210, \"'\": 2211, 'bhubaneshwar': 2212, 'workbench': 2213, 'peak': 2214, 'rms': 2215, 'transportation': 2216, 'node': 2217, 'extra': 2218, 'ebs': 2219, 'cheque': 2220, 'thirdeye': 2221, 'nos': 2222, 'club': 2223, 'formulate': 2224, 'uttarakhand': 2225, 'bw': 2226, 'ehp': 2227, 'automatable': 2228, 'labor': 2229, 'agreements': 2230, '24*7': 2231, 'too': 2232, 'infopath': 2233, 'teleperformance': 2234, '//': 2235, 'income': 2236, 'emc': 2237, 'lean': 2238, 'nas': 2239, 'chief': 2240, 'outside': 2241, 'wordpress': 2242, 'specflow': 2243, 'fluent': 2244, 'postal': 2245, 'sdet': 2246, 'offline': 2247, 'elastic': 2248, 'overview': 2249, 'arrange': 2250, 'cd': 2251, 'pharmaceuticals': 2252, 'vdc': 2253, 'kyc': 2254, 'timescale': 2255, 'amravati': 2256, 'joinee': 2257, 'pcb': 2258, 'ids': 2259, 'foundry': 2260, '⇨': 2261, \"company's\": 2262, 'bot': 2263, '12th': 2264, 'mathematics': 2265, 'things': 2266, 'honest': 2267, 'yadav': 2268, 'suppliers': 2269, 'profiler': 2270, 'headquarter': 2271, 'consistency': 2272, 'lower': 2273, 'individuals': 2274, 'gandhi': 2275, 'w': 2276, 'sem': 2277, 'servlet': 2278, 'strut': 2279, 'filezilla': 2280, 'scala': 2281, 'sqs': 2282, 'prevention': 2283, 'iot': 2284, 'locations': 2285, 'author': 2286, 'profit': 2287, 'ethics': 2288, 'sectors': 2289, 'floor': 2290, 'emea': 2291, 'driver': 2292, 'rise': 2293, 'venkateswara': 2294, 'processor': 2295, 'brahmapur': 2296, 'italent': 2297, 'plugins': 2298, 'accomplishment': 2299, '4j': 2300, 'generator': 2301, 'jawaharlal': 2302, 'proposals': 2303, 'quotations': 2304, 'testers': 2305, 'competitive': 2306, 'voip': 2307, 'jain': 2308, 'clinical': 2309, 'invalid': 2310, 'govt': 2311, 'tdd': 2312, 'testng': 2313, 'you': 2314, \"it's\": 2315, 'scratch': 2316, 'retrieve': 2317, 'see': 2318, 'dialog': 2319, 'gain': 2320, 'circulate': 2321, 'telecommunications': 2322, \"bachelor's\": 2323, 'postman': 2324, '5+': 2325, 'puppet': 2326, 'ssh': 2327, 'artifactory': 2328, 'declaration': 2329, 'statements': 2330, 'departments': 2331, 'strengths': 2332, 'discipline': 2333, 'snow': 2334, 'index': 2335, 'bing': 2336, 'top/bottom': 2337, 'stats': 2338, 'cosmos': 2339, 'acknowledgement': 2340, 'payload': 2341, '24': 2342, 'decide': 2343, 'statistical': 2344, 'embed': 2345, 'predictive': 2346, 'predict': 2347, 'sample': 2348, 'socket': 2349, 'providers': 2350, 'continual': 2351, 'investments': 2352, 'put': 2353, 'guard': 2354, 'collateral': 2355, '9i': 2356, 'bean': 2357, 'entries': 2358, 'adf': 2359, 'army': 2360, 'angularjs': 2361, 'professionally': 2362, 'institution': 2363, 'saraswati': 2364, 'compilation': 2365, 'finalize': 2366, 'g/l': 2367, 'receivable': 2368, 'together': 2369, 'watch': 2370, 'adhere': 2371, 'low': 2372, 'dealers': 2373, 'cab': 2374, 'velammal': 2375, 'destructive': 2376, 'protection': 2377, 'faster': 2378, 'recover': 2379, 'qualify': 2380, 'relations': 2381, 'mass': 2382, '30th': 2383, 'sort': 2384, 'graph': 2385, 'consecutive': 2386, 'sender': 2387, 'scheduler': 2388, 'workload': 2389, \"sla's\": 2390, 'connections': 2391, 'visvesvaraya': 2392, 'sense': 2393, 'expand': 2394, 'lotus': 2395, 'rfc': 2396, 'creativity': 2397, 'european': 2398, 'mark': 2399, 'arrow': 2400, 'equip': 2401, 'method': 2402, 'additionally': 2403, 'pull': 2404, 'innovation': 2405, 'delete': 2406, 'finish': 2407, 'rip': 2408, 'perl': 2409, 'telnet': 2410, 'dubai': 2411, 'qos': 2412, 'german': 2413, 'sep': 2414, 'pu': 2415, 'timeframe': 2416, 'old': 2417, 'activation': 2418, 'charter': 2419, 'entertainment': 2420, 'enablement': 2421, 'firmware': 2422, 'newly': 2423, 'convent': 2424, 'insight': 2425, 'wireshark': 2426, 'gupta': 2427, 'always': 2428, 'fresher': 2429, 'ghaziabad': 2430, 'parameters': 2431, 'accordingly': 2432, 'architectural': 2433, 'cater': 2434, '7+': 2435, 'truck': 2436, 'architected': 2437, 'organise': 2438, 'com/r/nitin': 2439, 'separate': 2440, 'passionate': 2441, 'portfolios': 2442, 'construction': 2443, '//pramodprakash': 2444, 'vijaya': 2445, 'widget': 2446, 'kitchen': 2447, 'wily': 2448, 'infra': 2449, 'p2': 2450, 'fail': 2451, 'mode': 2452, 'fa': 2453, 'olfm': 2454, 'history': 2455, 'dollar': 2456, 'plsql': 2457, 'johnson': 2458, 'dewas': 2459, 'appraisal': 2460, 'punch': 2461, 'pf': 2462, 'programme': 2463, '98': 2464, 'quota': 2465, 'tftp': 2466, 'assemble': 2467, 'drivers': 2468, 'grab': 2469, 'pycharm': 2470, 'com/r/rahul': 2471, '53': 2472, 'rds': 2473, 'evaluation': 2474, 'diagnose': 2475, 'facebook': 2476, 'bucket': 2477, 'talent': 2478, '1997': 2479, 'optimal': 2480, 'odi': 2481, 'ariba': 2482, 'discovery': 2483, 'superiors': 2484, 'journey': 2485, 'info': 2486, 'unique': 2487, 'blueprint': 2488, 'com/r/ravi': 2489, 'scs': 2490, 'mon': 2491, 'specify': 2492, 'scsm': 2493, 'threat': 2494, 'ge': 2495, 'synchronization': 2496, 'motor': 2497, 'minimal': 2498, 'sai': 2499, 'duty': 2500, 'instrument': 2501, 'mechanism': 2502, 'proxies': 2503, 'arise': 2504, 'ri': 2505, 'vivek': 2506, 'mitigate': 2507, 'valuable': 2508, 'cities': 2509, 'recur': 2510, 'reliable': 2511, 'ether': 2512, 'minimum': 2513, 'outages': 2514, 'vtp': 2515, 'avs': 2516, 'esxi': 2517, 'p2mp': 2518, 'centric': 2519, 'globe': 2520, 'federal': 2521, 'mogul': 2522, 'mormugao': 2523, 'badi': 2524, 'quarter': 2525, 'condition': 2526, 'routine': 2527, \"create'\": 2528, 'roll': 2529, '35': 2530, 'origin': 2531, 'ut': 2532, 'twitter': 2533, 'recognitions': 2534, 'blogging': 2535, 'satisfy': 2536, 'cloudbees': 2537, 'tiruchchirappalli': 2538, 'soumya': 2539, 'balan': 2540, 'but': 2541, 'sophisticate': 2542, 'aspire': 2543, 'robotics': 2544, 'pacific': 2545, 'sub': 2546, 'historical': 2547, 'genius': 2548, 'forum': 2549, 'redis': 2550, 'cutover': 2551, 'milestones': 2552, 'incremental': 2553, 'lot': 2554, 'clarify': 2555, 'syam': 2556, 'devendla': 2557, 'stl': 2558, 'vs': 2559, 'klocwork': 2560, 'vss': 2561, 'collector': 2562, 'matrix': 2563, 'renewals': 2564, 'chicago': 2565, 'programmer': 2566, 'matriculation': 2567, 'solaris': 2568, 'remove': 2569, \"organization's\": 2570, 'jun': 2571, 'ats': 2572, 'formerly': 2573, \"cisco's\": 2574, 'bombardier': 2575, 'wo': 2576, 'logo': 2577, 'type=1': 2578, 'biem': 2579, '+': 2580, 'topic': 2581, 'brainstorm': 2582, 'sld': 2583, 'idoc': 2584, 'cbs': 2585, 'wpf': 2586, 'welfare': 2587, 'collections': 2588, 'csat': 2589, 'mic': 2590, 'rosoft': 2591, 'frontend': 2592, 'bike': 2593, 'jci': 2594, 'aspect': 2595, 'paas': 2596, 'com/': 2597, 'msdn': 2598, 'firefighting': 2599, 'bcweb': 2600, 'percentage': 2601, 'promotion': 2602, 'blob/table': 2603, 'technic': 2604, 'cmc': 2605, 'gps': 2606, 'g4s': 2607, 'spoc': 2608, 'counsel': 2609, 'agency': 2610, 'genpact': 2611, 'representative': 2612, 'iii': 2613, 'saurabh': 2614, 'com/r/saurabh': 2615, 'cuddapah': 2616, '2nd': 2617, 'officials': 2618, 'affiliate': 2619, 'gokul': 2620, 'ola': 2621, 'itunes': 2622, 'hinjewadi': 2623, 'courier': 2624, 'clock': 2625, 'diseases': 2626, 'cell': 2627, '365': 2628, 'oceanic': 2629, 'calculation': 2630, 'cdb': 2631, 'autocad': 2632, 'georgia': 2633, 'atlanta': 2634, 'vi': 2635, 'ddd': 2636, 'com/r/arpit': 2637, '#project': 2638, 'hari': 2639, 'crd': 2640, 'bits': 2641, 'pc': 2642, 'fte’s': 2643, 'com/r/shivam': 2644, 'mostly': 2645, 'tb': 2646, 'resident': 2647, 'sipl': 2648, 'negative': 2649, 'hubli': 2650, 'modern': 2651, 'iiit': 2652, 'wish': 2653, 'conceptual': 2654, 'consistently': 2655, 'kanpur': 2656, 'dac': 2657, 'shivaji': 2658, 'kolhapur': 2659, 'com/r/akhil': 2660, 'systematic': 2661, 'intervention': 2662, 'important': 2663, '40': 2664, 'servicenow': 2665, 'jcl': 2666, 'mirror': 2667, 'wizard': 2668, 'dbcc': 2669, 'tight': 2670, 'itsm': 2671, 'migrations': 2672, 'previous': 2673, 'typically': 2674, 'com/r/ananya': 2675, 'chavan/738779ab71971a96': 2676, 'std': 2677, 'j': 2678, 'hotel': 2679, 'rao': 2680, 'detection': 2681, 'natural': 2682, 'air': 2683, 'automobile': 2684, '2019': 2685, 'pmp': 2686, 'registrations': 2687, 'advisors': 2688, 'complaints': 2689, 'sop': 2690, 'belt': 2691, '|': 2692, 'visionplus': 2693, 'replacement': 2694, 'catia': 2695, 'answer': 2696, 'mfc': 2697, 'council': 2698, 'atmosphere': 2699, 'willingness': 2700, 'accept': 2701, 'qualifications': 2702, 'doeacc': 2703, 'kunam': 2704, 'eloqua': 2705, 'connectors': 2706, \"'17\": 2707, 'parse': 2708, 'experts': 2709, 'recruiter': 2710, 'zoho': 2711, 'ece': 2712, 'purview': 2713, 'liaison': 2714, 'sharma': 2715, 'frequent': 2716, 'guru': 2717, 'nurture': 2718, 'nagar': 2719, 'teacher': 2720, 'adverse': 2721, 'ae': 2722, 'signature': 2723, 'numerous': 2724, 'dash': 2725, 'qualitycenter': 2726, 'confidential': 2727, 'appointments': 2728, '21': 2729, 'away': 2730, 'suggestions': 2731, 'vast': 2732, 'saudi': 2733, 'arabia': 2734, 'testcases': 2735, 'servlets': 2736, 'concept': 2737, 'grails': 2738, 'clarifications': 2739, 'mongo': 2740, 'reddy': 2741, 'credentials': 2742, 'administer': 2743, 'intuitive': 2744, 'conflict': 2745, 'repositories': 2746, 'pipelines': 2747, 'style': 2748, 'tirupati': 2749, 'bca': 2750, 'bharati': 2751, 'keen': 2752, 'ease': 2753, 'confident': 2754, 'bhatt': 2755, 'schema': 2756, 'minutes': 2757, 'biztalk': 2758, 'com/r/govardhana': 2759, 'lang': 2760, 'webservice': 2761, 'oc4j': 2762, 'com/r/harini': 2763, 'komaravelli/2659eee82e435d1b': 2764, 'yrs': 2765, 'energy': 2766, 'petroleum': 2767, '❑': 2768, 'nosql': 2769, 'publications': 2770, 'dataset': 2771, 'patient': 2772, 'malicious': 2773, 'com/r/ijas': 2774, 'nizamuddin/6748d77f76f94eed': 2775, 'stability': 2776, 'incorporate': 2777, \"'s\": 2778, 'maximum': 2779, 'recommendations': 2780, 'cu': 2781, 'repo': 2782, 'zero': 2783, 'excite': 2784, 'annotation': 2785, 'turn': 2786, 'ia': 2787, 'chemistry': 2788, 'military': 2789, 'com/r/jay': 2790, 'madhavi/1e7d0305af766bf6': 2791, 'cars': 2792, 'asap': 2793, 'verse': 2794, 'aptitude': 2795, 'listener': 2796, 'fashion': 2797, 'fleet': 2798, 'com/r/jyotirbindu': 2799, 'patnaik/77e3ceda47fbb7e4': 2800, 'superior': 2801, 'widely': 2802, 'professionalism': 2803, 'notify': 2804, 'unplanned': 2805, 'downtimes': 2806, 'minimize': 2807, 'com/r/karthihayini': 2808, 'c/627254c443836b3c': 2809, 'consistent': 2810, 'karthik': 2811, 'es': 2812, 'premier': 2813, 'accountable': 2814, 'roadmap': 2815, 'fiscal': 2816, 'retirement': 2817, 'downstream': 2818, 'regulation': 2819, 'fund': 2820, 'sse': 2821, 'rfp': 2822, 'statement': 2823, 'latam': 2824, 'gate': 2825, 'checklist': 2826, 'turnover': 2827, \"years'\": 2828, 'commitments': 2829, 'pfcg': 2830, 'cr': 2831, 'grant': 2832, 'privilege': 2833, 'restrict': 2834, 'removal': 2835, 'lovely': 2836, 'com/r/kasturika': 2837, 'borah/9e71468914b38ee8': 2838, 'fidelity': 2839, 'vlookup': 2840, 'salem': 2841, 'dependent': 2842, 'erode': 2843, 'simulation': 2844, 'uart': 2845, 'choudhary': 2846, 'com/r/khushboo': 2847, 'karnal': 2848, 'nagios': 2849, 'management/administration': 2850, 'crowd': 2851, 'kibana': 2852, 'mechanical': 2853, 'folders': 2854, 'lan/wan': 2855, 'com/r/lakshika': 2856, 'neelakshi/27b31f359c52ef76': 2857, 'airbus': 2858, 'aeronautical': 2859, 'annotate': 2860, 'specifically': 2861, 'laptop': 2862, 'plug': 2863, 'ie': 2864, 'measurement': 2865, 'crop': 2866, 'zoom': 2867, 'mnc': 2868, 'controllers': 2869, 'hence': 2870, 'viewer': 2871, 'dictionary': 2872, 'bind': 2873, 'navigation': 2874, 'tab': 2875, 'motorcycle': 2876, 'pocs': 2877, 'instrumentation': 2878, 'anantapur': 2879, 'com/r/madas': 2880, 'peddaiah/557069069de72b14': 2881, 'firefox': 2882, 'hpqc': 2883, 'hospital': 2884, 'com/r/madhuri': 2885, 'sripathi/04a52a262175111c': 2886, 'lacp': 2887, 'pagent': 2888, 'l2vpn': 2889, 'l3vpn': 2890, 'multicast': 2891, 'layer3': 2892, 'vodafone': 2893, 'sev1': 2894, 'sev2': 2895, 'sev3': 2896, 'enrich': 2897, 'academia': 2898, 'acquisition': 2899, 'synchronize': 2900, 'receivables': 2901, 'accomplishments': 2902, 'retrieval': 2903, 'robotic': 2904, 'alm/qc': 2905, 'iptv': 2906, 'agree': 2907, 'xii': 2908, 'amdocs': 2909, 'nokia': 2910, 'quest': 2911, 'com/r/mohamed': 2912, 'osi': 2913, 'vice': 2914, 'versa': 2915, 'tennis': 2916, 'navas': 2917, 'koya': 2918, '74': 2919, 'com/r/nazish': 2920, 'depend': 2921, 'routines': 2922, 'remittance': 2923, 'abstract': 2924, 'orchestrate': 2925, 'compromise': 2926, 'corporations': 2927, 'com/r/nikhileshkumar': 2928, 'reverse': 2929, 'sku': 2930, 'fresh': 2931, 'cold': 2932, 'seller': 2933, 'celery': 2934, 'employer': 2935, 'upgradation': 2936, 'tr': 2937, 'contain': 2938, 'empty': 2939, 'panel': 2940, 'pramodprakash': 2941, 'destination': 2942, 'showcase': 2943, 'btech': 2944, 'collaborator': 2945, 'menus': 2946, 'universal': 2947, 'com/r/prakriti': 2948, 'shaurya/5339383f9294887e': 2949, 'com/r/prashanth': 2950, 'introscope': 2951, 'managenow': 2952, 'qualification': 2953, 'ware': 2954, '9i/10g': 2955, '6i/10g': 2956, 'caterpillar': 2957, 'months/3': 2958, '07': 2959, 'overtime': 2960, 'yearly': 2961, 'motivational': 2962, 'competence': 2963, 'ample': 2964, '2950': 2965, '2600': 2966, 'isl': 2967, 'firewalls': 2968, 'corel': 2969, 'draw': 2970, 'com/r/puneet': 2971, 'vpc': 2972, 'elb': 2973, 'sns': 2974, 'geo': 2975, 'pega': 2976, 'recommend': 2977, 'survey': 2978, 'adwords': 2979, 'marketer': 2980, 'electric': 2981, 'collaboration': 2982, 'spirit': 2983, 'resolutions': 2984, '1995': 2985, 'shore': 2986, 'texas': 2987, 'com/r/ramesh': 2988, \"software's\": 2989, 'prospect': 2990, 'upselling': 2991, 'cst': 2992, 'openreach': 2993, 'reproduce': 2994, 'p1': 2995, 'rf': 2996, 'partial': 2997, 'plm': 2998, 'timeline': 2999, 'xi': 3000, 'commercial': 3001, '/2012': 3002, 'appliances': 3003, 'bidar': 3004, 'specialize': 3005, 'seminar': 3006, 'dc': 3007, 'aetna': 3008, 'ncr': 3009, 'sim': 3010, 'serial': 3011, 'basically': 3012, 'outgo': 3013, 'mulesoft': 3014, 'raml': 3015, 'proactive': 3016, 'urelease': 3017, 'groom': 3018, 'asynchronous': 3019, 'oauth': 3020, 'investigation': 3021, 'brazil': 3022, 'sustain': 3023, 'calculations': 3024, 'xslt': 3025, 'singleton': 3026, 'ejb': 3027, 'remarkable': 3028, 'diverse': 3029, 'interfacing': 3030, 'mid': 3031, 'com/r/sameer': 3032, 'kujur/0771f65bfa7aff96': 3033, 'com/r/samyuktha': 3034, 'gocd': 3035, 'studios': 3036, 'revamp': 3037, 'presence': 3038, 'inquiries': 3039, 'china': 3040, 'recognise': 3041, 'america': 3042, 'accent': 3043, 'revert': 3044, 'gre': 3045, 'tunnel': 3046, 'mstp': 3047, 'dot1q': 3048, 'checkpoint': 3049, 'vrrp': 3050, 'glbp': 3051, 'diversify': 3052, 'downgrade': 3053, 'apic': 3054, 'leaf': 3055, 'spine': 3056, '5/6': 3057, 'vm': 3058, 'ctp': 3059, '1q': 3060, 'protect': 3061, 'germany': 3062, 'mib': 3063, '4710': 3064, 'white': 3065, '3550': 3066, 'com/r/shaheen': 3067, 'etisalat': 3068, 'safe': 3069, 'automotive': 3070, 'opco': 3071, '\"bbp': 3072, 'fill': 3073, 'foreign': 3074, 'weeks': 3075, 'outcome': 3076, 'cargo': 3077, 'rank': 3078, 'pos': 3079, 'plot': 3080, 'turnaround': 3081, 'rental': 3082, 'idocs': 3083, 'com/r/shreyanshu': 3084, 'gupta/6bd08d76c29d63c7': 3085, 'amazonbookreview': 3086, 'art': 3087, 'chauhan': 3088, 'com/r/shrishti': 3089, 'chauhan/89d7feb4b3957524': 3090, 'doo/gop': 3091, 'diagram': 3092, 'documentations': 3093, 'com/r/sivaganesh': 3094, 'selvakumar/2d20204ef7c22049': 3095, 'nant': 3096, 'com/r/snehal': 3097, 'jadhav/005e1ab800b4cb42': 3098, 'sulthan': 3099, 'correspondence': 3100, 'solicit': 3101, 'advantage': 3102, '6th': 3103, 'pondicherry': 3104, 'btec': 3105, 'hnc': 3106, 'aviation': 3107, 'frankfinn': 3108, 'airhostess': 3109, 'balan/8c7fbb9917935f20': 3110, 'com/r/sowmya': 3111, 'constant': 3112, 'com/r/srabani': 3113, 'das/152269fb5b986c26': 3114, 'bobj': 3115, 'categories': 3116, 'units': 3117, 'behalf': 3118, 'siebel': 3119, 'ssi': 3120, 'variety': 3121, 'rpm': 3122, 'om': 3123, 'robot': 3124, 'context': 3125, 'tracelink': 3126, \"team's\": 3127, 'alignment': 3128, 'redshift': 3129, 'baselines': 3130, 'preparation/execution': 3131, 'msc': 3132, 'keybank': 3133, 'ebso': 3134, '8+': 3135, 'oto': 3136, 'organisational': 3137, 'a/c': 3138, 'depreciation': 3139, 'rectify': 3140, 'acknowledge': 3141, 'com/r/syam': 3142, 'hdfs': 3143, '32': 3144, 'yarn': 3145, 'hive': 3146, 'shp': 3147, 'windowsmobile5': 3148, 'clearly': 3149, 'ethereal': 3150, 'ioc': 3151, 'nessus': 3152, 'q': 3153, 'airtel': 3154, 'roorkee': 3155, 'krishna': 3156, 'com/r/vijayalakshmi': 3157, 'printer': 3158, 'phantom': 3159, 'intel': 3160, 'malware': 3161, 'passwords': 3162, '300+': 3163, 'com/r/yasothai': 3164, 'hld': 3165, 'aetest': 3166, 'wexp': 3167, 'smb': 3168, 'tims': 3169, 'offices': 3170, 'accelerate': 3171, 'waes': 3172, 'tutorial': 3173, 'hover': 3174, 'dialogs': 3175, 'mbo': 3176, 'reports/query': 3177, 'mif': 3178, 'crew': 3179, 'installation/upgradation': 3180, 'ambitious': 3181, 'behavior': 3182, 'setbacks': 3183, 'deadline': 3184, 'differ': 3185, 'item': 3186, 'default': 3187, 'something': 3188, 'precision': 3189, 'hrs': 3190, 'prevent': 3191, 'divide': 3192, 'graphical': 3193, 'axis': 3194, 'prioritization': 3195, 'factor': 3196, 'employment': 3197, 'sf': 3198, 'nintex': 3199, 'useful': 3200, 'pivot': 3201, 'graphic': 3202, 'dun': 3203, 'hack': 3204, 'techno': 3205, 'logy': 3206, 'trichur': 3207, 'traders': 3208, 'com/r/viny': 3209, 'khandelwal/02e488f477e2f5bc': 3210, 'camp': 3211, 'datacenter': 3212, 'faridabad': 3213, 'consolidate': 3214, 'calendar': 3215, 'downtime': 3216, 'ducation': 3217, 'lear': 3218, 'wherein': 3219, 'msit': 3220, 'heal': 3221, '//girishthegeek': 3222, 'consider': 3223, 'cdns': 3224, 'assertions': 3225, 'federation': 3226, 'cis': 3227, 'vlit': 3228, 'authenticate': 3229, 'why': 3230, 'tenant': 3231, 'usps': 3232, 'recycle': 3233, 'view/share': 3234, 'cio': 3235, 'compete': 3236, 'pilot': 3237, 'managements': 3238, 'itineraries': 3239, 'rl': 3240, 'com/r/ganesh': 3241, 'worth': 3242, 'xamarin': 3243, 'enginee': 3244, 'ma': 3245, 'cricket': 3246, 'bhandari/c9002fa44d6760bd': 3247, 'ist': 3248, 'telstra': 3249, 'fundamentals': 3250, 'mutual': 3251, 'cs': 3252, 'ojt': 3253, 'nalyst': 3254, 'antivirus': 3255, 'th': 3256, 'ahead': 3257, 'epg': 3258, 'subsequently': 3259, 'establishment': 3260, 'hvac': 3261, 'com/r/chhaya': 3262, 'prabhale/99700a3a95e3ccd7': 3263, 'datawarehouse': 3264, 'v/283106d88eb4649c': 3265, 'na': 3266, 'com/r/mohammed': 3267, 'murtuza/0cdc3284bf1bbeab': 3268, 'huddle': 3269, 'thus': 3270, 'technicians': 3271, 'blackberry': 3272, 'ty': 3273, 'beta': 3274, 'visakhapatnam': 3275, 'com/r/krishna': 3276, 'magadh': 3277, 'univercity': 3278, 'pradeep': 3279, 'com/r/paul': 3280, 'rajiv/2bd46ce0f01fad54': 3281, 'sanction': 3282, 'periyar': 3283, 'visa': 3284, 'expe': 3285, 'rience': 3286, 'advocacy': 3287, 'bad': 3288, 'effect': 3289, 'game': 3290, 'er': 3291, 'retention': 3292, 'measure': 3293, 'clcs': 3294, 'reimbursement': 3295, 'boy': 3296, \"db's\": 3297, 'wi': 3298, 'relocation': 3299, 'com/r/siddhartha': 3300, 'colleagues': 3301, 'music': 3302, 'ramakrishna': 3303, 'com/r/ramakrishna': 3304, 'rao/0b57f5f9d35b9e5c': 3305, 'maturity': 3306, 'hpe': 3307, 'arm': 3308, 'sqlserver': 3309, 'crucible': 3310, 'asg': 3311, 'algorythm': 3312, 'eit': 3313, '#1': 3314, 'tenure': 3315, 'com/r/kandrapu': 3316, 'reddy/69a289269ce9e1d1': 3317, 'flight': 3318, 'implant': 3319, 'amadeus': 3320, 'render': 3321, 'iata': 3322, 'akbar': 3323, 'prestigious': 3324, 'com/r/vineeth': 3325, 'seminars': 3326, 'dts': 3327, 'bharathiar': 3328, 'cdd': 3329, 'agreement': 3330, 'foreclosure': 3331, 'authority': 3332, 'centralization': 3333, 'com/r/suresh': 3334, 'kanagala/04b36892f9d2e2eb': 3335, 'maths': 3336, 'vacancy': 3337, 'arrangements': 3338, 'celebrations': 3339, 'com/r/somanath': 3340, 'com/r/ashish': 3341, 'indoriya/84f99c99ebe940be': 3342, 'bhilai': 3343, 'ic': 3344, 'shendra': 3345, 'midc': 3346, 'tower': 3347, 'com/r/ajay': 3348, 'elango/3c79ad143578c3f2': 3349, 'southern': 3350, 'simulink': 3351, 'analyzer': 3352, '3d': 3353, 'trello': 3354, 'clearcase': 3355, 'valgrind': 3356, 'totalview': 3357, 'labview': 3358, 'anz': 3359, 'gst': 3360, 'com/r/madhava': 3361, 'konjeti/964a277f6ace570c': 3362, 'mall': 3363, 'com/r/shreya': 3364, 'nologies': 3365, 'meenalochani': 3366, 'kondya': 3367, 'com/r/meenalochani': 3368, 'kondya/81e406bd03e7a6d2': 3369, '+91': 3370, 'ado': 3371, 'psg': 3372, 'xen': 3373, 'pivotal': 3374, 'teamcity': 3375, 'ratio': 3376, 'australian': 3377, 'accountant': 3378, 'tripura': 3379, 'memorial': 3380, 'com/r/k': 3381, 'siddharth/0023411a049a1441': 3382, 'indraprastha': 3383, 'vl': 3384, 'com/r/prasanna': 3385, 'ignatius/1404633e9449f641': 3386, 'allahabad': 3387, 'xs': 3388, 'vba': 3389, 'lss': 3390, 'notebooks': 3391, 'totipotentsc': 3392, 'fortis': 3393, 'interlink': 3394, 'micronutrient': 3395, 'com/r/valarmathi': 3396, 'jpm': 3397, 'reconciliations': 3398, 'colt': 3399, 'cdr': 3400, 'com/r/abhishek': 3401, 'jha/10e7a8cb732bc43a': 3402, 'com/r/afreen': 3403, 'jamadar/8baf379b705e37c6': 3404, 'believe': 3405, 'traits': 3406, 'walmart': 3407, 'repeat': 3408, 'issues/': 3409, 'retailer': 3410, 'polemaina/f6931801c51c63b1': 3411, 'anurag': 3412, 'unisys': 3413, 'com/r/alok': 3414, 'khandai/5be849e443b8f467': 3415, 'replications': 3416, 'modes': 3417, 'integrity': 3418, 'sight': 3419, 'washington': 3420, 'consolidation': 3421, 'failover': 3422, 'costco': 3423, 'bottleneck': 3424, 'i/o': 3425, 'membership': 3426, 'everyday': 3427, 'indira': 3428, 'mssql': 3429, 'tutorials': 3430, '11th': 3431, 'chembur': 3432, 'orm': 3433, 'versioning': 3434, 'com/r/anvitha': 3435, 'rao/9d6acc68cc30c71c': 3436, 'passion': 3437, \"api's\": 3438, 'unity': 3439, 'webi': 3440, 'iaas': 3441, 'spam': 3442, 'pandas': 3443, 'arizona': 3444, 'tempe': 3445, 'az': 3446, 'postgresql': 3447, 'com/r/arjun': 3448, 'ks/8e9247624a5095b4': 3449, 'familiarity': 3450, 'starter': 3451, 'oracle’s': 3452, 'lms': 3453, 'publication': 3454, 'rostering': 3455, 'seat': 3456, 'impart': 3457, 'enquiries': 3458, 'sikkim': 3459, 'accountancy': 3460, 'yellow': 3461, 'com/r/arun': 3462, 'elumalai/26575d617d50ea04': 3463, 'sauce': 3464, 'ansys': 3465, 'creo': 3466, 'parametric': 3467, 'com/r/ashalata': 3468, 'bisoyi/cf02125911cfb5df': 3469, 'esteem': 3470, 'culture': 3471, 'absence': 3472, 'rejections': 3473, 'khallikote': 3474, 'autonomous': 3475, 'berhampur': 3476, 'girls': 3477, 'ashok': 3478, 'com/r/ashok': 3479, 'kunam/7aac8767aacf10a0': 3480, 'nifi': 3481, 'jive': 3482, '150': 3483, 'insert': 3484, 'myitalent': 3485, 'cron': 3486, 'csc': 3487, 'kakinada': 3488, 'com/in/ashok': 3489, '85a845a8': 3490, 'iterative': 3491, 'com/r/avin': 3492, 'sharma/3ad8a8b57a172613': 3493, 'prospective': 3494, 'competency': 3495, 'merger': 3496, 'benchmarks': 3497, 'showcasing': 3498, 'nanak': 3499, 'lakes': 3500, 'com/r/ayesha': 3501, 'b/b2985be284dee3d6': 3502, 'utilise': 3503, 'literacy': 3504, 'com/r/ayushi': 3505, 'srivastava/2bf1c4b058984738': 3506, 'endpoints': 3507, 'tandberg': 3508, 'telepresence': 3509, 'cucm': 3510, 'sip': 3511, 'preschool': 3512, 'strongly': 3513, 'mind': 3514, 'kharadi': 3515, 'discrepancy': 3516, 'biology': 3517, 'chhindwara': 3518, 'darshan': 3519, 'com/r/darshan': 3520, 'g/025a61a82c6a8c5a': 3521, 'patience': 3522, 'furnish': 3523, 'nominate': 3524, 'chikmagalur': 3525, 'raj': 3526, 'com/r/dhanushkodi': 3527, 'raj/cf31bbac6c5a5d29': 3528, 'gherkin': 3529, 'loadrunner': 3530, 'variant': 3531, 'windows/unix': 3532, 'convenient': 3533, 'alternative': 3534, 'talk': 3535, 'jboss': 3536, 'tightly': 3537, 'subscribers': 3538, 'fax': 3539, 'broadband': 3540, 'sms': 3541, 'testbed': 3542, 'jsps': 3543, 'raw': 3544, 'com/r/dinesh': 3545, 'reddy/139711455c45e1ad': 3546, 'caliber': 3547, 'jar': 3548, 'war': 3549, 'tar': 3550, 'communicative': 3551, 'herein': 3552, 'belief': 3553, 'factual': 3554, 'ides': 3555, 'ims': 3556, 'hunter': 3557, 'cgc': 3558, 'fest': 3559, 'com/r/dipesh': 3560, 'gulati/17a483e9e19f9106': 3561, 'crescent': 3562, 'javascripting': 3563, 'click': 3564, 'dushyant': 3565, 'data/': 3566, 'deccan': 3567, 'star/': 3568, 'flake': 3569, 'store/analytics': 3570, 'interoperability': 3571, 'reports/dashboards': 3572, 'sales/marketing': 3573, 'pbi': 3574, 'frequencies': 3575, 'redemption': 3576, 'extractors': 3577, 'processors': 3578, 'reducers': 3579, 'stitch': 3580, 'hop': 3581, 'rbac': 3582, 'populate': 3583, 'biztrack': 3584, 'saurashtra': 3585, 'morbi': 3586, 'designations': 3587, 'promotions': 3588, 'k/b2de315d95905b68': 3589, 'radtool': 3590, 'apr': 3591, 'testcomplete': 3592, 'com/r/hartej': 3593, 'kathuria/04181c5962a4af19': 3594, 'retailers': 3595, 'basket': 3596, 'probability': 3597, 'operative': 3598, 'survive': 3599, 'die': 3600, 'numerical': 3601, 'variable': 3602, 'else': 3603, 'sentimental': 3604, 'hotels': 3605, '23': 3606, 'skillset': 3607, 'bash': 3608, 'preliminary': 3609, 'jupyter': 3610, 'ssga': 3611, 'institutional': 3612, 'gwt': 3613, 'actually': 3614, 'pie': 3615, 'previously': 3616, '475': 3617, 'reserve': 3618, 'itself': 3619, 'var': 3620, 'railway': 3621, 'mandatory': 3622, 'com/r/imgeeyaul': 3623, 'ansari/a7be1cc43a434ac4': 3624, 'jsff': 3625, 'jiras': 3626, 'reader': 3627, 'plugin': 3628, 'physics': 3629, 'rashtriya': 3630, 'c/c++': 3631, 'niit': 3632, 'b+': 3633, 'fi/co': 3634, 'com/r/jitendra': 3635, 'babu/bc3ea69a183395ed': 3636, 'workers': 3637, 'toll': 3638, 'substitution': 3639, 'fossil': 3640, 'subsidiaries': 3641, 'handbags': 3642, 'proprietary': 3643, 'armani': 3644, 'modifications': 3645, 'engines': 3646, 'random': 3647, 'patnaik': 3648, 'ethic': 3649, 'knowledgeable': 3650, 'outage': 3651, 'try': 3652, 'customer\"': 3653, 'rajapalaiyam': 3654, 'forge': 3655, 'bay': 3656, 'gv/1961c4eff806e6f4': 3657, 'evangelize': 3658, 'upcoming': 3659, 'tqa': 3660, 'gatekeeper': 3661, 'pgdbm': 3662, 'com/r/kartik': 3663, 'sharma/cc7951fd7809f35e': 3664, 'spearhead': 3665, 'statutory': 3666, 'instrumental': 3667, 'makers': 3668, 'su53': 3669, 'st01': 3670, 'grc': 3671, 'remediation': 3672, 'authorizations': 3673, 'math': 3674, 'quicksilver': 3675, 'maria': 3676, '1+': 3677, 'trap': 3678, 'infovista': 3679, 'vportal': 3680, 'ppt': 3681, 'relay': 3682, 'com/r/kavitha': 3683, 'k/8977ce8ce48bc800': 3684, 'com/r/kavya': 3685, 'u/049577580b3814e6': 3686, 'verilog': 3687, 'i2c': 3688, 'srinivas': 3689, 'fsm': 3690, 'amba': 3691, 'trainers': 3692, 'choudhary/b10649068fcdfa42': 3693, 'muzaffarnagar': 3694, 'thane': 3695, 'blend': 3696, 'mcsa': 3697, 'com/r/koushik': 3698, 'katta/a6b19244854199ec': 3699, 'mq': 3700, 'webhooks': 3701, 'ci/cd': 3702, 'bamboo': 3703, 'toward': 3704, 'arts': 3705, 'timeliness': 3706, 'civil': 3707, '2d': 3708, 'compatible': 3709, 'datum': 3710, 'color': 3711, 'original': 3712, 'appearance': 3713, 'sapui5/fiori': 3714, 'specially': 3715, 'navigate': 3716, 'debuggers': 3717, 'painter': 3718, '28': 3719, 'jabil': 3720, 'inbox': 3721, 'unite': 3722, 'vizframe': 3723, 'few': 3724, 'dayananda': 3725, 'chrome': 3726, 'feasibility': 3727, 'kuppam': 3728, 'banglore': 3729, 'tcl/tk': 3730, 'onsite/offsite': 3731, 'ipv4': 3732, 'spirent': 3733, 'generators': 3734, 'uae': 3735, 'at&t': 3736, 'topologies': 3737, 'pes': 3738, 'com/r/mahesh': 3739, 'vijay/a2584aabc9572c30': 3740, 'bundle': 3741, 'cleanup': 3742, 'tactical': 3743, 'accurate': 3744, 'creations': 3745, 'requesters': 3746, 'data/vendor': 3747, 'bharti': 3748, 'com/r/manisha': 3749, 'bharti/3573e36088ddc073': 3750, 'e&r': 3751, 'rpt': 3752, 'fs': 3753, 'insta': 3754, 'uft/qtp': 3755, 'com/r/manjari': 3756, 'singh/fd072d33991401f0': 3757, 'stbs': 3758, 'dslams': 3759, 'mobility': 3760, 'story': 3761, 'traceability': 3762, 'iteration': 3763, 'retrospective': 3764, 'telephony': 3765, 'subordinate': 3766, 'assure': 3767, 'free': 3768, 'pt': 3769, 'hdm': 3770, 'tv3': 3771, 'gen': 3772, 'strict': 3773, 'hsia': 3774, 'optik': 3775, 'worksoft': 3776, 'amity': 3777, 'canossa': 3778, 'catalog': 3779, 'ericsson': 3780, 'ameen': 3781, 'visveswaraiah': 3782, 'rajiv': 3783, 'ameen/ba052bfa70e4c0b7': 3784, 'com/r/mohini': 3785, 'gupta/08b5b8e1acd8cf07': 3786, '24x7': 3787, 'particulars': 3788, 'com/r/navas': 3789, 'koya/23c1e4e94779b465': 3790, 'descriptions': 3791, 'tprod': 3792, 'najeer': 3793, 'ulhasnagar': 3794, 'swami': 3795, 'grade': 3796, 'credence': 3797, 'efficiencies': 3798, 'friendly': 3799, 'alam/b06dbac9d6236221': 3800, 'adbc': 3801, 'push': 3802, 'com/r/nidhi': 3803, 'pandit/b4b383dbe14789c5': 3804, 'cbil': 3805, 'crucial': 3806, 'complexity': 3807, 'variants': 3808, 'underlie': 3809, 'stub': 3810, 'responses': 3811, 'omful': 3812, 'behaviour': 3813, 'emerge': 3814, 'aggrigator': 3815, 'stanford': 3816, 'marketplace': 3817, 'farmer': 3818, 'prototype': 3819, 'behavioural': 3820, 'shape': 3821, 'consumers': 3822, 'csv': 3823, 'ikhar/cb907948c3299ef4': 3824, '//github': 3825, 'nitin': 3826, 'tr/e7e3a2f5b4c1e24e': 3827, 'land': 3828, 'sellers': 3829, 'freelance': 3830, 'love': 3831, 'com/in/nitin': 3832, '588105129': 3833, \"ide's\": 3834, 'com/r/pradeeba': 3835, 'v/19ff20f4b8552375': 3836, 'oojs': 3837, 'wire': 3838, 'widgets': 3839, 'metlife': 3840, 'vellore': 3841, 'cookbooks': 3842, 'burks': 3843, 'componenets': 3844, 'contionus': 3845, 'binaries': 3846, 'balancers': 3847, 'webservers': 3848, 'sev4': 3849, 'weekend': 3850, 'badala/bf4c4b7253a8ece7': 3851, 'xp/7': 3852, 'annamacharya': 3853, 'jntu': 3854, 'p3': 3855, 'jvm': 3856, 'envs': 3857, 'webserver': 3858, 'kohls': 3859, 'ear': 3860, 'periodic': 3861, 'administrate': 3862, 'pratibha': 3863, 'com/r/pratibha': 3864, 'p/b4c1202741d63c6c': 3865, 'gsd': 3866, 'oem': 3867, 'mask': 3868, 'oum': 3869, 'months/10': 3870, 'vault': 3871, 'amat': 3872, 'emerson': 3873, 'builder': 3874, 'com/r/prem': 3875, 'koshti/a1fec9e7289496f0': 3876, 'continuously': 3877, '[a': 3878, 'cement': 3879, 'limited]': 3880, '06': 3881, 'polytechnic': 3882, '1990': 3883, 'buying/procurement': 3884, 'wag': 3885, 'gratuity': 3886, 'incentive': 3887, 'wage': 3888, 'slip': 3889, 'birth': 3890, 'increments': 3891, 'stationery': 3892, 'foxpro': 3893, \"oop's\": 3894, 'com/r/pulkit': 3895, 'saxena/ad3f35bfe88a0410': 3896, 'articulate': 3897, 'samba': 3898, '\\\\server': 3899, 'ntfs': 3900, 'arp': 3901, 'icmp': 3902, 'udp': 3903, 'rarp': 3904, 'hdlc': 3905, 'ppp': 3906, 'peripherals': 3907, 'aptech': 3908, 'convince': 3909, 'kinds': 3910, 'softwares': 3911, 'puneet': 3912, 'hyperion': 3913, 'rahul': 3914, 'disney': 3915, 'bollu/dc40f5ce78045741': 3916, 'adopt': 3917, 'dynamo': 3918, 'repetitive': 3919, 'coordinate/assist': 3920, 'labeling/': 3921, 'tomcat/web': 3922, 'lamp': 3923, 'advice': 3924, 'com/r/rajeev': 3925, 'kumar/3f560fd91275495b': 3926, 'exemplify': 3927, 'adaptability': 3928, 'please': 3929, 'consul': 3930, 'ta': 3931, 'lim': 3932, 'ited': 3933, 'giant': 3934, 'ns': 3935, 'mahar': 3936, 'ashtra': 3937, 'shortlist': 3938, 'ads': 3939, 'spss': 3940, 'com/in/rajeevkumar91': 3941, 'vidya': 3942, 'seo': 3943, 'com/r/ram': 3944, 'edupuganti/3ecdecbcba549e21': 3945, 'schneider': 3946, 'assessments': 3947, 'path': 3948, 'deputations': 3949, 'sacramento': 3950, 'norms': 3951, 'cooperation': 3952, 'nlp': 3953, 'kpis': 3954, 'integrator': 3955, '<s10>': 3956, '</s10>': 3957, 'ebusiness': 3958, 'redwood': 3959, 'ramesh': 3960, 'ces': 3961, 'hp/95fc615713630c4e': 3962, 'negotiations': 3963, 'correspond': 3964, \"buyer's\": 3965, 'com/r/ramya': 3966, 'p/00f125c7b9b95a35': 3967, 'pstn': 3968, 'stabilize': 3969, 'collate': 3970, 'lgi': 3971, 'nagious': 3972, 'womens': 3973, 'narayana': 3974, 'com/r/r': 3975, 'arunravi/0da1137537d8b159': 3976, 'magna': 3977, 'developments': 3978, 'crs': 3979, 'corp': 3980, 'ale': 3981, 'settings': 3982, 'ravi': 3983, 'shankar/befa180dc0449299': 3984, 'tough': 3985, 'eye': 3986, 'r2/2012': 3987, 'workstation': 3988, 'forefront': 3989, 'shivgond/4018c67548312089': 3990, 'promise': 3991, \"that's\": 3992, 'ac': 3993, 'fanuc': 3994, 'practical': 3995, 'industries': 3996, 'developer/senior': 3997, 'com/r/rohit': 3998, 'bijlani/06ecf59ddac448c7': 3999, 'cut': 4000, 'idea': 4001, 'comprise': 4002, 'premium': 4003, 'subsequent': 4004, \"infosys's\": 4005, 'gwalior': 4006, 'com/r/roshan': 4007, 'sinha/ab398efcd288724f': 4008, 'chemicals': 4009, 'movement': 4010, 'receipt': 4011, 'header': 4012, 'deviation': 4013, 'deliverable': 4014, 'spool': 4015, 'dhir/e6ed06ed081f04cf': 4016, 'ss7': 4017, 'stps': 4018, 'karizma': 4019, 'stamp': 4020, 'mean': 4021, 'vary': 4022, 'pmjjby': 4023, 'mantri': 4024, 'renew': 4025, 'anyone': 4026, 'patha/981ba615ab108e29': 4027, '6+': 4028, 'cvs': 4029, 'exercise': 4030, 'i&a': 4031, 'logics': 4032, 'ee': 4033, 'ws': 4034, 'csone': 4035, 'leakage': 4036, 'financials': 4037, 'xcelsius': 4038, 'amrita': 4039, 'dao': 4040, 'elucidation': 4041, 'spear': 4042, 'complaint': 4043, 'wcag': 4044, 'wai': 4045, 'aria': 4046, 'appraisals': 4047, 'ardent': 4048, 'believer': 4049, 'practitioner': 4050, 'encompass': 4051, 'scrap': 4052, 'text/sentiment': 4053, 'ceremonies': 4054, 'venkatraman/a009f49bfe728ad1': 4055, 'sameer': 4056, 'kujur': 4057, 'orrisha': 4058, 'vssut': 4059, 'burla': 4060, 'functionally': 4061, 'tandem': 4062, 'audience': 4063, 'shivakumar/cabce09fe942cb85': 4064, 'africa': 4065, 'speak': 4066, 'topics': 4067, 'indirect': 4068, 'exclusive': 4069, 'accolade': 4070, 'com/r/santosh': 4071, 'ganta/4270d63f03e71ee8': 4072, 'gmr': 4073, 'qmf': 4074, 'ahmad': 4075, 'com/r/sarfaraz': 4076, 'ahmad/1498048ada755ac3': 4077, 'combination': 4078, 'shut': 4079, 'svi': 4080, 'redundancy': 4081, 'url': 4082, 'sharif': 4083, 'vrf': 4084, 'redundant': 4085, 'dmvpn': 4086, 'com/r/senthil': 4087, 'kumar/d9d82865dd38d449': 4088, 'pod': 4089, 'ucs': 4090, '9k': 4091, 'interconnect': 4092, 'dvs': 4093, 'and/or': 4094, 'packet': 4095, 'double': 4096, 'dot1ad': 4097, 'lsp': 4098, 'sys': 4099, 'ft': 4100, 'derive': 4101, '12000': 4102, 'appliance': 4103, 'acs': 4104, 'vxlan': 4105, 'psudowire': 4106, 'iexplore': 4107, 'cat': 4108, 'com/r/shabnam': 4109, 'saba/dc70fc366accb67f': 4110, 'ags': 4111, 'subscriptions': 4112, '02': 4113, \"'2011\": 4114, 'rollout': 4115, 'mittal': 4116, 'household': 4117, 'confirmation': 4118, 'unissa/c54e7a04da30c354': 4119, 'gulf': 4120, 'approximately': 4121, 'chip': 4122, 'nearly': 4123, '42': 4124, 'begin': 4125, 'rapid': 4126, 'operators': 4127, 'rfx': 4128, 'prefix': 4129, 'smartforms': 4130, 'reject': 4131, 'nigeria': 4132, 'mrs': 4133, 'clearance': 4134, '90': 4135, 'tonnes': 4136, 'whole': 4137, 'treatment': 4138, 'iron': 4139, 'throughput': 4140, 'vessel': 4141, 'mohp': 4142, 'unload': 4143, 'rent': 4144, 'bupa': 4145, '45': 4146, 'cancel': 4147, 'rebate': 4148, 'accrue': 4149, 'com/r/sharan': 4150, 'adla/3a382a7b7296a764': 4151, '4yrs': 4152, 'illustrator': 4153, 'indesign': 4154, 'dreamweaver': 4155, 'layouts': 4156, 'collaboratively': 4157, \"sept'\": 4158, 'payrolls': 4159, \"apr'\": 4160, 'mpc': 4161, 'vijayawada': 4162, 'templating': 4163, 'doesn’t': 4164, 'expandable': 4165, 'dvd': 4166, 'blu': 4167, 'ray': 4168, 'popup': 4169, 'com/in/shreyanshu': 4170, '135176103/': 4171, 'writer': 4172, 'bilaspur': 4173, 'hone': 4174, 'clone': 4175, 'soapui': 4176, 'synchronous': 4177, 'xsd': 4178, 'wsdl': 4179, 'renfrew': 4180, 'suggestions/answers': 4181, 'partially': 4182, 'whitbread': 4183, 'com/r/shubham': 4184, 'mittal/4b29ab0545b0f67f': 4185, 'soql': 4186, 'vf': 4187, 'loader': 4188, 'contributions': 4189, 'rt': 4190, 'active/passive': 4191, '3560': 4192, 'vlsm': 4193, 'summarization': 4194, 'pat': 4195, 'asr901': 4196, 'asr903': 4197, 'asr900': 4198, 'isis': 4199, 'e1nd': 4200, 'bathery': 4201, 'ug': 4202, 'awa*': 4203, 'tree': 4204, 'experimental': 4205, 'slide': 4206, 'puzzle': 4207, 'salesman': 4208, 'inox': 4209, '2k12': 4210, 'aliasing': 4211, 'vecw': 4212, '4g': 4213, 'intellegence': 4214, 'oca': 4215, 'thiruvananthapuram': 4216, '+2': 4217, \"'global\": 4218, 'avinashilingam': 4219, 'karanth/a76c9c40c02ed396': 4220, 'das': 4221, 'concierge': 4222, 'green': 4223, 'aps': 4224, 'bteq': 4225, 'muti': 4226, 'tpump': 4227, 'tpt': 4228, 'radar': 4229, 'espresso': 4230, 'icheck': 4231, 'gitlab': 4232, 'leaderboard': 4233, 'actionable': 4234, 'autosys': 4235, 'alone': 4236, 'com/r/srinivas': 4237, 'vo/39c80e42cb6bc97f': 4238, 'relation': 4239, 'extremely': 4240, 'tcoe': 4241, 'awareness': 4242, 'sso': 4243, 'geographies': 4244, 'mission': 4245, 'applicable': 4246, \"ubs's\": 4247, 'discover': 4248, 'assess': 4249, '50+': 4250, 'com/r/srushti': 4251, 'bhadale/ffe3d9f99a4b3322': 4252, 'com/r/sudaya': 4253, 'puranik/eaf5f7c1a67c6c38': 4254, 'rac': 4255, 'com/r/sumit': 4256, 'kubade/256d6054d852b2a7': 4257, 'tolerance': 4258, 'park': 4259, 'reversal': 4260, 'r&d': 4261, 'kochi': 4262, 'alsa': 4263, 'coder': 4264, 'devendla/c9ba7bc582b14a7b': 4265, 'vc++': 4266, 'webrtc': 4267, 'commercialization': 4268, 'handsets': 4269, 'winshark': 4270, 'vs2010': 4271, '32/64': 4272, 'usable': 4273, 'nod': 4274, 'replicate': 4275, 'manifest': 4276, 'paint': 4277, 'mismatch': 4278, 'recorder': 4279, 'playlist': 4280, 'av': 4281, 'movie': 4282, 'editor': 4283, 'split': 4284, 'schindler': 4285, 'elevator': 4286, 'escalator': 4287, 'vc': 4288, 'tejasri': 4289, 'com/r/tejasri': 4290, 'gunnam/6ef1426c95ee894c': 4291, 'systemsindpvtltd': 4292, 'seed': 4293, 'progression': 4294, 'cserv': 4295, 'penetration': 4296, 'retina': 4297, 'puducherry': 4298, 'radius': 4299, 'com/r/urshila': 4300, 'lohani/ab8d3dc6dd8b13f0': 4301, '4x': 4302, 'mcafee': 4303, '200': 4304, 'thrice': 4305, '26': 4306, 'directors': 4307, 'penetrate': 4308, 'install': 4309, 'fy13': 4310, 'mentorship': 4311, 'shri': 4312, 'quantitative': 4313, 'vijayalakshmi': 4314, 'govindarajan': 4315, 'tvs': 4316, 'lakshmi': 4317, 'govindarajan/d71bfb70a66b0046': 4318, 'utilization/memory': 4319, 'metric': 4320, 'award\"': 4321, 'maersk': 4322, 'mlit': 4323, 'smp': 4324, 'ons': 4325, 'scheduling/cancelling': 4326, 'expensive': 4327, 'nwa': 4328, 'kernel': 4329, 'whenever': 4330, 'brtools': 4331, 'erp6': 4332, 'com/r/vikas': 4333, 'singh/8644db42854c4f6a': 4334, \"i've\": 4335, 'zeal': 4336, 'rtir': 4337, 'below': 4338, 'urls': 4339, 'palo': 4340, 'alto': 4341, 'eradication': 4342, 'quarantine': 4343, 'unapproved': 4344, 'identification': 4345, 'today': 4346, 'rsa': 4347, 'iiq': 4348, 'qap': 4349, 'auditors': 4350, 'mathura': 4351, 'regress': 4352, 'jayaramachandran/c36e76b64d9f477f': 4353, 'phase1': 4354, 'bandwidth': 4355, \"ao's\": 4356, 'lancer': 4357, 'phoenix': 4358, 'skyhawk': 4359, 'examine': 4360, 'adaptive': 4361, 'namakkal': 4362, 'com/r/yathishwaran': 4363, 'p/a9c8d42210af40b8': 4364, 'conditional': 4365, 'queries/reports': 4366, 'formal': 4367, 'informal': 4368, 'btramr0001syser': 4369, 'btramr2': 4370, 'v4': 4371, 'earlier': 4372, 'drawbacks': 4373, 'esthetical': 4374, 'font': 4375, 'instinctive': 4376, \"technician's\": 4377, 'simplicity': 4378, 'spectra': 4379, 'btramr0009': 4380, 'btramr0027': 4381, 'storeroom': 4382, 'kiosk': 4383, 'internally': 4384, 'assembly': 4385, 'redefine': 4386, '80': 4387, 'notion': 4388, 'btramr0002': 4389, 'might': 4390, 'vend': 4391, 'clarification': 4392, 'technical/functional': 4393, 'com/r/yogi': 4394, 'pesaru/2ed7aded59ecf425': 4395, 'udfs': 4396, 'ir': 4397, 'successfactor': 4398, 'runtime': 4399, '01st': 4400, 'sysco': 4401, 'receiver': 4402, 'nwds': 4403, 'qualities': 4404, 'com/r/anurag': 4405, 'asthana/ea7451b2bdb6115a': 4406, 'blob': 4407, 'csom': 4408, 'avepoint': 4409, 'docave': 4410, 'ecma': 4411, 'era': 4412, 'dehra': 4413, 'msbi': 4414, 'sadath': 4415, 'com/r/nida': 4416, 'integral': 4417, 'ti': 4418, 'bareilly': 4419, 'ye': 4420, 'succeed': 4421, 'soni': 4422, 'ion': 4423, 'corenlp': 4424, 'guice': 4425, 'microservice': 4426, 'xaml': 4427, 'atdd': 4428, 'viny': 4429, 'khandelwal': 4430, 'himachal': 4431, 'kudi': 4432, 'firang': 4433, 'pricewaterhousecoopers': 4434, 'corporates': 4435, 'submission': 4436, 'photography': 4437, 'dossier': 4438, 'journalism': 4439, 'com/r/amarjyot': 4440, 'sodhi/ba2e5a3cbaeccdac': 4441, 'comm': 4442, 'com/r/zaheer': 4443, 'uddin/fd9892e91ac9a58f': 4444, 'raid': 4445, 'com/r/abdul': 4446, 'b/eb2d7e0d29fe31b6': 4447, 'arabization': 4448, 'localization': 4449, \"master's\": 4450, 'organizer': 4451, 'le': 4452, 'band': 4453, 'tourism': 4454, 'com/r/girish': 4455, 'acharya/6757f94ee9f4ec23': 4456, 'someone': 4457, 'feedbacks': 4458, 'appfabric': 4459, 'monetization': 4460, 'store/windows': 4461, 'tip': 4462, 'watchdogs': 4463, 'com/in/girishazure': 4464, 'ure': 4465, 'hd': 4466, 'ieb': 4467, 'bunch': 4468, 'walk': 4469, '&lt': 4470, '&gt': 4471, 'bvts': 4472, 'executives': 4473, 'lob': 4474, 'transcoding': 4475, 'los': 4476, 'angeles': 4477, 'fnol': 4478, 'notice': 4479, 'silverlight': 4480, 'intend': 4481, 'du': 4482, 'abacus': 4483, 'cfe': 4484, 'bombay': 4485, 'centrally': 4486, 'com/r/asha': 4487, 'subbaiah/f7489ca1bec4570b': 4488, 'pb&amp': 4489, 'sms&amp': 4490, 'outcomes': 4491, 'itlg': 4492, 'agenda': 4493, 'visitors': 4494, 'square': 4495, 'advancement': 4496, 'utmost': 4497, 'foe': 4498, 'competition': 4499, 'infosis': 4500, 'exp': 4501, 'alalasundaram/': 4502, 'elevate': 4503, 'fasttrack': 4504, 'alalasundaram/dd5b500021e61f65': 4505, 'ecosystem': 4506, 'univer': 4507, 'sity': 4508, 'naik': 4509, 'salaries': 4510, 'telugu': 4511, 'seven': 4512, 'fut': 4513, 'spot': 4514, 'five': 4515, 'optical': 4516, 'harmonize': 4517, 'intercompany': 4518, 'atlas': 4519, 'europe': 4520, 'harvard': 4521, 'edi': 4522, 'indore': 4523, 'paul': 4524, 'ocsm': 4525, 'com/r/aarti': 4526, 'pimplay/778c7a91033a71ca': 4527, 'ind': 4528, 'news': 4529, 'tavarekere': 4530, 'volunteer': 4531, 'contestant': 4532, 'yappon': 4533, 'faculty': 4534, 'com/r/avani': 4535, 'priya/fe6b4c5516207abe': 4536, 'pal': 4537, 'com/r/sanand': 4538, 'pal/5c99c42c3400737c': 4539, 'vsto': 4540, 'collaborative': 4541, 'workbook': 4542, 'vstf': 4543, 'sarathi': 4544, 'mitra': 4545, 'surendranath': 4546, 'barrackpore': 4547, 'com/r/pranay': 4548, 'sathu/ef2fc90d9ec5dde7': 4549, 'uitest': 4550, 'norton': 4551, 'money': 4552, 'cylinder': 4553, \"and's\": 4554, 'top&co=i': 4555, 'secunderabad': 4556, 'specialization': 4557, 'com/in/karthik': 4558, 'icrosoft': 4559, 'earliest': 4560, 'soon': 4561, 'eta': 4562, 'chronology': 4563, 'ultimate': 4564, 'deletion': 4565, 'manuals': 4566, 'another': 4567, 'folder': 4568, 'scanners': 4569, 'unlock': 4570, 'peripheral': 4571, 'instruct': 4572, 'universi': 4573, 'nodal': 4574, 'chandra': 4575, 'mecs': 4576, 'ser': 4577, 'ver': 4578, 'fedora': 4579, 'com/r/pradeep': 4580, 'akansha': 4581, 'com/r/akansha': 4582, 'jain/b53674429e164cfc': 4583, 'cleanse': 4584, 'stone': 4585, 'informati': 4586, 'manufacturers': 4587, 'saarc': 4588, 'facets': 4589, 'annum': 4590, \"india's\": 4591, 'substantial': 4592, 'immediate': 4593, 'dubey': 4594, 'com/r/akshay': 4595, 'undergraduate': 4596, 'msa': 4597, 'enthusiasts': 4598, 'lonavale': 4599, 'flask': 4600, 'web2py': 4601, 'tensorflow': 4602, 'notebook': 4603, 'gokul/ca7750b94830268d': 4604, 'iversity': 4605, 'prasad/b8d7a1135a44a37a': 4606, 'sandhikar': 4607, 'sandhikar/e490c0d49e5aa698': 4608, 'colleges': 4609, 'ethical': 4610, 'society': 4611, 'com/r/priyesh': 4612, 'dubey/cd079a9e5de18281': 4613, 'fake': 4614, 'pace': 4615, 'com/r/laya': 4616, 'a/74af8dc044f3fa7f': 4617, 'again': 4618, 'inculcate': 4619, 'intent': 4620, 'draft': 4621, 'incentives': 4622, 'strive': 4623, 'equity': 4624, 'compliant': 4625, 'labournet': 4626, 'com/r/vishwanath': 4627, 'importantly': 4628, 'macros': 4629, 'agencies': 4630, 'stationary': 4631, \"member's\": 4632, 'quires': 4633, 'infy': 4634, 'ahmedabad': 4635, 'com/r/hemil': 4636, 'bhavsar/ce3a928d837ce9e1': 4637, 'concentrix': 4638, 'merchants': 4639, 'project/task': 4640, 'chetri/f6959d21c6b91bba': 4641, 'spencer': 4642, 'aditya': 4643, 'advisor': 4644, 'com/r/pratik': 4645, 'vaidya/e88324548608d0bc': 4646, 'aegis': 4647, 'adaptable': 4648, 'marathi': 4649, 'listen': 4650, \"a'bad\": 4651, 'bss': 4652, 'integrations': 4653, 'alm/octane': 4654, 'kubernetes': 4655, 'efs': 4656, 'opsworks': 4657, 'fxcop': 4658, 'ccnet': 4659, 'bmc': 4660, 'xlrelease': 4661, 'xldeploy': 4662, 'bau': 4663, 'iv': 4664, 'hk': 4665, 'com/r/keshav': 4666, 'beacon': 4667, 'vadodara': 4668, 'com/r/praveen': 4669, 'bhaskar/c9868b2e3dd70df1': 4670, 'com/r/gunjan': 4671, 'nayyar/a5819ca6733a0f41': 4672, 'wrestle': 4673, 'com/r/rupesh': 4674, 'xir2': 4675, 'pad': 4676, 'sapbi': 4677, 'idt': 4678, 'umt': 4679, 'lcm': 4680, 'xir3': 4681, 'wintel': 4682, 'expiry': 4683, 'hpsm': 4684, 'ngineering': 4685, 'nformation': 4686, 'cultural': 4687, 'hipower': 4688, 'com/r/puneeth': 4689, 'r/bc332220e733906d': 4690, '9001': 4691, 'gds': 4692, 'confirmations': 4693, 'airlines': 4694, 'fortnight': 4695, 'car': 4696, 'riya': 4697, 'airport': 4698, 'bharath': 4699, 'orange': 4700, 'freight': 4701, 'supervisors': 4702, 'qatar': 4703, 'vijayan/ee84e7ea0695181f': 4704, 'transcription': 4705, 'trainees': 4706, 'avail': 4707, 'destinations': 4708, 'round': 4709, 'wholly': 4710, 'tennessee': 4711, 'tayade/ce40c3731cb69763': 4712, 'ites': 4713, 'crime': 4714, 'portion': 4715, 'fpq': 4716, 'oms': 4717, 'csip': 4718, 'application/detail': 4719, 'requests/maintenance': 4720, 'daas': 4721, 'caas': 4722, 'maas': 4723, 'onward': 4724, 'eservices': 4725, 'com/r/debasish': 4726, 'ptc': 4727, 'finacle10': 4728, 'finacle7': 4729, 'dispute': 4730, 'replenishment': 4731, 'com/r/jaspreet': 4732, 'kaur/1b83bc42482ed5a0': 4733, 'advertise': 4734, 'esi': 4735, 'salary/': 4736, 'promotions/': 4737, 'maya': 4738, 'estatz': 4739, 'solitaire': 4740, 'man': 4741, '24th': 4742, 'behera/e9188fe8ba12dbbd': 4743, 'observer': 4744, 'termination': 4745, 'engi': 4746, 'macro': 4747, 'raipur': 4748, 'appl': 4749, 'ations': 4750, 'chnology': 4751, 'raman': 4752, 'com/r/dilliraja': 4753, 'baskaran/4a3bc8a35879ce5c': 4754, 'com/r/deepika': 4755, 's/1b4436206cf5871b': 4756, 'xp/7/8': 4757, 'citi': 4758, 'csr': 4759, 'com/r/jacob': 4760, 'philip/db00d831146c9228': 4761, 'systemreportforms': 4762, 'assignedtaskstoassociates': 4763, 'trackedprogressandupdatedmanagers': 4764, 'perkins': 4765, 'com/r/yogesh': 4766, 'ghatole/b381ddf132151a29': 4767, 'bms': 4768, 'electricians': 4769, 'transformer': 4770, 'breakers': 4771, 'pole': 4772, 'shutter': 4773, 'lt': 4774, 'oh': 4775, 'fan': 4776, 'adjustment': 4777, 'wpm': 4778, 'cit': 4779, 'boulder': 4780, 'massachusetts': 4781, 'cadence': 4782, 'multichannel': 4783, 'gedit': 4784, 'boot': 4785, 'onboard': 4786, 'vhdl': 4787, 'adv': 4788, 'com/r/shaik': 4789, 'tazuddin/1366179051f145eb': 4790, 'spain': 4791, 'folks': 4792, 'zealand': 4793, 'com/r/angad': 4794, 'saturday': 4795, '/sr': 4796, 'hardware/software': 4797, 'shivpuri': 4798, 'bbm': 4799, 'horizon': 4800, 'elasticsearch': 4801, 'kafka': 4802, 'agnihotri/c1755567027a0205': 4803, 'arpit': 4804, 'bhilwara': 4805, 'com/r/palani': 4806, 's/d3b2e79f56262868': 4807, 'xecu': 4808, 'tive': 4809, 'client/server': 4810, 'exhibit': 4811, 'ary': 4812, 'mvc4': 4813, 'krv@gmail': 4814, 'selva': 4815, 'noc': 4816, 'skava': 4817, 'ltd/edgeverve': 4818, 'com/r/mayank': 4819, 'shukla/3c6042bd141ad353': 4820, 'jazz': 4821, 'whiteboard': 4822, 'admarc': 4823, 'com/r/jatin': 4824, 'arora/a124b9609f62fbcb': 4825, 'volumes': 4826, '95': 4827, 'gururaj/a51f07b3eda3aa6c': 4828, 'deloitte': 4829, 'oncology': 4830, 'akila': 4831, 'mohideen': 4832, 'com/r/akila': 4833, 'mohideen/cfe2854527fb6a12': 4834, 'dual': 4835, 'com/r/ahmad': 4836, 'bardolia/8e2c49ea8e7dcd27': 4837, 'autoscaling': 4838, 'formation': 4839, 'dynamodb': 4840, 'sdk': 4841, 'swf': 4842, 'workspaces': 4843, 'beanstalk': 4844, 'datastore': 4845, 'dataproc': 4846, 'jfrog': 4847, 'com/r/sridevi': 4848, 'h/63703b24aaaa54e4': 4849, 'vxworks': 4850, 'com/r/raktim': 4851, 'podder/32472fc557546084': 4852, 'eod': 4853, 'initiation': 4854, 'decrease': 4855, 'com/r/pavithra': 4856, 'm/26f392ec8251143b': 4857, 'r2r': 4858, 'p2p': 4859, 'directories': 4860, 'com/r/chaban': 4861, 'debbarma/bf721c55fb380d19': 4862, 'siddharth': 4863, 'puthanampatti': 4864, 'dslr': 4865, 'camera': 4866, 'shivam': 4867, 'mta': 4868, 'converter': 4869, '16th': 4870, 'rathi/d7d73269f025a981': 4871, 'verma/b9e8520147f728d2': 4872, 'com/r/venkateswara': 4873, 'd/18b373e3b03b371f': 4874, \"microsoft's\": 4875, 'laminar': 4876, 'semi': 4877, 'lpo': 4878, \"rfc's\": 4879, 'ulm': 4880, 'otherwise': 4881, 'dpm': 4882, 'legato': 4883, 'networker': 4884, 'symantec': 4885, 'exec': 4886, 'sons': 4887, 'com/r/pankaj': 4888, 'bhosale/2d6f2e970b9a7ff6': 4889, 'com/r/vinay': 4890, 'singhal/c15261079a9b5ae7': 4891, 'pawan': 4892, 'nag': 4893, 'com/r/pawan': 4894, 'nag/e14493f28cb72022': 4895, 'dainamic': 4896, 'shreenath': 4897, 'engence': 4898, 'coffeeday': 4899, 'com/r/moumita': 4900, 'mitra/d63c4dc9837860db': 4901, 'olympiad': 4902, 'educator': 4903, 'prayag': 4904, 'sangit': 4905, 'samiti': 4906, 'therapy': 4907, 'zoology': 4908, 'barakpur': 4909, 'com/r/suman': 4910, 'biswas/63db95fe3ae14910': 4911, 'b2c': 4912, 'vibgyor': 4913, 'techsolutions': 4914, 'mithapur': 4915, 'com/r/anil': 4916, 'kumar/96983a9dd7222ae5': 4917, 'escan': 4918, 'rack': 4919, 'prof': 4920, 'epabx': 4921, 'scientific': 4922, 'gurgoan': 4923, 'spiceworks': 4924, 'cyberoam': 4925, 'stem': 4926, '9th': 4927, 'thecus': 4928, 'lcd': 4929, 'anti': 4930, 'virus': 4931, '23rd': 4932, 'cabinet': 4933, '250': 4934, 'tecumseh': 4935, 'citizens': 4936, 'offboarding': 4937, 'tokens': 4938, 'dhandapani/a2b3eb340068764d': 4939, 'amex': 4940, 'ifind': 4941, 'crl': 4942, 'brokerage': 4943, 'futures': 4944, 'sps': 4945, 'hoa': 4946, 'fos': 4947, 'intersystem': 4948, 'ibbn': 4949, '−': 4950, 'bio': 4951, 'biochemistry': 4952, 'contour': 4953, 'siem': 4954, 'abhishek': 4955, 'jha': 4956, 'utterances': 4957, 'woodbine': 4958, 'kendriya': 4959, 'vidyalaya': 4960, 'tolerant': 4961, 'polite': 4962, 'calm': 4963, 'afreen': 4964, 'jamadar': 4965, 'sangli': 4966, 'techkriti': 4967, 'skynet': 4968, 'personallity': 4969, 'pg': 4970, 'akhil': 4971, 'polemaina': 4972, 'polemaina/': 4973, 'f6931801c51c63b1': 4974, '#': 4975, \"'retail\": 4976, \"link'\": 4977, \"100's\": 4978, 'jntuh': 4979, 'z/os': 4980, 'alok': 4981, 'khandai': 4982, 'deadlocks': 4983, 'multitask': 4984, 'lose': 4985, 'wa': 4986, 'predominantly': 4987, '25000': 4988, '64bit': 4989, 'standalone': 4990, '\"costco': 4991, 'wholesale\"': 4992, 'substantially': 4993, 'conventional': 4994, 'resale': 4995, 'windows95/98/xp/nt': 4996, 'sas': 4997, 'ananya': 4998, 'chavan': 4999, 'extreme': 5000, '\"dr': 5001, 'babasaheb': 5002, 'ambedkar': 5003, '\"live\"': 5004, '\"kohinoor': 5005, 'management\"': 5006, '\"oracle': 5007, 'tutorials\"': 5008, 'sci': 5009, 'earch': 5010, '&jquery': 5011, '\"real': 5012, 'application\"': 5013, 'realtor': 5014, 'aryantech': 5015, 'anvitha': 5016, 'summer': 5017, 'geospark': 5018, 'taxi': 5019, 'exploratory': 5020, 'd3': 5021, 'prediction': 5022, 'pollution': 5023, 'pollutants': 5024, 'geographical': 5025, 'least': 5026, 'pollute': 5027, 'ref': 5028, 'ijrcct': 5029, 'org/index': 5030, 'php/ojs/article/view/1416': 5031, 'ramaiah': 5032, 'com/in/anvitha': 5033, '65a068a7': 5034, 'html/css': 5035, 'd3js': 5036, 'gephi': 5037, 'arjun': 5038, 'ks': 5039, 'individuality': 5040, 'causative': 5041, 'intensification': 5042, 'snap': 5043, 'delve': 5044, 'rapport': 5045, '{ms': 5046, 'powerpoint}': 5047, 'milestone': 5048, 'diffusion': 5049, 'bouyance': 5050, 'entrepreneurship': 5051, 'nen': 5052, 'employee/partner': 5053, \"oracle's\": 5054, 'sla’s': 5055, 'arun': 5056, 'elumalai': 5057, 'emboss': 5058, 'account/card': 5059, 'reissue': 5060, 'enrollment': 5061, 'cashback': 5062, 'software/tools': 5063, 'waf': 5064, 'ashalata': 5065, 'bisoyi': 5066, 'sincerity': 5067, 'seniors': 5068, 'hinjilicut': 5069, 'hinjilikatu': 5070, 'subsystems': 5071, 'schematics': 5072, 'preserve': 5073, 'instantly': 5074, 'recruiters': 5075, 'drupal': 5076, 'attivio': 5077, 'jackson': 5078, \"framework's\": 5079, 'mockito': 5080, 'app/web': 5081, 'skm': 5082, 'inversion': 5083, 'asish': 5084, 'ratha': 5085, 'com/r/asish': 5086, 'ratha/853988e0e0e236a3': 5087, 'avin': 5088, \"rfp's\": 5089, 'budgets/': 5090, 'commercials': 5091, 'planning/': 5092, \"'business\": 5093, 'delight': 5094, 'amritsar': 5095, 'ayesha': 5096, 'desgin': 5097, 'flexml': 5098, 'schemas': 5099, 'atria': 5100, 'sindhi': 5101, 'ayushi': 5102, 'srivastava': 5103, '1year': 5104, 'tier2': 5105, 'pbx': 5106, 'polycom': 5107, 'tms': 5108, 'vcs': 5109, 'sccp': 5110, '323': 5111, 'rtmt': 5112, 'hmr': 5113, 'sumermal': 5114, 'bhawana': 5115, 'daf': 5116, 'com/r/bhawana': 5117, 'daf/d9ddb6a54519d583': 5118, 'young': 5119, 'viman': 5120, 'vadgaonsheri': 5121, 'trial': 5122, 'demographic': 5123, 'serious': 5124, 'sae': 5125, 'laboratory': 5126, 'pandhurna': 5127, 'here': 5128, 'catalogue': 5129, 'fall': 5130, 'inactive': 5131, 'fringe': 5132, 'requite': 5133, 'stick': 5134, 'adhichunchanagiri': 5135, 'rx11': 5136, 'dhanushkodi': 5137, '9+': 5138, 'commerce/financial': 5139, 'client/server/': 5140, 'manifesto': 5141, 'defect/test': 5142, 'let': 5143, 'conversation': 5144, '237': 5145, 'pom': 5146, 'behaviours': 5147, 'selenium/cucumber': 5148, 'weaknesses': 5149, 'pge': 5150, 'uplift': 5151, 'speech': 5152, 'regression/functional': 5153, '182': 5154, 'web/': 5155, 'liability': 5156, 'intra': 5157, 'presentment': 5158, 'eipp': 5159, 'suntracker': 5160, 'reliably': 5161, 'securely': 5162, 'dissemination': 5163, 'easier': 5164, 'increasingly': 5165, 'instant': 5166, 'myriad': 5167, 'demographics': 5168, 'preferences': 5169, 'precisely': 5170, 'brief': 5171, 'illustrate': 5172, 'ians': 5173, 'ans': 5174, 'pop': 5175, 'economical': 5176, 'enquiry': 5177, 'comparisons': 5178, 'valid': 5179, 'bugzilla': 5180, 'venkateshwara': 5181, 'com/in/dhanushkodi': 5182, 'a190a0155': 5183, 'cyara': 5184, 'languages/frameworks': 5185, 'webservices': 5186, 'httpclient': 5187, 'dinesh': 5188, 'pursuit': 5189, 'deployable': 5190, 'windows64': 5191, 'windows32': 5192, 'linux64': 5193, 'linux/unix': 5194, 'java/j2eeweb': 5195, 'nodes/agents': 5196, 'trunks': 5197, 'suppress': 5198, 'fact': 5199, 'artifact': 5200, 'sontype': 5201, 'editors': 5202, 'notepad++': 5203, 'xp/2000/nt/98': 5204, 'enviornment': 5205, 'dipesh': 5206, 'gulati': 5207, 'vidyapeeth': 5208, 'shoppingkart': 5209, 'facilities': 5210, 'govardhana': 5211, 'k/': 5212, 'b2de315d95905b68': 5213, 'adithya': 5214, 'com/in/govardhana': 5215, '61024944/': 5216, 'harini': 5217, 'komaravelli': 5218, 'feb17': 5219, 'hartej': 5220, 'kathuria': 5221, 'buisness': 5222, 'mit': 5223, 'expectancy': 5224, 'lung': 5225, 'cancer': 5226, 'patients': 5227, 'predefined': 5228, 'variables': 5229, 'nominal': 5230, 'ordinal': 5231, 'false': 5232, 'happiness': 5233, 'binary': 5234, 'classifcation': 5235, 'tripadvisor': 5236, 'consisiting': 5237, 'classification': 5238, 'japan': 5239, 'huge': 5240, 'losses': 5241, 'categorical': 5242, 'sublime': 5243, 'vz': 5244, 'ijas': 5245, 'nizamuddin': 5246, 'irinchayam': 5247, 'investors1': 5248, 'heritage': 5249, 'centuries': 5250, 'brokerviews': 5251, 'counterparties': 5252, 'invest': 5253, 'redesign': 5254, 'grids': 5255, 'readability': 5256, 'understandability': 5257, 'imc': 5258, 'judge': 5259, 'usability': 5260, '500': 5261, 'laws': 5262, 'initially': 5263, 'regulators': 5264, 'aside': 5265, 'rigorous': 5266, \"bank's\": 5267, 'rbc': 5268, 'eligible': 5269, 'ineligible': 5270, 'rtrm': 5271, 'pnr': 5272, 'j2me': 5273, 'end/gui': 5274, 'flexbuilder': 5275, 'imgeeyaul': 5276, 'ansari': 5277, 'dtos': 5278, 'helper': 5279, 'assembler': 5280, 'collectionappmodule': 5281, 'pagedef': 5282, 'jaw': 5283, 'interval': 5284, 'multitasking': 5285, 'enginerring': 5286, 'rogramming': 5287, 'tortoise': 5288, 'jay': 5289, 'madhavi': 5290, 'navi': 5291, 'mscit': 5292, 'company/college': 5293, 'remark': 5294, 'italian': 5295, 'surround': 5296, 'stressful': 5297, 'kharghar': 5298, 'jitendra': 5299, 'babu': 5300, \"sap's\": 5301, 'assumptions': 5302, 'a/p': 5303, 'a/r': 5304, 'accessories': 5305, \"men's\": 5306, \"women's\": 5307, 'jewelry': 5308, 'leather': 5309, 'sunglasses': 5310, 'michele': 5311, 'misfit': 5312, 'relic': 5313, 'skagen': 5314, 'zodiac': 5315, 'chap': 5316, 'diesel': 5317, 'dkny': 5318, 'emporio': 5319, 'karl': 5320, 'lagerfeld': 5321, 'kate': 5322, 'spade': 5323, 'marc': 5324, 'jacobs': 5325, 'michael': 5326, 'kors': 5327, 'tory': 5328, 'burch': 5329, 'comers': 5330, 'validations': 5331, 'substitutions': 5332, 'ford': 5333, 'suvs': 5334, 'sedans': 5335, 'displacement': 5336, 'prefer': 5337, 'organizations/rental': 5338, 'embassy/consulates': 5339, 'outlets': 5340, 'wricef': 5341, 'machilipatnam': 5342, 'ag&sgs': 5343, 'jyotirbindu': 5344, '@sap': 5345, 'deeply': 5346, 'multitasker': 5347, 'bristlecone': 5348, 'chronological': 5349, 'downtimes/high': 5350, 'mttr': 5351, 'catchpoint': 5352, 'pingdom': 5353, 'kpi/availability/irt': 5354, '\"cloud': 5355, '\"business': 5356, 'design\"': 5357, \"ppt's\": 5358, 'biju': 5359, 'rayagada': 5360, 'karthihayini': 5361, 'renault': 5362, 'annuaire': 5363, 'smartsvn': 5364, 'tortoisesvn': 5365, 'visualiser': 5366, 'madurantakam': 5367, 'leylan': 5368, 'ennore': 5369, 'carborundum': 5370, 'thiruvottiyur': 5371, 'bonfiglioli': 5372, 'thirumudivakkam': 5373, '\"minda': 5374, 'limited\"': 5375, '\"bhel\"': 5376, 'ranipet': 5377, '\"aero': 5378, 'modeling\"': 5379, 'consto': 5380, 'uav': 5381, '\"non': 5382, 'testing\"': 5383, 'gv': 5384, 'aurora': 5385, 'psr': 5386, '~$6': 5387, 'strategize': 5388, 'adoption': 5389, 'retire': 5390, 'gdpr': 5391, 'dw': 5392, 'mckesson': 5393, 'singapore': 5394, 'provident': 5395, 'cee': 5396, '\"sse': 5397, 'services\"': 5398, '103': 5399, '~30': 5400, 'narsee': 5401, 'monjee': 5402, 'kartik': 5403, 'advancements': 5404, 'compliances': 5405, 'upper': 5406, 'seize': 5407, 'annexure': 5408, 'rb': 5409, 'reckitt': 5410, 'benckiser': 5411, \"'16\": 5412, 'agr*': 5413, 'usr*': 5414, 'shdb': 5415, 'su10': 5416, 'firefighter': 5417, 'grc10': 5418, 'handling/creating': 5419, 'solman': 5420, 'user/business/technical': 5421, 'su24': 5422, 'enable/disable': 5423, 'compensatory': 5424, 'fighter': 5425, 'security/authorization': 5426, 'suim': 5427, 'expiration': 5428, \"'avs\": 5429, \"infotech'\": 5430, 'northern': 5431, 'kasturika': 5432, 'borah': 5433, \"syslog's\": 5434, 'even': 5435, 'capgemini': 5436, '25th': 5437, 'nowl': 5438, 'randstad': 5439, 'daksh': 5440, 'spl': 5441, 'conglomerate': 5442, 'josé': 5443, 'syslogs': 5444, 'compucom': 5445, 'insitute': 5446, 'windows/xp': 5447, 'sciencelogic': 5448, 'syslog': 5449, 'kavitha': 5450, 'slider': 5451, 'bookmarks': 5452, 'delay': 5453, 'reiume': 5454, 'kavya': 5455, 'mux': 5456, 'quadgen': 5457, 'radio': 5458, 'nsb': 5459, 'spi': 5460, 'altera': 5461, 'quartus': 5462, 'modelsim': 5463, 'little': 5464, 'rock': 5465, 'vlsi': 5466, 'vidyodaya': 5467, 'udipi': 5468, 'rtl': 5469, 'libreoffice': 5470, 'khushboo': 5471, 'choudhary/': 5472, 'b10649068fcdfa42': 5473, 'pinnacle': 5474, 'sheer': 5475, 'abab': 5476, 'paratap': 5477, 'silver': 5478, 'bell': 5479, 'kimaya': 5480, 'sonawane': 5481, 'com/r/kimaya': 5482, 'sonawane/1f27a18d2e4b1948': 5483, 'ssvps’s': 5484, 'late': 5485, 'deore': 5486, 'koushik': 5487, 'katta': 5488, 'intellectual': 5489, '/chef': 5490, 'containerization': 5491, 'bamboo\\\\maven': 5492, 'handlers': 5493, 'project/repository': 5494, 'enterprise/datacenter': 5495, 'installation/upgrade': 5496, 'icinga': 5497, 'servers/applications': 5498, 'setup/maintain/improve': 5499, 'sister': 5500, 'nivedita': 5501, 'karimnagar': 5502, 'kowsick': 5503, 'somasundaram': 5504, 'com/r/kowsick': 5505, 'somasundaram/3bd9e5de546cc3c8': 5506, 'itis': 5507, 'eagerness': 5508, 'hardware&': 5509, 'indr': 5510, 'lakshika': 5511, 'neelakshi': 5512, 'annoq': 5513, 'chrome/edge': 5514, 'mouse': 5515, 'width': 5516, 'retain': 5517, 'netweaver': 5518, 'sap/r3': 5519, 'adt': 5520, '/webide': 5521, 'consume': 5522, 'weaver': 5523, 'vizframes': 5524, 'odata/': 5525, 'chrome/firefox': 5526, 'ctu': 5527, 'painter/screen': 5528, 'oriental': 5529, 'petersburg': 5530, 'florida': 5531, 'concentrate': 5532, 'plastic': 5533, 'metal': 5534, 'enclosures': 5535, 'assemblies': 5536, 'reusability': 5537, 'editable': 5538, 'distinct': 5539, '1886': 5540, 'guarantee': 5541, 'column': 5542, 'radial': 5543, 'launchpad': 5544, 'harley': 5545, 'davidson': 5546, 'manufacturer': 5547, 'milwaukee': 5548, 'wisconsin': 5549, '1903': 5550, 'ones': 5551, 'abap/4': 5552, 'madas': 5553, 'peddaiah': 5554, 'moths': 5555, 'customizations/enhancements': 5556, \"emi's\": 5557, 'vani': 5558, '1977': 5559, 'padmavani': 5560, 'madhuri': 5561, 'sripathi': 5562, 'desiging': 5563, 'pyats': 5564, 'stp/rstp': 5565, 'jan2014': 5566, 'qddts': 5567, 'gns3': 5568, 'ethechannelstp': 5569, 'abu': 5570, 'dabhi': 5571, 'layer2': 5572, 'reproductions': 5573, 'mw': 5574, 'repro': 5575, 'ddts': 5576, 'sip200': 5577, 'sip400': 5578, 'sip600': 5579, 'es+': 5580, 'es20': 5581, 'gig': 5582, 'tengig': 5583, 'lancards': 5584, 'rajah': 5585, 'mahesh': 5586, 'vijay': 5587, 'angels': 5588, 'psm': 5589, 'payables': 5590, 'iprocurement': 5591, 'withhold': 5592, 'tds': 5593, 'slm': 5594, '360': 5595, \"suppliers'\": 5596, 'isupplier': 5597, 'manuals/business': 5598, 'manisha': 5599, 'woking': 5600, 'mainframes': 5601, 'almost': 5602, '240': 5603, '2008/2005': 5604, 'odbc': 5605, 'meghnad': 5606, 'saha': 5607, 'vitualization': 5608, 'keyword': 5609, '5+years': 5610, 'qc/alm': 5611, 'di': 5612, 'abn': 5613, 'amro': 5614, \"netherland's\": 5615, 'manjari': 5616, 'cases/scenarios': 5617, 'modem': 5618, 'bcs': 5619, 'roadblocks': 5620, 'hoc': 5621, 'aspen': 5622, 'mentored/trained': 5623, 'satellite': 5624, 'television': 5625, 'exceed': 5626, 'organization/': 5627, 'assisting/leading': 5628, 'cad$': 5629, 'glitch': 5630, 'periods': 5631, 'cpe': 5632, 'modems': 5633, 'thor': 5634, 'tv': 5635, '250/250': 5636, 'bsas': 5637, 'vancouver': 5638, 'bc': 5639, 'netcracker': 5640, 'netprovision': 5641, 'iisy': 5642, 'test/qa': 5643, 'fieldlink': 5644, 'tocp': 5645, 'mediaroom': 5646, 'mediafirst': 5647, 'tdp': 5648, 'rm': 5649, 'mohamed': 5650, 'ameen/': 5651, 'ba052bfa70e4c0b7': 5652, '8x': 5653, '{': 5654, 'mohini': 5655, 'explanation': 5656, 'remote/local': 5657, \"server's\": 5658, 'kiit': 5659, 'iis': 5660, 'wsus': 5661, 'swimmer': 5662, 'lawn': 5663, 'prproject': 5664, 'rbs': 5665, 'w&g': 5666, 'cawp': 5667, 'explain': 5668, 'milagres': 5669, 'kallianpur': 5670, 'modularization': 5671, 'java/c/c++': 5672, 'navjyot': 5673, 'rathore': 5674, 'com/r/navjyot': 5675, 'rathore/': 5676, 'ad92079f3f1a4cad': 5677, 'tybms': 5678, 'vedanta': 5679, 'cllg': 5680, 'a+': 5681, 'nazish': 5682, 'alam': 5683, 'alam/': 5684, 'b06dbac9d6236221': 5685, 'site/': 5686, 'welspun': 5687, 'plate': 5688, 'coil': 5689, 'mill': 5690, 'mm/sd': 5691, 'inspection': 5692, 'painters': 5693, 'medruck': 5694, 'indent': 5695, 'rvdelnote': 5696, 'rvinvoice': 5697, 'gr': 5698, 'sequential': 5699, 'upload/ws': 5700, 'se24': 5701, 's4': 5702, 'cds': 5703, 'amdp': 5704, 'ddl': 5705, 'dml': 5706, 'syntaxes': 5707, 'academeic': 5708, 'uptu': 5709, 'nidhi': 5710, 'pandit': 5711, 'designate': 5712, 'virtualize': 5713, 'belong': 5714, 'initiate/': 5715, 'tell': 5716, 'lisa': 5717, 'apm': 5718, 'nikhileshkumar': 5719, 'ikhar': 5720, 'startups': 5721, 'ikhar/': 5722, 'cb907948c3299ef4': 5723, 'incubate': 5724, 'startup': 5725, 'agriculture': 5726, 'cto': 5727, 'auction': 5728, 'palletization': 5729, 'pallet': 5730, 'buyers': 5731, 'pallets': 5732, 'categorize': 5733, 'nudge': 5734, 'ui/ux': 5735, 'farm': 5736, 'wastage': 5737, 'buyer': 5738, 'usda': 5739, 'crawler': 5740, 'pdf': 5741, 'neural': 5742, 'vulnerabilities': 5743, 'onepk': 5744, 'vit': 5745, 'com/nik': 5746, 'hil': 5747, '//linkedin': 5748, 'com/in/nikhar': 5749, 'categorization': 5750, 'paginations': 5751, 'moderator': 5752, 'modals': 5753, 'customisations': 5754, 'inpeople': 5755, 'appdesigner': 5756, 'adequate': 5757, 'com/shop': 5758, 'com/tickitbusdemourl': 5759, 'kathmandu': 5760, 'pokhra': 5761, 'com/geisle/index': 5762, 'animations': 5763, 'geisle/index2': 5764, 'com/fulllogin': 5765, 'com/sec': 5766, 'combinations': 5767, 'com/r&d': 5768, 'parallax': 5769, 'com/web1': 5770, 'bcet': 5771, 'vtu': 5772, 'composite': 5773, 'peoplecode': 5774, 'pradeeba': 5775, 'toolkit': 5776, 'xwt': 5777, 'finux': 5778, 'totally': 5779, 'datagrid': 5780, 'inquire': 5781, '1980': 5782, 'prakriti': 5783, 'shaurya': 5784, 'vibrant': 5785, 'stable': 5786, 'notre': 5787, 'dame': 5788, 'oral': 5789, 'punctuality': 5790, 'prashanth': 5791, 'badala': 5792, 'badala/': 5793, 'bf4c4b7253a8ece7': 5794, 'web/appservers': 5795, 'hudson': 5796, 'union': 5797, 'war/ear': 5798, 'jenkins/hudson': 5799, 'jdk1': 5800, 'heap': 5801, 'xms': 5802, 'xmx': 5803, 'xnoopt': 5804, 'xnohup': 5805, 'tech/b': 5806, 'senor': 5807, \"amat's\": 5808, 'buyers/suppliers': 5809, 'fgi': 5810, 'lli': 5811, 'dayanand': 5812, 'admin/desktop/plus/': 5813, 'prem': 5814, 'koshti': 5815, 'energetic': 5816, 'harisingh': 5817, 'gour': 5818, 'damoh': 5819, 'holiday': 5820, \"employee's\": 5821, 'updation': 5822, \"record's\": 5823, 'absenteeism': 5824, 'arrear': 5825, 'dues': 5826, 'computerize': 5827, 'reconcile': 5828, 'esic': 5829, 'reception': 5830, 'mineral': 5831, 'biscuits': 5832, 'trainingig': 5833, 'john': 5834, 'ambulance': 5835, 'fight': 5836, 'usha': 5837, 'safety': 5838, 'pulkit': 5839, 'saxena': 5840, 'jammu': 5841, 'kashmir': 5842, '2008r2\\\\server': 5843, 'subnetting': 5844, 'v1/v2': 5845, 'igrp': 5846, '1900': 5847, '2960': 5848, '2500': 5849, '1800': 5850, 'dotlq': 5851, '5500': 5852, 'nfs': 5853, 'nis': 5854, 'terminals': 5855, 'mcl': 5856, 'ignou': 5857, 'tactfully': 5858, 'acese': 5859, 'rim': 5860, 'acrobat': 5861, 'micromedia': 5862, 'cmd': 5863, 'singh/cb1ede9ee6d21bca': 5864, 'trigent': 5865, 'onwards': 5866, 'enc': 5867, 'institute/board': 5868, 'essbase': 5869, 'com/in/puneet': 5870, '277a11151': 5871, 'bollu': 5872, 'alarm': 5873, 'platforms/continuous': 5874, 'construct': 5875, 'vaughn': 5876, 'aeronautics': 5877, 'rajeev': 5878, 'infosys/offshore': 5879, 'erudite': 5880, 'it/presales/project': 5881, 'digital/social': 5882, 'endow': 5883, 'extracurricular': 5884, 'analytical/logical': 5885, 'differentiate': 5886, 'constraints': 5887, 'zest': 5888, 'ior': 5889, '/offshore': 5890, 'graphy': 5891, 'ultant': 5892, 'eam': 5893, 'recommendation': 5894, 'literature': 5895, 'development/configuration': 5896, 'vertical/service/solution': 5897, 'brochures': 5898, 'pgdm': 5899, 'hubspot': 5900, 'addi': 5901, 'tional': 5902, 'innovator': 5903, 'pe': 5904, 'ram': 5905, 'edupuganti': 5906, 'appplicatoins': 5907, 'absences': 5908, 'succession': 5909, 'implantations': 5910, \"macy's\": 5911, 'pike': 5912, 'telcom': 5913, \"clients'\": 5914, 'stipulations': 5915, 'unsupervised': 5916, 'snowflake': 5917, 'aggregations': 5918, 'bics': 5919, 'dvcs': 5920, 'oac': 5921, 'otbi': 5922, 'mappings': 5923, 'uml': 5924, 'jdk': 5925, 'applications/database/sql/batch': 5926, 'corrections': 5927, 'secretary': 5928, 'a&m': 5929, 'kingsville': 5930, 'tx': 5931, '1994': 5932, '1992': 5933, 'parallely': 5934, 'commodities': 5935, 'commodity': 5936, 'cad': 5937, 'cam': 5938, 'healthy': 5939, 'annually': 5940, 'hassan': 5941, 'genearation': 5942, 'forcasting': 5943, 'demonstration': 5944, 'ramya': 5945, 'nga': 5946, 'llu': 5947, 'requirements/test': 5948, 'plan/test': 5949, 'approach/': 5950, 'techniques/': 5951, 'liberty': 5952, 'heath': 5953, 'graphana': 5954, 'acheviments': 5955, 'excuting': 5956, 'stopper': 5957, 'vasundhara': 5958, 'pragathi': 5959, 'sdlc&stlc': 5960, 'ait': 5961, 'intelligent': 5962, 'arunravi': 5963, 'caterpillar]': 5964, 'tech]': 5965, 'johannesburg': 5966, 'wm/sd/mm': 5967, \"'tu\": 5968, \"weight'\": 5969, 'waive': 5970, 'urg': 5971, 'dealer': 5972, 'rearrangement': 5973, 'jdc': 5974, 'clientis': 5975, 's3g': 5976, 'kair': 5977, 'bauer': 5978, 'hockey': 5979, 'finalization': 5980, 'vplm': 5981, 'bom': 5982, 'specs': 5983, 'voletix': 5984, 'momentive': 5985, 'ecci': 5986, 'vat': 5987, 'outline': 5988, '/it': 5989, 'configuration/': 5990, 'requirements/': 5991, '/gap': 5992, 'coding/debugging': 5993, 'functional/': 5994, 'spec': 5995, 'afs': 5996, 'shankar': 5997, 'eps': 5998, '5th': 5999, 'padmshree': 6000, 'patil': 6001, 'pimpri': 6002, 'software/hardware': 6003, 'blank': 6004, 'scdpm': 6005, 'scvmm': 6006, 'runbooks': 6007, 'runbook': 6008, '/2008': 6009, '/2003': 6010, 'win8': 6011, '1/win8/win7/vista/xp': 6012, 'flavor': 6013, 'distributions': 6014, 'hat/fedora': 6015, '/centos/debian': 6016, 'virtualbox': 6017, 'shivgond': 6018, 'rejoin': 6019, 'yernalli': 6020, 'allen': 6021, 'bradley': 6022, 'prolific': 6023, 'scada': 6024, 'vfd': 6025, '\"mat': 6026, 'applications\"': 6027, 'e&ee': 6028, 'gndec': 6029, 'rohit': 6030, 'bijlani': 6031, 'itarsi': 6032, 'headoffice': 6033, 'hartford': 6034, 'srq': 6035, 'rating/quoting': 6036, 'traditional': 6037, 'representatives': 6038, 'underwriters': 6039, 'product/': 6040, 'dld': 6041, 'km': 6042, 'tips/quizzes/sessions': 6043, 'theoretical': 6044, 'eng': 6045, 'itm': 6046, 'roshan': 6047, 'sinha': 6048, 'petrochemicals': 6049, 'maintainence': 6050, 'emm': 6051, 'dispatch': 6052, 'imei': 6053, 'imsp': 6054, 'fm': 6055, 'credit/invoice': 6056, 'repacking': 6057, 'reprint': 6058, 'c/f': 6059, 'dim': 6060, 'ehs': 6061, 'lack1': 6062, 'ck2/ck3': 6063, 'override': 6064, 'gts': 6065, 'webui': 6066, 'infotype': 6067, 'dhir': 6068, 'sasken': 6069, 'realys': 6070, 'signally': 6071, 'replace': 6072, 'adjacent': 6073, 'seps': 6074, 'statute': 6075, 'valorem': 6076, 'levy': 6077, 'max': 6078, 'pmjj': 6079, 'pradhan': 6080, 'jeevan': 6081, 'jyoti': 6082, 'bima': 6083, 'yojana': 6084, 'death': 6085, 'csb': 6086, 'could': 6087, 'hardly': 6088, 'similar': 6089, 'ptu': 6090, 'jalhandar': 6091, '400': 6092, 'domian': 6093, 'patha': 6094, 'mesb': 6095, 'osb': 6096, '7v': 6097, '8v': 6098, 'gw': 6099, 'cloudhub': 6100, 'benchmarking': 6101, 'enrichment': 6102, 'tiered': 6103, 'ally': 6104, 'dev/test/prod': 6105, 'log4j': 6106, 'wrapper': 6107, 'fellow': 6108, \"developers'\": 6109, 'mom': 6110, 'mel': 6111, 'weave': 6112, 'oat': 6113, 'properly': 6114, 'apikit': 6115, 'fsms': 6116, 'smtp': 6117, 'ftp/sftp': 6118, 'rma': 6119, 'ai': 6120, 'c3': 6121, 'token': 6122, 'fine': 6123, 'mmc': 6124, 'oracle11i': 6125, 'omlss': 6126, 'boundary': 6127, 'pseudo': 6128, 'code/algorithms/test': 6129, \"'go\": 6130, \"live'\": 6131, 'workarounds/': 6132, 'insertion': 6133, 'synchro': 6134, 'pvcs': 6135, 'itcs': 6136, 'drilldowns': 6137, 'bench': 6138, 'swb': 6139, 'extjs': 6140, 'boss': 6141, 'sphere': 6142, 'facade': 6143, 'dto': 6144, 'locator': 6145, 'jax': 6146, 'rs': 6147, \"ide's/tools\": 6148, 'java/j2eetechnologies': 6149, 'venkatraman': 6150, 'decisive': 6151, 'venkatraman/': 6152, 'a009f49bfe728ad1': 6153, 'optimistic': 6154, 'maker': 6155, 'negotiator': 6156, 'world’s': 6157, 'adhiparasakthi': 6158, 'samyuktha': 6159, 'shivakumar': 6160, 'shivakumar/': 6161, 'cabce09fe942cb85': 6162, 'stay': 6163, \"product's\": 6164, 'buzzsumo': 6165, 'hootsuite': 6166, 'tweet': 6167, 'deck': 6168, 'buzzstream': 6169, 'wistia': 6170, 'quora': 6171, 'uganda': 6172, 'mateo': 6173, 'team’s': 6174, 'continually': 6175, 'alliances': 6176, '‘most': 6177, 'player’': 6178, 'contest': 6179, 'tesco': 6180, 'mount': 6181, 'carmel': 6182, 'santosh': 6183, 'ganta': 6184, 'cics': 6185, 'rexx': 6186, 'ispf': 6187, 'spufi': 6188, 'mainview': 6189, 'librarian': 6190, 'xpeditor': 6191, 'sarfaraz': 6192, 'muzaffarpur': 6193, 'internetwork': 6194, 'lan/wan/network': 6195, 'cmip': 6196, '7200/7600': 6197, '/juniper': 6198, 'mx104': 6199, '7750': 6200, 'compatibilities': 6201, 'parent': 6202, 'either': 6203, 'getaway': 6204, 'juniper': 6205, 'huawei': 6206, 'qnq': 6207, 'vty': 6208, 'redundancies': 6209, 'severe': 6210, 'responsibilities/achievement': 6211, 'channel/port': 6212, 'bpdu': 6213, 'examination': 6214, 'pvst': 6215, 'pvst+': 6216, 'mst': 6217, 'span/rspan': 6218, 'pagp': 6219, 'fhrp': 6220, 'v1': 6221, 'v2': 6222, 'float': 6223, 'lite': 6224, 'fw': 6225, 'clusterxl': 6226, 'asa': 6227, 'standby': 6228, 'contexts': 6229, 'zbf': 6230, 'garp': 6231, 'ntp': 6232, 'senthil': 6233, 'stretch': 6234, \"epg's\": 6235, 'replica': 6236, 'decommission': 6237, 'commission': 6238, 'inconsistencies': 6239, 'exi': 6240, 'vcenter': 6241, 'vmotion': 6242, 'iscsi': 6243, 'eft': 6244, 'pseudowire': 6245, 'topology': 6246, 'flush': 6247, 'jumbo': 6248, 'aggregation': 6249, '600': 6250, 'snoop': 6251, 'keymile': 6252, 'eth': 6253, 'flood': 6254, 'untag': 6255, 'iss': 6256, 'gigabit': 6257, 'broadcast': 6258, \"cfd's\": 6259, 'externally': 6260, 'anm': 6261, 'csm': 6262, 'mgr': 6263, 'com/in/senthil': 6264, '9600101b': 6265, 'vsphere': 6266, 'gsr': 6267, '5k': 6268, '6500': 6269, 'shabnam': 6270, 'saba': 6271, 'correlate': 6272, 'dynamism': 6273, 'ag': 6274, 'nav': 6275, 'occasionally': 6276, 'territories': 6277, 'territory': 6278, 'padmanava': 6279, \"joseph's\": 6280, 'shaheen': 6281, 'unissa': 6282, 'unissa/': 6283, 'c54e7a04da30c354': 6284, 'acelor': 6285, 'nnit': 6286, 'may/2008': 6287, 'may/2016': 6288, 'acelormittal': 6289, 'philosophy': 6290, 'sustainable': 6291, 'footprint': 6292, '19': 6293, \"east's\": 6294, 'arab': 6295, 'dh81': 6296, 'us$22': 6297, 'dh32': 6298, 'us$9': 6299, \"etisalat's\": 6300, 'earnest': 6301, '3g': 6302, 'witness': 6303, 'fastest': 6304, 'rocket': 6305, '141': 6306, 'in2013': 6307, 'dynpro': 6308, 'invitation': 6309, 'invitation\"': 6310, 'sf\"': 6311, 'doc': 6312, 'badi\"': 6313, 'kerosene': 6314, 'lagos': 6315, '426': 6316, 'fuel': 6317, 'spread': 6318, 'nigerian': 6319, 'naira': 6320, 'usd': 6321, 'mi01': 6322, 'permit': 6323, 'worlds': 6324, 'sizeable': 6325, 'captive': 6326, '$78': 6327, 'crude': 6328, 'zbapi': 6329, '$1': 6330, 'hpsd': 6331, 'slot': 6332, 'comment': 6333, 'enter': 6334, 'llp': 6335, 'engine/': 6336, 'accumulation': 6337, '1923': 6338, 'caregivers': 6339, 'broadest': 6340, 'insulin': 6341, 'haemophilia': 6342, 'chronic': 6343, 'inflammation': 6344, 'sapmf02k': 6345, 'zxf05u01': 6346, 'marmagao': 6347, '1962': 6348, '27': 6349, '33': 6350, 'though': 6351, 'predominant': 6352, 'steady': 6353, 'liquid': 6354, 'ever': 6355, 'iw33': 6356, 'inward': 6357, 'barge': 6358, 'hydraulic': 6359, 'expire': 6360, 'berth': 6361, 'arrival': 6362, 'vessels': 6363, 'mv45afzz': 6364, 'penal': 6365, '920': 6366, 'rv61a920': 6367, 'tcode': 6368, 'ia05': 6369, \"'rebdpr'\": 6370, 'bu': 6371, \"'rebdbu'\": 6372, 'cn': 6373, \"'recn'\": 6374, 'ro': 6375, \"'rebdro'\": 6376, \"data'\": 6377, \"2'\": 6378, '$6': 6379, 'heavy': 6380, 'highway': 6381, 'agricultural': 6382, 'marine': 6383, 'rail': 6384, 'locate': 6385, 'hierarchical': 6386, 'backorders': 6387, '\"bc\"': 6388, \"bdc's\": 6389, 'ale/': 6390, 'sharan': 6391, 'adla': 6392, 'low/high': 6393, 'wireframes': 6394, 'prototyping': 6395, 'personas': 6396, 'rwd': 6397, 'prolifics': 6398, \"dec'\": 6399, \"oct'\": 6400, '\"the': 6401, 'foundation\"': 6402, 'sparkle': 6403, 'microsites': 6404, 'oow': 6405, 'vizianagaram': 6406, 'gowtham': 6407, 'vignan': 6408, 'vidyalayam': 6409, 'shreyanshu': 6410, 'omnivoracious': 6411, 'kalinga': 6412, 'greymeter': 6413, 'shrishti': 6414, 'fault': 6415, 'transformations': 6416, 'xpath': 6417, 'holts': 6418, 'holt': 6419, '180': 6420, 'canadian': 6421, 'array': 6422, 'luxury': 6423, 'boutiques': 6424, 'mediator': 6425, 'attending/conducting': 6426, 'sept': 6427, \"uk's\": 6428, 'inn': 6429, 'costa': 6430, 'coffee': 6431, 'beefeater': 6432, 'brewers': 6433, 'fayre': 6434, 'shubham': 6435, \"fulfillment's\": 6436, 'sosl': 6437, 'ci/ant': 6438, 'salesforce/cloudsense': 6439, 'superbadge': 6440, 'lightning': 6441, \"refinement's\": 6442, 'lighten': 6443, 'eee': 6444, \"john's\": 6445, 'sivaganesh': 6446, 'selvakumar': 6447, 'deployment/delivery': 6448, 'boundaries': 6449, 'create/submit': 6450, 'acceptance/approval': 6451, 'wiki': 6452, '\"instrumentation': 6453, 'engineering\"': 6454, 'saranathan': 6455, 'msbuild': 6456, 'mstest': 6457, 'cobertura': 6458, 'snehal': 6459, 'jadhav': 6460, 'acesoftlabs': 6461, 'tcp/udp': 6462, 'mp': 6463, 'ipv4/ipv6': 6464, 'vpnv4': 6465, 'vpnv6': 6466, 'multicats': 6467, 'yr': 6468, 'sowmya': 6469, 'karanth': 6470, 'karanth/': 6471, 'a76c9c40c02ed396': 6472, 'namer': 6473, \"americas'\": 6474, \"'yar\": 6475, '\"young': 6476, 'early': 6477, 'achiever\"': 6478, 'eastern': 6479, 'asian': 6480, \"resource'\": 6481, \"'llc\": 6482, \"tool'\": 6483, 'reviewer': 6484, 'globalise': 6485, 'standardise': 6486, 'differences': 6487, 'sectorial': 6488, 'specialisation': 6489, 'deem': 6490, '/interests': 6491, 'srabani': 6492, 'bishnupur': 6493, 'manipur': 6494, '722122': 6495, 'boost': 6496, 'exilant': 6497, 'odm': 6498, 'pubic': 6499, 'ipad': 6500, 'gbi': 6501, 'pulse': 6502, 'benchmark': 6503, 'redzone': 6504, 'crysral': 6505, 'modifcation': 6506, 'store/country': 6507, 'store/market/country': 6508, 'setups': 6509, 'docs': 6510, 'wing': 6511, 'workshops/events': 6512, 'symptoms/': 6513, 'vo': 6514, '15+yrs': 6515, '$40m': 6516, 'organisations': 6517, 'enviable': 6518, 'rfi/rfps': 6519, 'walkthroughs': 6520, '/loss': 6521, 'pilots/proof': 6522, 'talented': 6523, 'possibilities': 6524, 'yield': 6525, 'healthcare/': 6526, 'telecom/': 6527, 'bfsi/supply': 6528, 'fmw': 6529, 'reim': 6530, 'pa': 6531, 'cm': 6532, 'tm': 6533, 'idm': 6534, 'oam': 6535, 'oim': 6536, 'ovd': 6537, 'oid': 6538, 'ebilling': 6539, 'shipments': 6540, 'oracle®': 6541, 'brs': 6542, 'omof': 6543, 'programs/projects': 6544, 'alternate': 6545, 'oats': 6546, 'reqpro': 6547, 'ra': 6548, 'rft': 6549, 'rcc': 6550, 'rcq': 6551, 'appium': 6552, 'jbehave': 6553, 'thinker': 6554, 'implementer': 6555, 'rup': 6556, 'cmmi': 6557, 'successes': 6558, 'clientele': 6559, 'dhl': 6560, 'mobily': 6561, 'royce': 6562, 'derby': 6563, 'hinckley': 6564, 'rcuk': 6565, 'councils': 6566, 'swindon': 6567, 'adat': 6568, 'ohi': 6569, 'netherlands': 6570, 'citibank': 6571, 'transurban': 6572, 'bcbs': 6573, 'shield': 6574, 'ultimately': 6575, 'habari': 6576, 'elasticache': 6577, 'personalization': 6578, 'endurance': 6579, 'spike': 6580, 'wmi': 6581, \"'2010\": 6582, \"testers'\": 6583, 'kakatiya': 6584, 'srushti': 6585, 'bhadale': 6586, 'keycorp': 6587, 'cleveland': 6588, \"customers'\": 6589, 'ruparel': 6590, \"girls'\": 6591, 'sudaya': 6592, 'puranik': 6593, 'pillars': 6594, 'asmt': 6595, 'switchover': 6596, 'mile': 6597, 'adop': 6598, 'bhoomaraddi': 6599, 'belgaum': 6600, 'enginner': 6601, 'sumit': 6602, 'kubade': 6603, 'assignments': 6604, 'graduation': 6605, '0in': 6606, 'uv': 6607, 'technocrats': 6608, '&functional': 6609, '&assign': 6610, '02/fb50': 6611, 'sundry': 6612, 'creditors': 6613, 'fb60': 6614, '/miro': 6615, 'fb70': 6616, 'encashment': 6617, 'cancellation': 6618, 'afab': 6619, '92': 6620, 'ajab': 6621, 'obh2': 6622, 'fsv': 6623, 'issues/tickets': 6624, 'moderate': 6625, 'program/form': 6626, 'indicator': 6627, 'secretory': 6628, 'appear': 6629, 'devendla/': 6630, 'c9ba7bc582b14a7b': 6631, 'smts': 6632, 'hackerrank': 6633, 'multithreaded': 6634, 'eight': 6635, 'windbg': 6636, 'sqoop': 6637, 'hbase': 6638, 'zookeeper': 6639, 'audioout': 6640, 'audioin': 6641, 'commercialize': 6642, 'mobiles': 6643, 'twenty': 6644, 'ipc': 6645, 'beyond': 6646, 'leak': 6647, 'coveragetool': 6648, 'vs2005': 6649, 'diagnosabilty': 6650, 'enhancer': 6651, 'ibots': 6652, 'fix/enhance': 6653, 'ibot': 6654, 'delivers/agent/schedulers': 6655, 'nqscheduler': 6656, 'embeddable': 6657, 'tlp': 6658, 'dte': 6659, 'phrase': 6660, 'overburden': 6661, 'fright': 6662, 'playback': 6663, 'platformsy2012': 6664, 'platformsy2011': 6665, 'bada2': 6666, 'preview': 6667, 'trim': 6668, 'veplayer': 6669, 'vpl': 6670, \"bada's\": 6671, 'pls': 6672, 'emulator': 6673, 'etms': 6674, 'wabtec': 6675, 'town': 6676, 'iar': 6677, 'wre': 6678, 'supt': 6679, 'superintendents': 6680, 'elevators': 6681, 'escalators': 6682, 'fldlink': 6683, 'gunnam': 6684, 'scriptsfor': 6685, 'regressiontesting': 6686, 'acquaint': 6687, 'scrubber': 6688, 'mantis': 6689, 'profound': 6690, 'goldstone': 6691, 'csos': 6692, 'cso': 6693, 'normalization': 6694, 'file/': 6695, 'unmanaged': 6696, 'density': 6697, 'vulnerability': 6698, 'bear': 6699, 'correctness': 6700, '&sql': 6701, '98/xp': 6702, '&unix': 6703, 'runner7': 6704, 'aaa': 6705, 'tacacs': 6706, 'vpns': 6707, 'urshila': 6708, 'lohani': 6709, 'intuit': 6710, 'religare': 6711, 'attendees': 6712, '$1m': 6713, '322': 6714, 'fy17': 6715, 'fy18': 6716, '$4m': 6717, 'towns': 6718, 'induct': 6719, 'cxos': 6720, '$400k': 6721, 'hoover': 6722, 'resellers': 6723, 'counterparts': 6724, 'kit': 6725, 'q1': 6726, 'q2': 6727, 'fy12': 6728, 'honor': 6729, 'vamsi': 6730, 'com/r/vamsi': 6731, 'krishna/15906b55159d4088': 6732, 'gnanambika': 6733, 'varun': 6734, 'ahluwalia': 6735, 'ndeed': 6736, 'com/r/varun': 6737, 'ahluwalia/725d9b113f3c4f0c': 6738, 'tavant': 6739, 'ingersoll': 6740, 'rand': 6741, 'lender': 6742, 'ameriquest': 6743, 'patni': 6744, 'profitability': 6745, 'il': 6746, 'govindarajan/': 6747, 'd71bfb70a66b0046': 6748, 'thiagarajar': 6749, 'sathya': 6750, 'aix': 6751, 'bottle': 6752, 'neck': 6753, 'db13': 6754, 'activate': 6755, 'slt': 6756, 'pas': 6757, 'trax': 6758, 'cps': 6759, 'vertex': 6760, '\"manager\\'s': 6761, 'choice': 6762, 'crisis': 6763, '\"deep': 6764, 'adder': 6765, 'snote': 6766, 'spam/saint': 6767, 'slds': 6768, 'unilever': 6769, 'creating/modifying': 6770, 'pesonal': 6771, 'vikas': 6772, 'bluecoat': 6773, 'fee': 6774, 'ingestion': 6775, 'iocs': 6776, 'tanium': 6777, 'fireeye': 6778, 'hx': 6779, 'feed': 6780, 'explode': 6781, 'flag': 6782, 'mssp': 6783, 'append': 6784, 'disable': 6785, 'departure': 6786, 'provisioning/de': 6787, 'administrators': 6788, 'corrective': 6789, 'pip': 6790, 'segregation': 6791, 'violation': 6792, 'sod': 6793, 'infraction': 6794, 'violations': 6795, 'justification': 6796, 'gla': 6797, 'sailpoint': 6798, 'beeline': 6799, 'yasothai': 6800, 'jayaramachandran': 6801, 'jayaramachandran/': 6802, 'c36e76b64d9f477f': 6803, 'eclipse[pydev': 6804, 'plugin]': 6805, '1000+': 6806, 'cdets/rally': 6807, 'hornet': 6808, 'ipng': 6809, 'border': 6810, 'ao': 6811, '200+': 6812, 'phase2': 6813, 'pi19': 6814, '&phase2': 6815, '535': 6816, 'netflow': 6817, 'acceleration': 6818, 'interoperation': 6819, 'transparency': 6820, 'plaform': 6821, '600+': 6822, 'bugs/defects': 6823, 'sprit': 6824, 'wafs': 6825, 'intercept': 6826, 'redirect': 6827, 'adventist': 6828, 'matric': 6829, 'wae': 6830, 'wccp': 6831, 'pydev[plugin': 6832, 'ide]': 6833, 'earms': 6834, 'acme': 6835, 'htmltestrunner': 6836, 'aras': 6837, 'aml': 6838, 'markup': 6839, 'xp/10': 6840, 'yathishwaran': 6841, 'nandha': 6842, 'boys': 6843, 'pallipalayam': 6844, 'coda': 6845, 'yogi': 6846, 'pesaru': 6847, 'pi/xi': 6848, 'hci': 6849, 'atomsphere': 6850, 'exceptions': 6851, 'udms': 6852, 'ichannel': 6853, 'cts+': 6854, 'confirm': 6855, 'oder': 6856, 'synchronously': 6857, 'hindupur': 6858, 'hosanna': 6859, 'c+': 6860, 'asthana': 6861, 'cognitive': 6862, 'sdks': 6863, 'underwrite': 6864, '[web': 6865, \"api's]\": 6866, 'moss': 6867, 'limitations': 6868, 'kashipur': 6869, 'knockoutjs': 6870, 'syed': 6871, 'ali': 6872, 'com/r/syed': 6873, 'ali/cf3a21da22da956d': 6874, 'kgisl': 6875, 'nida': 6876, 'khan': 6877, 'khan/6c9160696f57efd8': 6878, 'bhel': 6879, 'heep': 6880, 'haridwar': 6881, 'cnc': 6882, 'system&amp': 6883, 'execu': 6884, 've': 6885, 'adfc': 6886, 'banker': 6887, 'en': 6888, 'gg': 6889, 'gnit': 6890, 'ars': 6891, 'khan/6c9160696f57': 6892, 'fenil': 6893, 'francis': 6894, 'com/r/fenil': 6895, 'francis/445e6b4cb0b43094': 6896, 'equipments': 6897, 'kamaraj': 6898, 'abiliti': 6899, 'capabi': 6900, 'gaurav': 6901, 'com/r/gaurav': 6902, 'soni/d492b5b1697f7f66': 6903, 'repurchase': 6904, 'anvil': 6905, 'component/service': 6906, 'keywords': 6907, 'ggsipu': 6908, 'kullu': 6909, \"year's\": 6910, 'emcee': 6911, 'wife': 6912, 'ngo': 6913, 'tourist': 6914, 'décor': 6915, 'exhibitions': 6916, 'remotely': 6917, 'logon': 6918, 'configure/': 6919, 'incident/change': 6920, 'request/ticket': 6921, 'rename': 6922, 'procurement/replacement': 6923, 'pwc': 6924, 'activations': 6925, 'nitte': 6926, 'meenakshi': 6927, 'awwa': 6928, \"viny's\": 6929, 'vlog': 6930, 'youtube': 6931, 'orator': 6932, 'amarjyot': 6933, 'sodhi': 6934, 'just': 6935, 'shuttl': 6936, 'sutherland': 6937, 'outbound/inbound': 6938, 'customs': 6939, 'cx': 6940, 'zaheer': 6941, 'uddin': 6942, 'standpoint': 6943, 'erm': 6944, 'resolve/escalate': 6945, 'impediments': 6946, 'dmaic': 6947, 'tickets/resolu': 6948, 'tions': 6949, 'lead/operations': 6950, 'anager': 6951, '68': 6952, '000+': 6953, \"sku's\": 6954, 'hotmail': 6955, '2000/2003': 6956, 'shortages': 6957, 'tender': 6958, 'cas': 6959, 'cpus': 6960, 'microprocessors': 6961, 'tickets/calls': 6962, 'ed': 6963, 'uc': 6964, 'ation': 6965, 'osmani': 6966, 'abdul': 6967, 'supporter': 6968, 'thomson': 6969, 'reuters': 6970, 'lg': 6971, 'urdu': 6972, 'wadi': 6973, 'int': 6974, 'arabic/islamic': 6975, 'interpreter': 6976, 'linguist': 6977, 'sp1': 6978, 'version5': 6979, '\"product': 6980, 'studio\"': 6981, 'project#5': 6982, 'analog': 6983, 'palghat': 6984, 'com/r/bike': 6985, 'rally/e00d408e91e83868': 6986, 'edius': 6987, 'proshow': 6988, 'gold': 6989, 'thomas': 6990, 'george': 6991, 'chairman': 6992, 'dhoni': 6993, 'touch': 6994, 'adventure': 6995, 'panchayat': 6996, 'elections': 6997, 'ambras@lead': 6998, 'girish': 6999, 'describe': 7000, 'chance': 7001, 'ops/site': 7002, 'reliability': 7003, 'telemetry': 7004, 'prototypes': 7005, 'it’s': 7006, 'biggest': 7007, 'bcp/': 7008, '“testing': 7009, 'production”': 7010, 'requests/day': 7011, 'eventual': 7012, 'mcpdea': 7013, 'net*': 7014, 'designing/architecting/building/testing/deploying': 7015, 'apps/apis': 7016, 'rest/wcf': 7017, 'subscription': 7018, 'encryption': 7019, 'adfs/sts': 7020, 'documentation/code': 7021, 'diagnostics': 7022, 'avicode': 7023, 'cmdlets': 7024, 'inclusion': 7025, '250+': 7026, 'transactions/day': 7027, 'brick': 7028, 'mortar': 7029, 'rhinomock': 7030, '/defects': 7031, 'service/api': 7032, 'architec': 7033, 'ture': 7034, 'cl': 7035, 'ient': 7036, 'wrap': 7037, 'clien': 7038, 'technet': 7039, 'sts': 7040, 'simulate': 7041, 'visibility': 7042, 'configurable': 7043, 'empowerment': 7044, 'however': 7045, 'larger': 7046, 'aggregate': 7047, 'transcodes': 7048, 'solutioning': 7049, 'idc': 7050, 'intensive': 7051, \"cloud's\": 7052, 'sensitive': 7053, 'succ': 7054, 'essfully': 7055, 'pdc': 7056, 'half': 7057, 'classes/database/user': 7058, 'statefarm': 7059, 'aics': 7060, 'saas/multi': 7061, 'landsend': 7062, 'parcel': 7063, 'fedex': 7064, 'emr': 7065, \"usps's\": 7066, \"'electronic\": 7067, \"solution'\": 7068, \"what's\": 7069, 'starbucks': 7070, 'coca': 7071, 'cola': 7072, 'dynamically': 7073, 'csss': 7074, 'publishers': 7075, 'bitly': 7076, 'june2008': 7077, 'architects': 7078, 'drawing/': 7079, 'wf': 7080, 'dsm': 7081, 'june2006': 7082, 'hr/scheduling/sales': 7083, 'talking/calling/interviewing': 7084, 'bse': 7085, 'trader': 7086, 'inbuilt': 7087, 'asha': 7088, 'subbaiah': 7089, 'pcmm': 7090, 'tele': 7091, 'korea': 7092, 'conclude': 7093, 'continents': 7094, 'intimately': 7095, \"director's\": 7096, \"ibm's\": 7097, 'joi': 7098, 'ned': 7099, 'egl': 7100, '5000': 7101, 'foot': 7102, 'irl': 7103, 'focal': 7104, 'gvi': 7105, 'wbs': 7106, 'reso': 7107, 'stp/customs/logistics': 7108, 'controls/ero/bcp': 7109, 'nmkrv': 7110, 'bangalor': 7111, 'divesh': 7112, 'com/r/divesh': 7113, 'singh/a76ddf6e110a74b8': 7114, 'handwrite': 7115, 'solo': 7116, 'sing': 7117, 'cricketer': 7118, 'motiva': 7119, 'chokkala': 7120, 'chokkala/16d5fa56f8c19eb6': 7121, 'trinity': 7122, 'ganesh': 7123, 'alalasundaram': 7124, 'lead/sdet/': 7125, 'master/program': 7126, 'dd5b500021e61f65': 7127, 'positively': 7128, 'handshaking': 7129, 'brown': 7130, 'bag': 7131, 'retrospectives': 7132, 'vso': 7133, 'hour': 7134, 'boarding/reporting': 7135, 'pubsec': 7136, 'dubai/columbia/new': 7137, 'avg': 7138, '\"voice': 7139, '//blogs': 7140, 'com/ganesh/': 7141, 'com/ganesh': 7142, 'ganeshalalasundaram': 7143, 'hool': 7144, 'ny': 7145, 'srinu': 7146, 'ramavath': 7147, 'anymore': 7148, 'serilingampalle': 7149, 'com/r/srinu': 7150, 'ramavath/2d9f28ccfa115f79': 7151, 'gachibowli': 7152, \"person's\": 7153, 'valiball': 7154, 'firesafety': 7155, 'bhandari': 7156, 'mexico': 7157, 'twelve': 7158, 'et': 7159, 'adient': 7160, 'relative': 7161, 'nine': 7162, 'separation': 7163, 'ptp': 7164, 'ptd': 7165, 'rtr': 7166, 'copco': 7167, 'thirty': 7168, 'nordics': 7169, 'agri': 7170, 'ten': 7171, 'bpp': 7172, 'duet': 7173, 'bok': 7174, 'reusable': 7175, 'sustainability': 7176, 'cummins': 7177, 'coe': 7178, 'preconfigured': 7179, 'sixteen': 7180, 'unification': 7181, 'rotational': 7182, 'p100': 7183, 'p200': 7184, 'exams': 7185, 'vaishnav': 7186, 'rgpv': 7187, 'shanti': 7188, 'aarti': 7189, 'pimplay': 7190, 'breaks/lunch': 7191, 'changeover': 7192, 'disciplinary': 7193, 'evaluations': 7194, 'supervis': 7195, 'gsoc': 7196, 'sitel': 7197, 'improve/create': 7198, 'kb': 7199, 'modular': 7200, 'infor': 7201, 'mation': 7202, 'overcome': 7203, 'objections': 7204, 'com/r/bangalore': 7205, 'tavarekere/8fc92a48cbe9a47c': 7206, '560029': 7207, 'christ': 7208, 'avani': 7209, 'priya': 7210, 'javatally': 7211, 'girl': 7212, \"don't\": 7213, 'br': 7214, 'begusarai': 7215, 'sanand': 7216, 'ssas': 7217, 'developer/sustain': 7218, 'fwb': 7219, 'usnaforecast': 7220, 'atu': 7221, 'corpnet': 7222, 'upstream': 7223, 'discussions/sessions': 7224, 'bugs/': 7225, 'issues/defects/crs': 7226, 'ts': 7227, 'promptly': 7228, 'partho': 7229, 'com/r/partho': 7230, 'mitra/683dfd08d0246836': 7231, 'pranay': 7232, 'sathu': 7233, 'ba': 7234, 'ux': 7235, 'discussion': 7236, 'ambiguity': 7237, 'scenarios/sessions': 7238, 'neudesic': 7239, 'epam': 7240, 'srec': 7241, 'speflow': 7242, 'tanmoy': 7243, 'maity': 7244, 'com/r/tanmoy': 7245, 'maity/145eb1ed39df317c': 7246, 'mrac': 7247, 'gtti': 7248, 'aanirudh': 7249, 'razdan': 7250, 'com/r/aanirudh': 7251, 'razdan/efbf36cc74cec0e5': 7252, 'gradation': 7253, 'windwos': 7254, 'xp/vista/7/8/8': 7255, '1/10': 7256, 'b2x': 7257, 'nest': 7258, 'shiksha': 7259, 'bhatnagar': 7260, 'chnadigarh': 7261, 'com/r/shiksha': 7262, 'bhatnagar/70e68b28225ca499': 7263, 'chhaya': 7264, 'prabhale': 7265, '411014': 7266, 'reorder': 7267, '\"gas': 7268, 'system\"': 7269, 'experiance': 7270, 'manipulation': 7271, 'navigational': 7272, '2018h2': 7273, 'shell/perl': 7274, 'geographic': 7275, 'gdf': 7276, '15+': 7277, 'gement': 7278, 'nars': 7279, 'monji': 7280, '7a25462/': 7281, '7a2': 7282, '5462/': 7283, 'mohammed': 7284, 'murtuza': 7285, 'executives/gms': 7286, 'change/premium': 7287, \"l1's\": 7288, 'normal': 7289, 'insure': 7290, 'incidents/outages': 7291, 'techs': 7292, 'week': 7293, 'incidents/': 7294, 'reoccurrence': 7295, 'preparations': 7296, 'mortem/root': 7297, 'coordinators': 7298, 'forums': 7299, 'invensys': 7300, 'esx': 7301, 'lync': 7302, 'contractors/vendors': 7303, 'writers': 7304, \"queue's\": 7305, 'siemens': 7306, 'consumables': 7307, 'armstrong': 7308, 'diligently': 7309, 'free/busy': 7310, 'activesync': 7311, 'rpc': 7312, 'explorer': 7313, 'mozilla': 7314, 'probe': 7315, 'xp/': 7316, 'vista/7': 7317, \"pc's\": 7318, 'appendages': 7319, 'keting': 7320, 'esources': 7321, 'ana': 7322, 'elect': 7323, 'ronics': 7324, 'hy': 7325, 'derabad': 7326, 'saurabh/87e6b26903460061': 7327, 'prabhu': 7328, 'mohapatra': 7329, 'urgently': 7330, 'bhubaneswar': 7331, 'com/r/prabhu': 7332, 'mohapatra/1e4b62ea17458993': 7333, 'xiaomi': 7334, 'still': 7335, 'bhagabati': 7336, 'sarakana': 7337, 'typewrite': 7338, 'raja': 7339, 'mouli': 7340, 'com/r/raja': 7341, 'mouli/445cbf3eb0a361cd': 7342, 'ards': 7343, 'collage': 7344, 'kadapa': 7345, 'prasad/56249a1d0efd3fca': 7346, 'omen': 7347, 'traini': 7348, 'enjoy': 7349, 'chauhan/7fd59212dcc556bd': 7350, 'teachers': 7351, 'sunder': 7352, 'emancipate': 7353, 'secondry': 7354, 'pcm': 7355, 'tl': 7356, 'dat': 7357, 'rishabh': 7358, 'anuppur': 7359, 'com/r/rishabh': 7360, 'soni/503ce837ae2924ff': 7361, 'specilization': 7362, 'regal': 7363, 'raptor': 7364, 'choppers': 7365, 'cruiser': 7366, '[coo]': 7367, 'domestically': 7368, \"sop's\": 7369, '\"regal': 7370, 'raptor\"': 7371, 'recognisable': 7372, 'delegate': 7373, 'instill': 7374, 'competitiveness': 7375, 'gross': 7376, 'margin': 7377, \"patrick's\": 7378, 'specialties': 7379, 'overheads': 7380, \"enablement's\": 7381, '[dell]': 7382, 'uk/ireland': 7383, 'motion': 7384, 'difference': 7385, 'dhtml': 7386, 'fab': 7387, 'masqati': 7388, 'haras': 7389, 'smen': 7390, 'karan': 7391, 'turkar': 7392, 'balaghat': 7393, 'com/r/karan': 7394, 'turkar/9ed71ae013a9e899': 7395, 'davv': 7396, 'akshay': 7397, 'dubey/87dcd40b335e6ffa': 7398, 'msp': 7399, 'recognizable': 7400, 'demonstrable': 7401, 'societies': 7402, 'preferably': 7403, 'ceo': 7404, 'satya': 7405, 'nadella': 7406, 'techdays': 7407, 'devcon': 7408, '//akshaydubey': 7409, 'associa': 7410, 'promotional': 7411, 'especially': 7412, 'undergraduates': 7413, 'influencers': 7414, 'emulato': 7415, 'dubey/': 7416, '87dcd40b335e6ffa': 7417, 'msps': 7418, '//admicrosoft': 7419, 'blogspot': 7420, 'in/': 7421, 'ninja': 7422, 'wall': 7423, 'databa': 7424, 'inhgad': 7425, 'jav': 7426, 'ascript': 7427, 'chnical': 7428, 'cpp': 7429, 'v2013': 7430, 'v2008': 7431, '1/': 7432, 'sayani': 7433, 'goswami': 7434, 'com/r/sayani': 7435, 'goswami/066e4d4956f82ee3': 7436, 'promoter': 7437, 'sweety': 7438, 'garg': 7439, 'com/r/sweety': 7440, 'garg/9f2d2afa546d730d': 7441, 'ramkrishan': 7442, 'com/r/ramkrishan': 7443, 'bhatt/': 7444, 'da07dc6d058dfc64': 7445, 'polymer': 7446, 'word2vec': 7447, 'jupiter': 7448, 'jpa': 7449, 'sqlite': 7450, 'webex': 7451, 'gantter': 7452, 'b1': 7453, 'b2': 7454, '2025': 7455, 'dadabari': 7456, 'ajmer': 7457, 'kota': 7458, 'com/r/b': 7459, '/ca7750b94830268d': 7460, 'inspire': 7461, 'acumen': 7462, 'ftware': 7463, 'aadhar': 7464, 'rfid': 7465, 'vote': 7466, 'univ': 7467, 'ersi': 7468, 'com/r': 7469, '/b': 7470, 'anand': 7471, 'com/r/anand': 7472, 's/ce230cad6115ae68': 7473, 'sport': 7474, 'soccer': 7475, 'kabbadi': 7476, 'swim': 7477, 'kannada': 7478, 'tail': 7479, 'danapur': 7480, 'sandhikar/': 7481, 'e490c0d49e5aa698': 7482, 'hike': 7483, 'road/weather': 7484, 'hundreds': 7485, 'wrongly': 7486, 'terminate': 7487, 'flaw': 7488, 'because': 7489, 'gitam': 7490, 'delta': 7491, 'jee': 7492, 'georges': 7493, 'grammar': 7494, 'leadlab': 7495, 'sharpers': 7496, 'fellowship': 7497, 'ankit': 7498, 'fadia': 7499, 'championship': 7500, 'javasc': 7501, 'priyesh': 7502, 'philips': 7503, 'mvvm': 7504, 'ooad': 7505, 'tremendous': 7506, 'dependable': 7507, 'shooter': 7508, 'conceptualization': 7509, 'devel': 7510, 'op': 7511, 'manit': 7512, 'laya': 7513, 'restructure': 7514, 'obscure': 7515, 'assimilable': 7516, 'attainment': 7517, \"firm's\": 7518, 'grievance': 7519, 'vela': 7520, 'mmal': 7521, 'ne': 7522, 'talentacquisition': 7523, 'probable': 7524, 'curb': 7525, 'relatively': 7526, 'lesser': 7527, 'elite': 7528, 'law': 7529, 'talents': 7530, 'vacant': 7531, 'strategizing': 7532, 'consultation': 7533, 'departmental': 7534, 'devise': 7535, 'hierarchy': 7536, 'concord': 7537, 'attractive': 7538, 'optimise': 7539, 'enthusiasm': 7540, 'nestle': 7541, 'equilibrium': 7542, 'kinder': 7543, 'cherthala': 7544, 'leonine': 7545, 'associate@': 7546, 'dia': 7547, 'uit': 7548, 'erala': 7549, 'morale': 7550, 'personage': 7551, 'har': 7552, 'vishwanath': 7553, 'p/06a16ac2d087d3c9': 7554, 'meaningful': 7555, '3years': 7556, \"superior's\": 7557, \"peer's\": 7558, 'v/s': 7559, 'projection': 7560, 'dashboard/reports': 7561, '\"single': 7562, 'contact\"': 7563, 'whoever': 7564, 'nsdc': 7565, 'colleague': 7566, 'hq': 7567, 'nap': 7568, 'apprenticeship': 7569, 'p/06a16ac2d087': 7570, 'd3c9': 7571, 'ani': 7572, 'cafe': 7573, 'café': 7574, \"mis's\": 7575, 'cite': 7576, 'offense': 7577, 'callers': 7578, 'jul': 7579, 'enr': 7580, 'mrl': 7581, 'esau': 7582, '[24]7': 7583, 'dropouts': 7584, 'edf': 7585, 'npower': 7586, 'isu': 7587, '\"knowledge\"': 7588, 'n1': 7589, \"fresher's\": 7590, 'laterals': 7591, 'reword': 7592, 'ramp': 7593, 'hemil': 7594, 'bhavsar': 7595, 'unicode': 7596, 'softech': 7597, 'ksv': 7598, 'gandhinagar': 7599, 'siddhartha': 7600, 'chetri': 7601, 'chetri/': 7602, 'f6959d21c6b91bba': 7603, 'project/change': 7604, 'collabera': 7605, 'infrastructure/bandwidth': 7606, 'analyst/project': 7607, 'instructions': 7608, 'lwi': 7609, 'sapient': 7610, \"won't\": 7611, 'breach': 7612, 'reprocess': 7613, 'tibco': 7614, 'cable': 7615, 'worldwide/': 7616, 'm&amp': 7617, 'centrica': 7618, 'crq': 7619, 'tawasul': 7620, 'fatsweb': 7621, 'organization/duration/roles': 7622, 'advisor/': 7623, 'inac': 7624, 'bang': 7625, 'alore': 7626, 'kar': 7627, 'nata': 7628, 'ka': 7629, 'srms': 7630, 'mori': 7631, 'gcd': 7632, 'locm': 7633, 'gtoms': 7634, 'pratik': 7635, 'vaidya': 7636, 'allscripts': 7637, 'loophole': 7638, 'kyrion': 7639, 'iete': 7640, 'congress': 7641, 'mahanubhav': 7642, 'ashram': 7643, 'emotional': 7644, 'enthusiast': 7645, '27/12/1994': 7646, 'gender': 7647, 'male': 7648, 'marital': 7649, 'unmarried': 7650, 'hobbies': 7651, '142': 7652, 'auronoday': 7653, 'colony': 7654, 'near': 7655, 'datta': 7656, 'mandir': 7657, '431010': 7658, 'deogiri': 7659, 'chate': 7660, 'intranet/': 7661, 'roadmaps': 7662, 'safe/scrum': 7663, 'integration/delivery': 7664, 'clarity': 7665, 'bitbukcet': 7666, 'xebialabs': 7667, 'xl': 7668, 'automation/automic': 7669, 'understate': 7670, 'java/': 7671, 'vstudio': 7672, 'alm/qc/octane': 7673, 'validator': 7674, 'tdm': 7675, 'rtc': 7676, 'bitbucket/stash': 7677, 'automations': 7678, 'git/bitbucket': 7679, 'vha': 7680, 'scotiabank': 7681, 'volkswagen': 7682, 'netapp': 7683, 'optus': 7684, 'cenveo': 7685, 'onboarded': 7686, '100+': 7687, 'transitions/takeover': 7688, 'att': 7689, ']': 7690, 'band/': 7691, 'u4': 7692, 'august/2004': 7693, 'april/2005': 7694, 'infoland': 7695, 'java/j2ee': 7696, '[asp': 7697, 'ef': 7698, 'vs2012]': 7699, 'tfs2013': 7700, 'inrelease': 7701, 'borelandtogether2007': 7702, 'visio2010': 7703, 'trainings/certifications': 7704, 'introduction': 7705, 'keshav': 7706, 'dhawale': 7707, 'dhawale/f5ce584c13e7368d': 7708, 'guest': 7709, 'persnol': 7710, 'univers': 7711, 'ity': 7712, '//at': 7713, 'dhawale/f5ce584c13e7': 7714, 'praveen': 7715, 'bhaskar': 7716, 'viable': 7717, 'mix': 7718, 'assume': 7719, \"program's\": 7720, 'consultant/': 7721, 'tekskills': 7722, 'contingency': 7723, 'interdependencies': 7724, '20+': 7725, 'reportees': 7726, 'smes': 7727, 'oversee': 7728, '40+': 7729, 'coaching/training/mentoring': 7730, 'poornam': 7731, 'infovision': 7732, 'cpanel': 7733, 'plesk': 7734, 'ogic': 7735, 'certifi': 7736, 'tate': 7737, 'certifica': 7738, 'holder': 7739, 'gunjan': 7740, 'nayyar': 7741, 'hoshiarpur': 7742, 'blood': 7743, 'donation': 7744, '17thnov': 7745, 'humanoids': 7746, 'resemble': 7747, 'carrom': 7748, 'bollywood': 7749, 'tambola': 7750, 'antakshari': 7751, 'catechism': 7752, 'decoration': 7753, 'chitkara': 7754, 'triple': 7755, 'rupesh': 7756, 'reddy/5402dfa9c92fb7bf': 7757, 'warehousing/business': 7758, 'infoview/bi': 7759, '0/4': 7760, 'udt': 7761, 'xi3': 7762, 'unv': 7763, 'unx': 7764, 'boxi': 7765, 'universes': 7766, 'patches/fixes': 7767, 'versatile': 7768, 'reddy/5402dfa9': 7769, 'c92fb7bf': 7770, 'bbdpr2171l': 7771, 'yderabad': 7772, '2021': 7773, 'dxc': 7774, 'mauritius': 7775, 'universe/report': 7776, 'ha': 7777, 'eliminate': 7778, 'completeness': 7779, 'sever': 7780, 'deployment/migrations': 7781, 'pfizer': 7782, 'prade': 7783, 'sh': 7784, 'sensitivity': 7785, 'articulation': 7786, 'puneeth': 7787, 'optimum': 7788, 'harmoniously': 7789, 'forth': 7790, 'everyone': 7791, 'performances': 7792, 'gameplay': 7793, 'dsat': 7794, 'ftr': 7795, 'stringent': 7796, 'compensations': 7797, 'at&amp': 7798, 'generations': 7799, 'contd': 7800, 'discrepancies': 7801, 'hgs': 7802, 'mts': 7803, 'inq': 7804, 'uir': 7805, 'coll': 7806, 'kandrapu': 7807, 'itc': 7808, 'fare': 7809, 'reservations': 7810, 'chauffer': 7811, 'isakhapatnam': 7812, 'internationally': 7813, 'galileo': 7814, 'accredit': 7815, 'gamut': 7816, 'travelers': 7817, '31st': 7818, 'body': 7819, 'gali': 7820, 'leo': 7821, 'airline': 7822, 'nri': 7823, 'visakhapa': 7824, 'tnam': 7825, 'vineeth': 7826, 'vijayan': 7827, 'vijayan/': 7828, 'ee84e7ea0695181f': 7829, 'repute': 7830, '27001': 7831, 'exper': 7832, 'ience': 7833, '\"store': 7834, 'xec': 7835, 'utive\"': 7836, 'nsti': 7837, 'tute': 7838, 'rotate': 7839, 'disposal': 7840, 'surpluses': 7841, 'inspect': 7842, 'shelve': 7843, 'perpetual': 7844, 'mednet': 7845, 'abc': 7846, 'ved': 7847, 'fsn': 7848, '\"hr': 7849, 'agility': 7850, 'adjust': 7851, 'themselves': 7852, 'newcomers': 7853, 'managers/departments': 7854, 'comply': 7855, '\"training': 7856, 'coordinator\"': 7857, 'nevada': 7858, 'las': 7859, 'vegas': 7860, 'gadgets': 7861, 'housekeep': 7862, 'enquire': 7863, 'institutions': 7864, 'huddles/counseling': 7865, '\"manager\"': 7866, 'nair': 7867, 'pv': 7868, 'accentia': 7869, 'oak': 7870, 'mts/editors': 7871, '\"process': 7872, 'executive\"': 7873, 'logistic': 7874, 'precise': 7875, 'safely': 7876, '\"sr': 7877, 'transcriptionist\"': 7878, 'vanderbilt': 7879, 'nashville': 7880, 'transcribe': 7881, \"patient's\": 7882, 'illness': 7883, 'diagnostic': 7884, \"mt's\": 7885, 'horizons': 7886, 'cente': 7887, 'micr': 7888, 'ob': 7889, 'iology': 7890, 'microbiology': 7891, 'colleg': 7892, 'storekeeping': 7893, 'tayade': 7894, '12+': 7895, 'support/maintenance': 7896, 'unwanted': 7897, 'nva': 7898, 'depute': 7899, 'ipswich': 7900, 'qmg': 7901, 'pmr': 7902, 'v3': 7903, 'ifpug': 7904, 'smoothly': 7905, 'ead': 7906, 'diligence': 7907, 'tackle': 7908, 'fcr': 7909, 'leadership/people': 7910, 'technolog': 7911, 'variance': 7912, 'lap': 7913, 'miscommunications': 7914, 'britis': 7915, 'lecom': 7916, 'contractor': 7917, 'v21': 7918, \"metasolv's\": 7919, 'monetary': 7920, 'ribbon': 7921, 'telecomm': 7922, 'ewmp': 7923, 'tacticals': 7924, 'manual/': 7925, 'robots': 7926, 'getwell': 7927, 'eosl': 7928, 'fastq': 7929, 'countrywide': 7930, 'repay': 7931, 'trench': 7932, 'disburse': 7933, 'capitalize': 7934, 'repayment': 7935, 'installment': 7936, 'delinquent': 7937, 'deployme': 7938, 'electroni': 7939, 'mah': 7940, 'arashtra': 7941, 'oard': 7942, '1993': 7943, 'debasish': 7944, 'dasgupta': 7945, 'qasba': 7946, 'dasgupta/a20561e10f83ae3f': 7947, 'dop': 7948, 'theory': 7949, 'crores': 7950, 'foster': 7951, 'solut': 7952, 'inf': 7953, 'osys': 7954, 'opttions': 7955, 'rainbow': 7956, 'dasgupta/a20561e10f83': 7957, 'ae3f': 7958, 'salt': 7959, 'treasury': 7960, 'channelize': 7961, 'liquidity': 7962, 'asst': 7963, 'jamshedpur': 7964, 'fams': 7965, \"5's\": 7966, 'authorities': 7967, 'fortnightly': 7968, '\"aaa\"': 7969, 'petty': 7970, 'logbook': 7971, 'lodge': 7972, 'circle': 7973, 'excess': 7974, 'expenditure': 7975, 'renewal': 7976, 'cra': 7977, 'softwa': 7978, 'deve': 7979, 'suresh': 7980, 'kanagala': 7981, 'sharepoint/office': 7982, '/azure': 7983, 'cloud/': 7984, 'c2': 7985, 'modus': 7986, 'month/year': 7987, 'com/in/sureshkanagala': 7988, 'metalogix': 7989, 'sharegate': 7990, 'jaspreet': 7991, 'kaur': 7992, 'intellectually': 7993, 'headofficein': 7994, 'melbourne': 7995, 'round/': 7996, 'f2f': 7997, 'ict': 7998, 'rotation': 7999, 'increment': 8000, 'birthday/': 8001, 'anniversary/wedding': 8002, 'gifts/': 8003, 'festival': 8004, 'benefits/': 8005, 'leaves/': 8006, 'confirmations/': 8007, 'rectification/credit': 8008, 'policy/': 8009, 'closure/': 8010, 'holidays/': 8011, 'ascent': 8012, 'change/contact': 8013, 'joinees': 8014, 'detail/': 8015, 'increments/': 8016, 'transfers/full': 8017, 'twice': 8018, 'dept': 8019, \"'leave\": 8020, 'deactivation': 8021, 'mailbox': 8022, 'deactivate': 8023, 'withdrawal': 8024, 'zirakpur': 8025, 'qualitative': 8026, 'panchkula': 8027, 'zirakpur&amp': 8028, 'recruitments': 8029, 'rag': 8030, 'joiner': 8031, 'birthday': 8032, 'anniversary': 8033, 'christmas': 8034, 'celebration': 8035, 'diwali': 8036, 'lohri': 8037, 'advertisements': 8038, \"cv's\": 8039, 'attrition': 8040, 'enterprises': 8041, 'consultancies': 8042, 'appointment': 8043, 'celebrate': 8044, 'festivals': 8045, 'formulation': 8046, 'payments/deliveries': 8047, 'samaj': 8048, 'word/excel/power': 8049, 'somanath': 8050, 'behera': 8051, 'behera/': 8052, 'e9188fe8ba12dbbd': 8053, '14th': 8054, 'bput': 8055, 'balasore': 8056, 'tidal': 8057, 'ashish': 8058, 'indoriya': 8059, 'durg': 8060, 'façade': 8061, 'task/': 8062, 'pointers': 8063, 'pig': 8064, 'neer': 8065, 'indirectly': 8066, 'distance': 8067, 'duplicate': 8068, 'retrievals': 8069, 'memento': 8070, 'attern': 8071, 'augus': 8072, 'chhatt': 8073, 'isgarh': 8074, 'certi': 8075, 'ficate': 8076, 'sping': 8077, 'notic': 8078, 'dilliraja': 8079, 'baskara': 8080, 'panimalar': 8081, 'imsdb': 8082, 'imsdc': 8083, 'deepika': 8084, 'gift': 8085, 'whom': 8086, 'cge': 8087, 'ifw': 8088, 'difficult': 8089, 'exactly': 8090, 'consignment': 8091, 'datastage': 8092, 'pub': 8093, 'bharathiyar': 8094, 'jacob': 8095, 'philip': 8096, 'kottayam': 8097, 'strategicsales': 8098, 'experienceinsales': 8099, 'assistantbusinessdevelopmentmanager': 8100, 'builtstrong': 8101, 'clientrelationshipsandprovidedhighvalue': 8102, 'addingservices': 8103, 'resultingina15': 8104, 'marketshareincrease': 8105, 'developstools': 8106, 'practicesacrosstheorganization': 8107, 'negotiatingcontractsandpackages': 8108, 'negotiatingthetermsofanagreementwithaviewto': 8109, 'closingsale': 8110, 'andnew': 8111, 'businessdata': 8112, 'workedcloselywithpartners': 8113, 'throughconductingqualityassurancetests': 8114, 'actasthepointofcontactandcommunicate': 8115, 'projectstatustoallparticipantsinourteam': 8116, 'ordinator': 8117, 'marketingco': 8118, 'bhimajewelers': 8119, 'plannedandexecutedeventsandmarketingprograms': 8120, 'producingfivetimestargetnumberof': 8121, 'qualifiedleads': 8122, 'forecastsandincreasedperformanceby52percent': 8123, 'preparesmarketingreportsbycollecting': 8124, 'andsummarizingsalesdata': 8125, 'staffedprojects': 8126, 'customerserviceexecutive': 8127, 'unitedarabemirates': 8128, 'maintainandorganizeacustomerdatabaseofover10': 8129, '000members': 8130, 'evaluatedpatientcareneeds': 8131, 'prioritizedtreatment': 8132, 'andmaintainedpatientflow': 8133, 'responsibleforprimarycare': 8134, 'casemanagement': 8135, 'andmedicationmanagement': 8136, 'dealtwithinsurancecards': 8137, 'cashcollection': 8138, 'ande': 8139, 'inadditiontohandling': 8140, 'incomingcallsorenquiriesfrompatients': 8141, 'salesofficer': 8142, 'infosystems': 8143, 'increasedcompanyexposure': 8144, 'customertraffic': 8145, 'andsales': 8146, 'materialsforsalespresentationsandclientmeetings': 8147, 'inadditiontoinventoryrecordingandmaintainstocks': 8148, 'partnersandclientsasnecessary': 8149, 'yogesh': 8150, 'ghatole': 8151, 'realize': 8152, 'ahus': 8153, 'rad': 8154, 'motorize': 8155, 'ht': 8156, 'mcc': 8157, 'ph': 8158, 'centrifugal': 8159, 'chillers': 8160, 'doas': 8161, 'actuators': 8162, 'hrw': 8163, 'exhaust': 8164, 'ahu': 8165, 'pump': 8166, 'cool': 8167, 'csus': 8168, 'fcus': 8169, 'ecus': 8170, 'cfm': 8171, 'airflow': 8172, 'heat/cool': 8173, 'tractor': 8174, 'pac': 8175, \"ac's\": 8176, 'voltas': 8177, 'breakdowns': 8178, 'coolers': 8179, 'electrician': 8180, 'polytechni': 8181, 'agpur': 8182, 'shree': 8183, 'binzani': 8184, 'ins': 8185, 'titute': 8186, 'ajay': 8187, 'elango': 8188, 'admission': 8189, 'universities': 8190, 'carnegie': 8191, 'mellon': 8192, 'pittsburgh': 8193, 'cornell': 8194, 'ithaca': 8195, 'colorado': 8196, 'illinois': 8197, 'mathworks': 8198, 'seattle': 8199, 'diego': 8200, 'revere': 8201, 'toolset': 8202, 'researchers': 8203, 'scientists': 8204, 'visualize': 8205, '85': 8206, 'gecko': 8207, 'collision': 8208, 'engineers/technical': 8209, 'workarounds': 8210, 'handoff': 8211, 'qt': 8212, 'ccms': 8213, 'cadet': 8214, 'austin': 8215, 'fpga': 8216, 'digitizer': 8217, 'pxie': 8218, '5171': 8219, 'adc': 8220, 'transceivers': 8221, 'chipsets': 8222, 'significantly': 8223, 'escripts': 8224, 'defense': 8225, 'encoder': 8226, '7174/7179': 8227, 'decoder': 8228, '7184': 8229, 'institu': 8230, 'ga': 8231, 'ecember': 8232, 'communica': 8233, 'com/in/ajayelango': 8234, '98/11': 8235, 'hoop': 8236, '3dgs': 8237, 'opengl': 8238, 'shaik': 8239, 'tazuddin': 8240, 'emear': 8241, 'dart': 8242, 'especial': 8243, 'attention': 8244, 'france': 8245, 'kingdom': 8246, 'italy': 8247, 'sweden': 8248, 'slovakia': 8249, 'israel': 8250, 'figure': 8251, 'overlap': 8252, 'quantity': 8253, 'example': 8254, 'ccw': 8255, 'sfdc': 8256, 'rural': 8257, 'margadarshi': 8258, 'htm': 8259, 'angad': 8260, 'waghmare': 8261, 'waghmare/42aa9e8655a5f7a3': 8262, 'hardware/desktop': 8263, '2008environment': 8264, 'netsol': 8265, 'tooltech': 8266, 'replacements': 8267, 'laptops': 8268, 'misuse': 8269, '4th': 8270, 'thursday': 8271, 'onths': 8272, 'waghm': 8273, 'are/42aa9e8655a5f7a3': 8274, 'qulification': 8275, 'egg': 8276, 'gayatri': 8277, 'authorize': 8278, 'acer': 8279, 'window7': 8280, 'window8': 8281, 'window10': 8282, 'hardwa': 8283, 'proffesion': 8284, 'sohan': 8285, 'dhakad': 8286, 'com/r/sohan': 8287, 'dhakad/038dfd47a0cf071f': 8288, 'issuance': 8289, 'provisional': 8290, 'adherences': 8291, 'jiwaj': 8292, 'parsuing': 8293, 'madhava': 8294, 'konjeti': 8295, 'motive': 8296, 'personally': 8297, 'skillsets': 8298, '1month': 8299, '10days': 8300, 'bellandur': 8301, 'itpl': 8302, '2months': 8303, '4days': 8304, 'vijnana': 8305, 'vihara': 8306, 'formula': 8307, 'shreya': 8308, 'agnihotri': 8309, 'agnihotri/': 8310, 'c1755567027a0205': 8311, 'teamwork': 8312, 'perspective': 8313, 'classic': 8314, 'galgotias': 8315, 'prometheus': 8316, 'grafana': 8317, 'tapan': 8318, 'nayak': 8319, 'com/r/tapan': 8320, 'nayak/': 8321, 'da1f5ffb3c4c4b17': 8322, '10years': 8323, 'jain/3714fe32f98b03a9': 8324, 'miles': 8325, 'vodqa': 8326, 'jasmine': 8327, \"qa's\": 8328, 'jain/3714fe32': 8329, 'f98b03a9': 8330, 'frisby': 8331, 'zap': 8332, 'infos': 8333, 'ys': 8334, 'phantomas': 8335, 'cripts': 8336, 'jaypee': 8337, 'valley': 8338, 'palani': 8339, 'porur': 8340, 'experince': 8341, 'wor': 8342, 'king': 8343, 'ampark': 8344, 'manipulate': 8345, '3/2': 8346, 'fkc': 8347, \"information's\": 8348, 'exl': 8349, 'landcorp': 8350, 'appeal': 8351, 'disease': 8352, 'grigora': 8353, 'techinical': 8354, 'ann': 8355, 'nad': 8356, 'ec': 8357, 'ember': 8358, '009': 8359, 'tirunelveli': 8360, 'ptember': 8361, 'kanna': 8362, '4/5': 8363, 'june2015': 8364, 'regularize': 8365, 'javascripts': 8366, 'slickgrid': 8367, 'nyse': 8368, 'intimate': 8369, 'agl': 8370, 'faulty': 8371, 'periodical': 8372, '9500615962': 8373, 'doodle': 8374, 'shrinidhi': 8375, 'com/r/shrinidhi': 8376, 'kumar/50d8e59fabb41a63': 8377, 'appdynamics': 8378, 'ecllipse': 8379, 'mazenet': 8380, 'tejaa': 8381, 'shakthi': 8382, 'mayank': 8383, 'shukla': 8384, 'bfsi': 8385, '\"award': 8386, 'excellence\"': 8387, 'tricentis': 8388, 'originally': 8389, 'edgeverve': 8390, 'rclm': 8391, 'technique': 8392, 'ccm': 8393, 'saroj': 8394, 'edb': 8395, 'tora': 8396, 'mobaxterm': 8397, 'devotee': 8398, 'punctual': 8399, 'shraddha': 8400, 'achar': 8401, 'com/r/shraddha': 8402, 'achar/': 8403, 'd6d4e3c0237ccc6c': 8404, 'trining': 8405, 'immersive': 8406, \"employable'\": 8407, 'enzymatic': 8408, 'hydrolysis': 8409, 'carbohydrates': 8410, 'fermentable': 8411, 'digestible': 8412, 'sugars\"': 8413, \"'microbial\": 8414, 'polysaccaride': 8415, \"s'\": 8416, 'sql/p': 8417, 'lsql': 8418, 'nmam': 8419, 'poorna': 8420, 'prajna': 8421, 'admar': 8422, 'ganapathi': 8423, 'padubidri': 8424, 'godha': 8425, 'godha/4c363189fbff3de8': 8426, 'contingencies': 8427, 'reengineering': 8428, 'ideation': 8429, 'reengineered': 8430, 'tracer': 8431, 'aht': 8432, 'austria': 8433, 'dtp': 8434, 'rkt': 8435, 'dtp/sop': 8436, 'som': 8437, 'godha/4c363189fbff': 8438, '3de8': 8439, 'regularly': 8440, 'unpaid': 8441, 'unapplied': 8442, 'ach': 8443, 'rajas': 8444, 'ppi': 8445, 'abi': 8446, 'jatin': 8447, 'arora': 8448, 'pehowa': 8449, 'sqa': 8450, 'reduction': 8451, 'spend': 8452, 'hackathon': 8453, 'mtm': 8454, 'mindmaps': 8455, 'charles': 8456, 'river': 8457, 'ngvl': 8458, 'wwlp': 8459, 'partnership': 8460, 'wpg': 8461, 'sqls': 8462, 'cience': 8463, 'kurukshetra': 8464, 'gururaj': 8465, '90+': 8466, 'datawarehousing': 8467, 'defunct': 8468, 'thereby': 8469, '$12': 8470, '5m': 8471, 'dw/bi': 8472, '75': 8473, 'downsize': 8474, \"'appluase\": 8475, \"award'\": 8476, 'apreciation': 8477, \"'star\": 8478, \"month'\": 8479, 'successive': 8480, 'distinctive': 8481, 'datamart': 8482, '63': 8483, 'veeva': 8484, 'stm/design': 8485, '5/2015': 8486, 'sftp': 8487, 'massage': 8488, '850': 8489, '855': 8490, '856': 8491, 'nxtrend': 8492, 'comma': 8493, 'sulfa': 8494, '888': 8495, '4350': 8496, '386': 8497, 'pi/po': 8498, 'bardolia': 8499, 'triplo': 8500, 'makemytrip': 8501, 'solartis': 8502, 'essentials': 8503, 'swarm': 8504, 'openshit': 8505, 'cloustack': 8506, 'sonar': 8507, 'qube': 8508, 'puran': 8509, 'mal': 8510, 'com/r/puran': 8511, 'mal/357ea77b3b002be6': 8512, \"bachelor'\": 8513, 'sridevi': 8514, '/project': 8515, 'networking/platform/drivers/vxworks': 8516, 'feasible': 8517, 'brilliant': 8518, 'knowlegde': 8519, 'mlt': 8520, 'smlt': 8521, 'slpp': 8522, 'ipfix': 8523, 'rsp': 8524, 'fastpath': 8525, 'crash': 8526, 'chassis': 8527, 'wmm': 8528, 'proficiency/hardware': 8529, 'programming/': 8530, 'library/platform': 8531, 'rtos': 8532, 'simulators': 8533, 'analyzers': 8534, 'databse': 8535, 'quotient': 8536, 'tnc': 8537, 'mspp': 8538, 'designati': 8539, 'raktim': 8540, 'podder': 8541, 'one’s': 8542, 'wfm': 8543, 'catch': 8544, 'up’s': 8545, 'disruption': 8546, 'stop': 8547, 'ccss': 8548, 'his/her': 8549, 'bmm': 8550, 'incoming': 8551, 'dip': 8552, 'weekly/': 8553, 'behind': 8554, 'baseline': 8555, 'illustration': 8556, 'confusion': 8557, 'fte': 8558, 'knowhow': 8559, 'happy': 8560, 'tasmania': 8561, 'memo': 8562, 'sanction/approval': 8563, 'disbursement': 8564, 'barriers': 8565, 'casual': 8566, \"why's\": 8567, 'pareto': 8568, 'elicitation': 8569, 'debts': 8570, 'debt': 8571, 'percentages': 8572, 'vertical': 8573, 'scatter': 8574, 'bcom': 8575, 'edd': 8576, 'pavithra': 8577, 'sqlyog': 8578, 'shrikant': 8579, 'desai': 8580, 'com/r/shrikant': 8581, 'desai/': 8582, 'cc6430615ce4d44a': 8583, 'murgud': 8584, '//shrikantdesai89@gmail': 8585, '87': 8586, 'kiran': 8587, 'com/r/kiran': 8588, 'kumar/7e76e7a9e62e7ee5': 8589, 'lvm': 8590, 'yum': 8591, 'acl': 8592, 'sticky': 8593, 'rhel': 8594, 'symbolic': 8595, 'admiration': 8596, 'srikalahasteeswara': 8597, 'chaban': 8598, 'debbarma': 8599, 'agartala': 8600, 'akash': 8601, 'gulhane': 8602, 'com/r/akash': 8603, 'gulhane/8b86faac48268d09': 8604, 'revocation': 8605, 'multy': 8606, 'jre': 8607, 'narsamma': 8608, 'ramkrishna': 8609, 'krida': 8610, 'evolve': 8611, '260nos': 8612, '405nos': 8613, 'surveillances': 8614, 'two/four': 8615, 'vehicles': 8616, 'correctly': 8617, 'products/software/problems': 8618, 'surveillance': 8619, 'gentleness': 8620, 'photoshoot': 8621, 'xerox': 8622, 'anything': 8623, 'challenger': 8624, 'joseph': 8625, 'dce': 8626, 'adi': 8627, 'sankara': 8628, 'rathi': 8629, 'rathi/': 8630, 'd7d73269f025a981': 8631, 'fulfil': 8632, '31th': 8633, '/extra': 8634, 'activitie': 8635, 'captain': 8636, 'volleyball': 8637, 'uttrakhand': 8638, 'verma': 8639, 'educate': 8640, 'admins': 8641, \"users'\": 8642, 'users/admins': 8643, 'onedrive': 8644, 'skype': 8645, 'rave': 8646, 'cap': 8647, 'avaya': 8648, 'entc': 8649, 'technocrat': 8650, 'chemist': 8651, 'heterolabs': 8652, 'april2004': 8653, 'msfnsdt1': 8654, 'ftes': 8655, 'generally': 8656, '47': 8657, 'headcount': 8658, 'ww': 8659, 'calypso': 8660, 'faqs': 8661, 'sa': 8662, '#2': 8663, 'glider': 8664, 'msu': 8665, 'alpha': 8666, 'ecx': 8667, '0/1': 8668, '1&1': 8669, 'vla': 8670, 'loc': 8671, 'rocs': 8672, 'brd': 8673, 'fsd': 8674, '#3': 8675, 'bgos': 8676, 'dublin': 8677, 'pob': 8678, 'platform/application': 8679, 'taxware': 8680, 'production/uat/pob': 8681, \"dll's\": 8682, 'logins': 8683, 'around/resolution': 8684, 'finally': 8685, 'frequently': 8686, 'correction': 8687, '9x': 8688, 'x64': 8689, 'x86': 8690, 'filenet': 8691, 'shivasai': 8692, 'com/r/shivasai': 8693, 'mantri/': 8694, 'eb5df334d3959e42': 8695, 'terrain': 8696, 'aba': 8697, 'sreenidhi': 8698, 'vamshi': 8699, 'bodhan': 8700, 'x++': 8701, 'prasanna': 8702, 'ignatius': 8703, \"system's\": 8704, '08': 8705, '09': 8706, '05': 8707, '08+': 8708, 'inception': 8709, 'workbooks': 8710, 'ready': 8711, 'storages': 8712, 'joint': 8713, 'venture': 8714, \"tata's\": 8715, 'eminent': 8716, \"aia's\": 8717, 'majority': 8718, 'bishop': 8719, 'ambrose': 8720, 'pankaj': 8721, 'bhosale': 8722, '2005/8': 8723, '2008/2010': 8724, 'softzel': 8725, 'vaasthu': 8726, 'contractors': 8727, 'grocery': 8728, \"rcpet's\": 8729, 'jalgaon': 8730, 'palesh': 8731, 'jai': 8732, 'hind': 8733, 'vinay': 8734, 'singhal': 8735, 'eu': 8736, 'amie': 8737, '//mcp': 8738, 'com/anonymous//transcript/validate': 8739, '2012r2': 8740, 'sharma/8e4755830666f3b6': 8741, 'handson': 8742, 'gmo': 8743, 'rpd': 8744, 'disc': 8745, 'servicesspn': 8746, 'dora': 8747, 'fsmo': 8748, 'forest': 8749, 'greenfields': 8750, 'gaikwad': 8751, 'dilip': 8752, 'com/r/gaikwad': 8753, 'dilip/6cc87ee90de2b0fe': 8754, 'moreover': 8755, 'proficiently': 8756, 'shall': 8757, 'vehicle': 8758, 'oparater': 8759, 'micit': 8760, 'moumita': 8761, 'vocal': 8762, 'chitra': 8763, 'bhushan': 8764, 'pracheen': 8765, 'kala': 8766, 'kendra': 8767, 'kathak': 8768, 'dance': 8769, 'dissertation/': 8770, 'glucagon': 8771, 'peptide': 8772, 'incretin': 8773, 'therapies': 8774, 'exenatide': 8775, 'antigen': 8776, 'cells': 8777, 'gene': 8778, 'sclerosis': 8779, 'peptides': 8780, 'autoantigens': 8781, 'mhc': 8782, 'molecule': 8783, 'immunotherapy': 8784, \"hashimoto's\": 8785, 'thyroiditis': 8786, 'poster': 8787, '\"neurotoxins': 8788, 'medicinal': 8789, 'emphasis': 8790, 'snake': 8791, 'neurotoxic': 8792, 'venom\"': 8793, 'colloquium': 8794, 'ugc': 8795, 'sponsor': 8796, '\"rediscovering': 8797, 'immunology': 8798, 'immunological': 8799, 'ballygunge': 8800, 'rastraguru': 8801, \"paul's\": 8802, '1978': 8803, 'board/': 8804, 'bengali': 8805, 'suman': 8806, 'biswas': 8807, 'royal': 8808, 'dutch': 8809, 'toronto': 8810, 'xsjs': 8811, 'crv': 8812, 'prelude': 8813, 'charon': 8814, 'ctt': 8815, 'gpd': 8816, 'aif': 8817, 'hcp': 8818, 'row': 8819, 'analytic': 8820, 'xsaccess': 8821, 'interviewer': 8822, 'lumira': 8823, 'bi/ip': 8824, 'refine': 8825, 'bex': 8826, 'mock': 8827, 'showcased': 8828, 'bright': 8829, 'primarily': 8830, 'remoting': 8831, 'oop': 8832, 'animation': 8833, 'poker': 8834, \"'em\": 8835, 'omaha': 8836, 'calcutta': 8837, \"'a'\": 8838, \"'o'\": 8839, 'ui5/fiori': 8840, 'com/in/sumanbiswas2018': 8841, 'mansi': 8842, 'thanki': 8843, 'jamnagar': 8844, 'com/r/mansi': 8845, 'thanki/04b8914a81df5a81': 8846, '\"water': 8847, 'environmental': 8848, 'bhuj': 8849, 'anil': 8850, 'deterministic': 8851, '/wan': 8852, '/ip': 8853, '97': 8854, 'macafee': 8855, 'clint': 8856, 'lenovo': 8857, 'toshiba': 8858, 'handheld': 8859, 'mg': 8860, 'oxford': 8861, 'joomla': 8862, 'desktop/notebook': 8863, 'suumary': 8864, 'cesca': 8865, 'therapeutics': 8866, 'nec': 8867, 'topaz': 8868, 'cr50ia': 8869, 'udyog': 8870, 'vihar': 8871, 'totipotentrx': 8872, 'mb': 8873, 'cctv': 8874, 'honeywell': 8875, 'biometric': 8876, '3000': 8877, 'cr35ing': 8878, 'suncity': 8879, 'x3320': 8880, 'aten': 8881, 'dlink': 8882, 'iquinox': 8883, 'postmaster': 8884, 'dayal': 8885, '18th': 8886, '20th': 8887, 'prolaint': 8888, 'ml150': 8889, 'ultrium': 8890, 'isdn': 8891, 'pix': 8892, '501': 8893, \"vender's\": 8894, 'proff': 8895, 'mi': 8896, 'cartridge': 8897, 'lucent': 8898, 'omnipcx': 8899, 'cti': 8900, 'pimphony': 8901, 'vaccine': 8902, 'cum': 8903, '226': 8904, 'xeon': 8905, '205': 8906, 'sysware': 8907, 'dairy': 8908, 'ndri': 8909, '300': 8910, 'lasers': 8911, 'jet': 8912, 'mfp': 8913, 'vipul': 8914, '160': 8915, 'passive': 8916, 'ballabhgarh': 8917, 'com/r/siddharth': 8918, 'choudhary/19d56a964e37fa1a': 8919, 'aggressive/challenging': 8920, 'logically': 8921, 'choudharysiddharth22@gmail': 8922, 'training/articleship': 8923, 'cycles/operations': 8924, 'com/in/sid': 8925, 'icai': 8926, '464/800': 8927, 'cfa': 8928, 'derivatives': 8929, 'valarmathi': 8930, 'dhandapani': 8931, 'operations/pmo': 8932, 'dhandapani/': 8933, 'a2b3eb340068764d': 8934, 'hosur': 8935, 'buffer': 8936, 'submissions': 8937, 'fp': 8938, 'sow/task': 8939, 't&m': 8940, \"amc's\": 8941, 'bgv': 8942, 'graphics': 8943, 'timesheets': 8944, 'adhoc': 8945, 'commerzbank': 8946, 'subcontractors': 8947, 'timesheet': 8948, 'itime': 8949, 'rtb': 8950, 'ctb': 8951, 'respectively': 8952, 'child': 8953, 'say': 8954, 'variations': 8955, 'amongst': 8956, 'pbs': 8957, 'ecms': 8958, 'alcon': 8959, 'ipm+': 8960, 'deutsche': 8961, 'allocations': 8962, 'laa': 8963, 'enrol': 8964, 'jp': 8965, 'morgan': 8966, 'chase': 8967, 'remediate': 8968, 'triparty': 8969, 'egus': 8970, 'reo': 8971, 'incur': 8972, 'associations': 8973, 'attorneys': 8974, 'foreclose': 8975, 'dmsi': 8976, 'telekurs': 8977, 'euro': 8978, 'fit': 8979, 'au': 8980, 'nz': 8981, 'issuer': 8982, 'coupon': 8983, 'martini': 8984, 'julius': 8985, 'ransom': 8986, 'firc': 8987, 'spider': 8988, 'equities': 8989, 'counterparty': 8990, 'settle': 8991, 'equal': 8992, 'considerations': 8993, 'sydney': 8994, 'shortcuts': 8995, 'stanes': 8996, 'anglo': 8997, 'kumar/96485546eadd9488': 8998, 'arc': 8999, 'esm': 9000} \n",
            "\n",
            "Длина словаря: 9000\n",
            "Индекс тега <s0> : 78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-1Dc4FRZwHv",
        "outputId": "e2c28e87-d037-454e-a2c5-7fcbd68d428a"
      },
      "source": [
        "# Превращает текст в последовательность индексов согласно словарю частотности\n",
        "tok_agreem = tokenizer.texts_to_sequences(docs) # Обучающий выборка в последовтельность индексов\n",
        "\n",
        "print(\"Взгляните на фрагмент обучающей выборки:\")\n",
        "print(\"Исходный текст:              \", docs[0][:20])\n",
        "print(\"Тот же текст, но как последовательность индексов: \", tok_agreem[0][:20], '\\n')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Взгляните на фрагмент обучающей выборки:\n",
            "Исходный текст:               ['<s0>', 'abhishek', 'jha', '</s0>', '<s6>', 'application', 'development', 'associate', '</s6>', '<s5>', 'accenture', '</s5>', '<s8>', 'bengaluru', '</s8>', 'karnataka', 'email', 'me', 'on', '<s9>']\n",
            "Тот же текст, но как последовательность индексов:  [78, 4955, 4956, 79, 22, 47, 73, 246, 23, 11, 492, 12, 27, 158, 28, 81, 61, 69, 7, 67] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpJtw64mZ-7B"
      },
      "source": [
        "# Создание yTrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_P5EXtsaCqy"
      },
      "source": [
        "#  Собираем лист индексов и их мультилейбл класссификации\n",
        "def getXYSamples(tok_agreem, tags_index):\n",
        "  tags01 = [] # лист тегов\n",
        "  indices = [] # лист индексов\n",
        " \n",
        "  for agreement in tok_agreem: # Проходимся по каждому договору-листу\n",
        "    tag_place = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] # создаём вектор [0,0,0,0,0,0] \n",
        "    for ex in agreement: # Проходимся по каждому слову из договора\n",
        "        if ex in tags_index: # Проверяем, если индекс слова соотвествует индексу одного из тегов\n",
        "          place = np.argwhere(tags_index==ex) # Запоминаем позицию тега в этом листе тегов\n",
        "          if len(place)!=0: # Проверяем, если тек в самом деле есть\n",
        "            if place[0][0]<11: # Первые 6 тегов - открывающие теги\n",
        "              tag_place[place[0][0]] = 1    # устанавливаем значение 1\n",
        "            else: \n",
        "              tag_place[place[0][0] - 11] = 0  # Все остальные теги закрывающие, так что мы меняем в соответсвующем месте в векторе на 0\n",
        "        else:          \n",
        "          tags01.append(tag_place.copy()) # Добавляем в наш лист тегов новые вектора мульти-лейбл классификации. \n",
        "                                          # В конце концов у нас будет большой лист всех вектор-тегов\n",
        "          indices.append(ex) # Добавляем индекс-слова в лист индексов\n",
        "\n",
        "  return indices, tags01\n",
        "\n",
        "# Получаем лист слов из листа индексов\n",
        "def reverseIndex(clean_voc, x):\n",
        "  reverse_word_map = dict(map(reversed, clean_voc.items())) #  Берёт ключ и значение из словаря и меняет их местами\n",
        "  docs = [reverse_word_map.get(letter) for letter in x] # Положим их в лист\n",
        "  return docs # Возвращает текст"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR9McUXAZ3Qx",
        "outputId": "a9aad0b7-08f7-4849-a1ea-8caaf9c256e0"
      },
      "source": [
        "tags_index = ['<s' + str(i) + '>' for i in range(0, 11)] # Лист открывающих тегов\n",
        "closetags = ['</s' + str(i) + '>' for i in range(0, 11)] # Лист закрывающих тегов\n",
        "tags_index.extend(closetags) # конкатенируем все теги\n",
        "\n",
        "tags_index = np.array([clean_voc[i] for i in tags_index]) # Получаем инексы всех тегов из словря частотности\n",
        "print('Индексы открывающих тегов:', tags_index[:11])\n",
        "print('Индексы закрывающих тегов:', tags_index[11:])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Индексы открывающих тегов: [  78   41   48   64  405   11   22   24   27   67 3956]\n",
            "Индексы закрывающих тегов: [  79   42   49   65  406   12   23   25   28   68 3957]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI8g31E5aTKW",
        "outputId": "baef2e7a-028c-4b99-d0e8-3dca3340cc27"
      },
      "source": [
        "curTime = time.time()\n",
        "xData, yData = getXYSamples(tok_agreem,tags_index) # Получаем теги и создаём листы с ними\n",
        "decoded_text = reverseIndex(clean_voc, xData) # Чтобы создать лист для эмбеддинга, нам нужно превратить лист индексов обратно в лист слов\n",
        "print('Превращение заняло: ', round(time.time() - curTime, 2), 'с.')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Превращение заняло:  0.75 с.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRA5AERFa8pR",
        "outputId": "47c64959-83c8-4e0a-ce47-e015570b4f30"
      },
      "source": [
        "print('длина xData:', len(xData))\n",
        "print('длина yData:', len(yData))\n",
        "\n",
        "print('Посмотрим на исходные слова: ', docs[0][:50])\n",
        "print('Сдекодированые слова:', decoded_text[:50])\n",
        "print('Часть xData:     ', xData[:50])\n",
        "print('Часть yData:     ', yData[:50])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "длина xData: 99282\n",
            "длина yData: 99282\n",
            "Посмотрим на исходные слова:  ['<s0>', 'abhishek', 'jha', '</s0>', '<s6>', 'application', 'development', 'associate', '</s6>', '<s5>', 'accenture', '</s5>', '<s8>', 'bengaluru', '</s8>', 'karnataka', 'email', 'me', 'on', '<s9>', 'indeed', 'indeed', 'com/r/abhishek', 'jha/10e7a8cb732bc43a', '</s9>', 'to', 'work', 'for', 'an', 'organization', 'which', 'provide', 'me', 'the', 'opportunity', 'to', 'improve', 'my', 'skills', 'and', 'knowledge', 'for', 'my', 'individual', 'and', \"company's\", 'growth', 'in', 'best', 'possible']\n",
            "Сдекодированые слова: ['abhishek', 'jha', 'application', 'development', 'associate', 'accenture', 'bengaluru', 'karnataka', 'email', 'me', 'on', 'indeed', 'indeed', 'com/r/abhishek', 'jha/10e7a8cb732bc43a', 'to', 'work', 'for', 'an', 'organization', 'which', 'provide', 'me', 'the', 'opportunity', 'to', 'improve', 'my', 'skills', 'and', 'knowledge', 'for', 'my', 'individual', 'and', \"company's\", 'growth', 'in', 'best', 'possible', 'ways', 'will', 'to', 'relocate', 'to', 'bangalore', 'karnataka', 'work', 'experience', 'application']\n",
            "Часть xData:      [4955, 4956, 47, 73, 246, 492, 158, 81, 61, 69, 7, 13, 13, 3401, 3402, 3, 8, 6, 107, 212, 129, 90, 69, 2, 832, 3, 460, 136, 26, 1, 77, 6, 136, 796, 1, 2262, 443, 4, 415, 1177, 1987, 109, 3, 209, 3, 178, 81, 8, 17, 47]\n",
            "Часть yData:      [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6r6K_hIeILO"
      },
      "source": [
        "# Разделение выборки на окна"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY8VBM4beJJV"
      },
      "source": [
        "# Создание выборки из индексов\n",
        "def getSetFromIndices(wordIndices, xLen, step): \n",
        "  xBatch = [] # Лист, хранящий фрагменты текста\n",
        "  wordsLen = len(wordIndices) # получаем длину текста\n",
        "  index = 0 #  стартовый индекс\n",
        "  \n",
        "  while (index + xLen <= wordsLen): # Пока сумма индекса и окна меньше или равно чем число слов в выборке\n",
        "    xBatch.append(wordIndices[index:index+xLen]) # Добавляем X в лист, что содержит наши фрагменты(окна) текста\n",
        "    index += step # Смещаем наше индекс на наш шаг(step)\n",
        "\n",
        "  return xBatch #  Лист фрагментов текста"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZZH3XYhjQiR"
      },
      "source": [
        "xLen = 256 # Длина каждого окна\n",
        "step = 30 # шаг \n",
        "embeddingSize = 300 # Число измерений вектор-пространства для каждого нашего слова "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCj9Ptq7b7tE"
      },
      "source": [
        "#  Генерируем выборки с параметрами наших окон\n",
        "xTrain = getSetFromIndices(decoded_text, xLen, step) # Последовательность индексов с окном xLen слов\n",
        "yTrain = getSetFromIndices(yData, xLen, step) # Последовательность индексов с окном xLen от тегов"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CPBZQI9jdDg",
        "outputId": "db0c9b99-e791-4846-a454-f1b097abb3e4"
      },
      "source": [
        "print('Длина xTrain:', len(xTrain))\n",
        "print('Длина yTrain:', len(yTrain))\n",
        "print('Длина примера из xTrain:',len(xTrain[0]))\n",
        "print('Длина примера из yTrain:',len(yTrain[0]), '\\n')\n",
        "print('Пример xTrain', xTrain[0])\n",
        "print('Пример yTrain', yTrain[0], '\\n')\n",
        "\n",
        "print('Первый пример xTrain:', xTrain[0][step-5:step+5])\n",
        "print('Второй пример xTrain:', xTrain[1][:10])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина xTrain: 3301\n",
            "Длина yTrain: 3301\n",
            "Длина примера из xTrain: 256\n",
            "Длина примера из yTrain: 256 \n",
            "\n",
            "Пример xTrain ['abhishek', 'jha', 'application', 'development', 'associate', 'accenture', 'bengaluru', 'karnataka', 'email', 'me', 'on', 'indeed', 'indeed', 'com/r/abhishek', 'jha/10e7a8cb732bc43a', 'to', 'work', 'for', 'an', 'organization', 'which', 'provide', 'me', 'the', 'opportunity', 'to', 'improve', 'my', 'skills', 'and', 'knowledge', 'for', 'my', 'individual', 'and', \"company's\", 'growth', 'in', 'best', 'possible', 'ways', 'will', 'to', 'relocate', 'to', 'bangalore', 'karnataka', 'work', 'experience', 'application', 'development', 'associate', 'accenture', 'november', '2017', 'to', 'present', 'role', 'currently', 'work', 'on', 'chat', 'bot', 'develop', 'backend', 'oracle', 'peoplesoft', 'query', 'for', 'the', 'bot', 'which', 'will', 'be', 'trigger', 'base', 'on', 'give', 'input', 'also', 'train', 'the', 'bot', 'for', 'different', 'possible', 'utterances', 'both', 'positive', 'and', 'negative', 'which', 'will', 'be', 'give', 'as', 'input', 'by', 'the', 'user', 'education', 'b', 'e', 'in', 'information', 'science', 'and', 'engineer', 'b', 'v', 'b', 'college', 'of', 'engineer', 'and', 'technology', 'hubli', 'karnataka', 'august', '2013', 'to', 'june', '2017', '12th', 'in', 'mathematics', 'woodbine', 'modern', 'school', 'april', '2011', 'to', 'march', '2013', '10th', 'kendriya', 'vidyalaya', 'april', '2001', 'to', 'march', '2011', 'skills', 'c', 'less', 'than', '1', 'year', 'database', 'less', 'than', '1', 'year', 'database', 'management', 'less', 'than', '1', 'year', 'database', 'management', 'system', 'less', 'than', '1', 'year', 'java', 'less', 'than', '1', 'year', 'additional', 'information', 'technical', 'skills', 'https', '//www', 'indeed', 'com/r/abhishek', 'jha/10e7a8cb732bc43a', 'isid=rex', 'download&ikw=download', 'top&co=in', 'program', 'language', 'c', 'c++', 'java', 'oracle', 'peoplesoft', 'internet', 'of', 'things', 'machine', 'learn', 'database', 'management', 'system', 'computer', 'network', 'operate', 'system', 'work', 'on', 'linux', 'windows', 'mac', 'non', 'technical', 'skills', 'honest', 'and', 'hard', 'work', 'tolerant', 'and', 'flexible', 'to', 'different', 'situations', 'polite', 'and', 'calm', 'team', 'player', 'afreen', 'jamadar', 'active', 'member', 'of', 'iiit', 'committee', 'in', 'third', 'year', 'sangli', 'maharashtra', 'email', 'me', 'on', 'indeed', 'indeed', 'com/r/afreen', 'jamadar/8baf379b705e37c6', 'i', 'wish', 'to', 'use', 'my', 'knowledge', 'skills', 'and', 'conceptual', 'understand', 'to', 'create']\n",
            "Пример yTrain [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] \n",
            "\n",
            "Первый пример xTrain: ['to', 'improve', 'my', 'skills', 'and', 'knowledge', 'for', 'my', 'individual', 'and']\n",
            "Второй пример xTrain: ['knowledge', 'for', 'my', 'individual', 'and', \"company's\", 'growth', 'in', 'best', 'possible']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1qWire4je1w",
        "outputId": "20fc6d73-1621-4636-ae42-ee450485319c"
      },
      "source": [
        "# Превращаем текст в последовательность индексов согласно словарю частотности\n",
        "tok_agreemTest = tokenizer.texts_to_sequences(docsToTest) # Обучающий текст в индексы\n",
        "\n",
        "print(\"Посмотрим на фрагмент тестового текста:\")\n",
        "print(\"Исходный текст:              \", docsToTest[4][:20])\n",
        "print(\"Тот же текст, но как последовательность индексов: \", tok_agreemTest[4][:20], '\\n')\n",
        "\n",
        "xDataTest, yDataTest = getXYSamples(tok_agreemTest,tags_index) # Распознаём теги и создаём лист, что их хранят\n",
        "decoded_text = reverseIndex(clean_voc, xDataTest) # Чтобы создать лист для эмбеддинга, нам нужно превратить лист индексов обратно в лист слов\n",
        "print('Длина xDataTest:', len(xDataTest))\n",
        "print('Длина yDataTest:', len(yDataTest))\n",
        "\n",
        "print('Сдекодированные текст:', decoded_text[50:80])\n",
        "print('Часть xDataTest:     ', xDataTest[50:80])\n",
        "print('Часть yDataTest:     ', yDataTest[50:80])\n",
        "\n",
        "xLen = 256 # Длина окна\n",
        "step = 30 # Шаг \n",
        "embeddingSize = 300 # Число измерений вектор-пространства для каждого нашего слова \n",
        "\n",
        "# Генерируем выборки с определёнными параметрами\n",
        "xTest = getSetFromIndices(decoded_text, xLen, step) # Последовательность индексов с окном Xlen слов\n",
        "yTest = getSetFromIndices(yDataTest, xLen, step) # # Последовательность индексов с окном Xlen от тегов\n",
        "\n",
        "print('Длина xTest:', len(xTest))\n",
        "print('Длина yTest:', len(yTest))\n",
        "print('Длина примера xTest:',len(xTest[0]))\n",
        "print('Длина примера yTrain:',len(yTest[0]), '\\n')\n",
        "print('Пример xTest', xTest[0])\n",
        "print('Пример yTest', yTest[0], '\\n')\n",
        "\n",
        "print('Первый пример xTest:', xTest[0][step-5:step+5])\n",
        "print('Второй пример xTest:', xTest[1][:10])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Посмотрим на фрагмент тестового текста:\n",
            "Исходный текст:               ['<s0>', 'suman', 'biswas', '</s0>', '<s6>', 'sap', 'ui5', 'lead', 'native', 'hana', 'developer', '</s6>', '<s5>', 'royal', 'dutch', 'shell', '</s5>', '<s8>', 'bengaluru', '</s8>']\n",
            "Тот же текст, но как последовательность индексов:  [78, 8806, 8807, 79, 22, 72, 990, 102, 1959, 755, 182, 23, 11, 8808, 8809, 660, 12, 27, 158, 28] \n",
            "\n",
            "Длина xDataTest: 4286\n",
            "Длина yDataTest: 4286\n",
            "Сдекодированные текст: ['2003', '2008', '2012', '2012r2', 'exchange', '2003', '2007', '2010', '2013', 'date', '[…]', 'name', 'pawan', 'nag', 'https', '//www', 'indeed', 'com/r/pawan', 'nag/e14493f28cb72022', 'shivam', 'sharma', 'l1', 'analyst', 'in', 'microsoft', 'project', 'hcl', 'technologies', 'ghaziabad', 'uttar']\n",
            "Часть xDataTest:      [719, 199, 153, 8740, 411, 719, 315, 177, 131, 400, 718, 520, 4892, 4893, 63, 66, 13, 4894, 4895, 4867, 2715, 2203, 251, 4, 29, 19, 922, 147, 2430, 503]\n",
            "Часть yDataTest:      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "Длина xTest: 135\n",
            "Длина yTest: 135\n",
            "Длина примера xTest: 256\n",
            "Длина примера yTrain: 256 \n",
            "\n",
            "Пример xTest ['pawan', 'nag', 'microsoft', 'certify', 'system', 'engineer', 'delhi', 'delhi', 'email', 'me', 'on', 'indeed', 'indeed', 'com/r/pawan', 'nag/e14493f28cb72022', 'work', 'experience', 'microsoft', 'certify', 'system', 'engineer', 'mcsa', '2000', 'to', '2000', 'corporate', 'train', 'in', 'india', 'education', 'amie', 'sec', 'a', 'train', 'program', '2018', 'link', 'https', '//mcp', 'microsoft', 'com/anonymous//transcript/validate', 'additional', 'information', 'skill', 'summary', 'operate', 'systems', 'windows', 'server', '2000', '2003', '2008', '2012', '2012r2', 'exchange', '2003', '2007', '2010', '2013', 'date', '[…]', 'name', 'pawan', 'nag', 'https', '//www', 'indeed', 'com/r/pawan', 'nag/e14493f28cb72022', 'shivam', 'sharma', 'l1', 'analyst', 'in', 'microsoft', 'project', 'hcl', 'technologies', 'ghaziabad', 'uttar', 'pradesh', 'email', 'me', 'on', 'indeed', 'indeed', 'com/r/shivam', 'sharma/8e4755830666f3b6', 'work', 'experience', 'l1', 'analyst', 'in', 'microsoft', 'project', 'hcl', 'technologies', 'noida', 'uttar', 'pradesh', 'september', '2016', 'to', 'present', 'learn', 'learn', 'to', 'work', 'on', 'different', 'field', 'such', 'as', 'network', 'servers', 'sql', 'server', 'and', 'some', 'integration', 'software', 'tool', 'such', 'as', 'microsoft', 'service', 'now', 'snow', '●', 'work', 'as', 'l1', 'analyst', 'in', 'it', 'command', 'center', 'team', 'for', 'monitor', 'network', 'and', 'server', 'issue', '●', 'handson', 'experience', 'in', 'monitor', 'tool', 'service', 'now', 'snow', '●', 'work', 'on', 'user', 'request', 'mail', 'regard', 'servers', 'and', 'network', 'break', 'fix', 'issue', '●', 'communicate', 'and', 'coordinate', 'with', 'different', 'track', 'team', 'for', 'proper', 'resolution', 'of', 'issue', '●', 'work', 'on', 'gmo', 'sql', 'servers', 'for', 'troubleshoot', 'issue', 'like', 'job', 'failures', 'disk', 'space', 'issue', '●', 'work', 'on', 'troubleshoot', 'servers', 'issue', 'like', 'rpd', 'connectivity', 'disc', 'space', 'servicesspn', 'creation', 'and', 'deletion', '●', 'knowledge', 'of', 'dhcp', 'dora', 'process', 'active', 'directories', 'dns', 'fsmo', 'roles', 'forest', 'and', 'domains', 'portion', 'static', 'and', 'dynamic', 'ip', 'trust', 'relations', '●', 'document', 'new', 'process', 'education', 'bachelor', 'of', 'technology', 'in', 'computer', 'science', 'engineer', 'indraprastha', 'engineer', 'college', 'uttar', 'pradesh', 'technical', 'university', 'ghaziabad', 'uttar', 'pradesh', '2016', 'greenfields', 'public', 'school']\n",
            "Пример yTest [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] \n",
            "\n",
            "Первый пример xTest: ['corporate', 'train', 'in', 'india', 'education', 'amie', 'sec', 'a', 'train', 'program']\n",
            "Второй пример xTest: ['amie', 'sec', 'a', 'train', 'program', '2018', 'link', 'https', '//mcp', 'microsoft']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hjZba9cc-kZ"
      },
      "source": [
        "# Функции создания моделей\n",
        "https://youtu.be/wdi8HYhgGj0?t=1574"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnOpxdVYobli"
      },
      "source": [
        "## Функция, что считает ошибку\n",
        "https://youtu.be/wdi8HYhgGj0?t=1566"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcCy8cBXoYVD"
      },
      "source": [
        "# Функция нужна для точности\n",
        "def dice_coef(y_true, y_pred):\n",
        "    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mziewaaKdLRC"
      },
      "source": [
        "## **Conv1D**\n",
        "\n",
        "https://youtu.be/wdi8HYhgGj0?t=1635"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-gxB7-4GEQP"
      },
      "source": [
        "# Функция, что создаёт линейную свёрточную сеть\n",
        "def create_Conv1d(xLen, embeddingSize): \n",
        "  text_input_layer = Input((xLen,embeddingSize)) \n",
        "  text_layer = Conv1D(16, 3, padding='same',activation='relu')(text_input_layer)\n",
        "  text_layer = Conv1D(16, 3, padding='same',activation='relu')(text_layer)\n",
        "  text_layer = Conv1D(16, 3,padding='same', activation='relu')(text_layer) \n",
        "  text_layer = Conv1D(GENSIMtrainY.shape[-1], 3, padding='same',activation='sigmoid')(text_layer)\n",
        "  model = Model(text_input_layer, text_layer)\n",
        "  model.compile(optimizer=Adadelta(),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=[dice_coef])\n",
        "  return model"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCtzijm7dUHA"
      },
      "source": [
        "## **PSPnet**\n",
        "https://youtu.be/wdi8HYhgGj0?t=1697"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPg0cOeddWWA"
      },
      "source": [
        "# Функция по созданию сети PSPnet\n",
        "def create_PSPNet(conv_size = 64, num_classes = 11, input_shape = (30, 300)):\n",
        "    img_input = Input(input_shape)\n",
        "\n",
        "    # Блок 1\n",
        "    x = Conv1D(conv_size, 3, padding='same')(img_input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    x = Conv1D(conv_size, 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x_mp_2 = MaxPooling1D(2)(x)\n",
        "    x_mp_4 = MaxPooling1D(4)(x)\n",
        "    x_mp_8 = MaxPooling1D(8)(x)\n",
        "    x_mp_16 = MaxPooling1D(16)(x)\n",
        "    x_mp_32 = MaxPooling1D(32)(x)\n",
        "\n",
        "    x_mp_2 = Conv1D(conv_size, 3, padding='same', activation='relu')(x_mp_2)\n",
        "    x_mp_2 = Dropout(0.5)(x_mp_2)\n",
        "\n",
        "    x_mp_4 = Conv1D(conv_size, 3, padding='same', activation='relu')(x_mp_4)\n",
        "    x_mp_4 = Dropout(0.5)(x_mp_4)\n",
        "\n",
        "    x_mp_8 = Conv1D(conv_size, 3, padding='same', activation='relu')(x_mp_8)\n",
        "    x_mp_8 = Dropout(0.5)(x_mp_8)\n",
        "\n",
        "    x_mp_16 = Conv1D(conv_size, 3, padding='same', activation='relu')(x_mp_16)\n",
        "    x_mp_16 = Dropout(0.5)(x_mp_16)\n",
        "\n",
        "    x_mp_32 = Conv1D(conv_size, 3, padding='same', activation='relu')(x_mp_32)\n",
        "    x_mp_32 = Dropout(0.5)(x_mp_32) \n",
        "\n",
        "    x_mp_2 = Conv1DTranspose(conv_size, 2, strides=2)(x_mp_2)\n",
        "    x_mp_2 = Activation('relu')(x_mp_2)\n",
        "\n",
        "    x_mp_4 = Conv1DTranspose(conv_size, 4, strides=4)(x_mp_4)\n",
        "    x_mp_4 = Activation('relu')(x_mp_4)\n",
        "\n",
        "    x_mp_8 = Conv1DTranspose(conv_size, 8, strides=8)(x_mp_8)\n",
        "    x_mp_8 = Activation('relu')(x_mp_8)\n",
        "\n",
        "    x_mp_16 = Conv1DTranspose(conv_size, 16, strides=16)(x_mp_16)\n",
        "    x_mp_16 = Activation('relu')(x_mp_16)\n",
        "\n",
        "    x_mp_32 = Conv1DTranspose(conv_size, 32, strides=32)(x_mp_32)\n",
        "    x_mp_32 = Activation('relu')(x_mp_32)\n",
        "\n",
        "    fin = concatenate([img_input, x_mp_2, x_mp_4, x_mp_8, x_mp_16, x_mp_32])    \n",
        "    fin = Conv1D(conv_size, 3, padding='same')(fin)\n",
        "    fin = BatchNormalization()(fin)\n",
        "    fin = Activation('relu')(fin)\n",
        "    fin = Conv1D(conv_size, 3, padding='same')(fin)\n",
        "    fin = BatchNormalization()(fin)\n",
        "    fin = Activation('relu')(fin)\n",
        "\n",
        "    fin = Conv1D(num_classes, 3, activation='sigmoid', padding='same')(fin)\n",
        "\n",
        "    model = Model(img_input, fin)\n",
        "    model.compile(optimizer=Adadelta(lr=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=[dice_coef])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTqr7W3GdV3n"
      },
      "source": [
        "##**UNET**\n",
        "https://youtu.be/wdi8HYhgGj0?t=1769"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez6T-lXcEmNL"
      },
      "source": [
        "# Функция по созданию сети UNET\n",
        "def create_unet(k = 1, num_classes = 11, input_shape= (30, 300)):\n",
        "    img_input = Input(input_shape) \n",
        "\n",
        "    # Блок 1\n",
        "    x = Conv1D(64 * k , 3, padding='same')(img_input) \n",
        "    x = BatchNormalization()(x) \n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv1D(64 * k, 3, padding='same')(x)  \n",
        "    x = BatchNormalization()(x)     \n",
        "    block_1_out = Activation('relu')(x) \n",
        "\n",
        "    # Блок 2\n",
        "    x = MaxPooling1D()(block_1_out)\n",
        "    x = Conv1D(128 * k, 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)  \n",
        "\n",
        "    x = Conv1D(128 * k , 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    block_2_out = Activation('relu')(x)\n",
        "\n",
        "    # Блок 3\n",
        "    x = MaxPooling1D()(block_2_out)\n",
        "    x = Conv1D(256 * k, 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)               \n",
        "    x = Activation('relu')(x)                     \n",
        "\n",
        "    x = Conv1D(256 * k , 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv1D(256 * k , 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    block_3_out = Activation('relu')(x)\n",
        "\n",
        "    # Блок 4\n",
        "    x = MaxPooling1D()(block_3_out)\n",
        "    x = Conv1D(512 * k, 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x) \n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv1D(512 * k , 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv1D(512 * k , 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)      \n",
        "    block_4_out = Activation('relu')(x)\n",
        "    x = block_4_out \n",
        "\n",
        "    # UP 2\n",
        "    x = Conv1DTranspose(256 * k, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x) \n",
        "\n",
        "    x = concatenate([x, block_3_out]) \n",
        "    x = Conv1D(256 * k , 3, padding='same')(x) \n",
        "    x = BatchNormalization()(x) \n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv1D(256 * k , 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    # UP 3\n",
        "    x = Conv1DTranspose(128 * k, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x) \n",
        "\n",
        "    x = concatenate([x, block_2_out])\n",
        "    x = Conv1D(128 * k , 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv1D(128 * k , 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # UP 4\n",
        "    x = Conv1DTranspose(64 * k, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = concatenate([x, block_1_out])\n",
        "    x = Conv1D(64 * k , 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv1D(64 * k , 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv1D(num_classes, 3, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    model = Model(img_input, x) \n",
        "\n",
        "    model = Model(img_input, x)\n",
        "    model.compile(optimizer=Adam(0.0025), \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=[dice_coef])\n",
        "  \n",
        "    return model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbx6fVH_e0fZ"
      },
      "source": [
        "# Создание xTrain и  yTrain используя Word2Vec GENSIM\n",
        "\n",
        "https://youtu.be/wdi8HYhgGj0?t=1830\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59GQEYwpfLY3"
      },
      "source": [
        "def pad_zeros(phrase, xLen = 256): # Функция для дополнением нулями\n",
        "  while len(phrase) < xLen: # Пока сущестующий размер меньше чем требуемый \n",
        "    phrase.append([0] * embeddingSize) # Продолжаем добавлять элементы(нули) в фразу(zero-pad)  \n",
        "  if len(phrase) > xLen: # В противном случае, если фраза больше чем  требуемый размер\n",
        "    phrase = phrase[:xLen] # Берём только требуемое число элементов\n",
        "  return phrase # Возвращаем обработанную фразу\n",
        "\n",
        "# Создаём выборку\n",
        "def getSets(model, senI, tagI):\n",
        "  xVector = [] # Лист будет содержать ембеддинг представление на каждый индекс\n",
        "  tmp = [] # Временный список\n",
        "  for text in senI: # Проходимся по каждому лист-тексту\n",
        "    tmp=[]\n",
        "    for word in text: # Проходимся по кажому слову лист-текста\n",
        "      try: # Если слово есть в модели (словарь не слишком мал), мы не получим ошибку\n",
        "        tmp.append(model[word])\n",
        "      except: # В противном случае пропустим слово\n",
        "        pass\n",
        "\n",
        "    xVector.append(pad_zeros(tmp, xLen))\n",
        "  temp = np.array(xVector)\n",
        "  return np.array(xVector, dtype = np.float32), np.array(tagI)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6690s4h2e-ub",
        "outputId": "163cd6be-d804-4e6a-a41c-cf6a09fd033c"
      },
      "source": [
        "# Подаём лист листов слов в word2vec для обучающей выборке\n",
        "# size = embeddingSize - Размер ембеддинга\n",
        "# window = 10 -  минимальное расстояния между эмбеддинг словами\n",
        "# min_count = 1 - Игнорируем все слова с частотой меньше чем 1\n",
        "# workers = 10 -  Число потоков на обучение эмбеддинга\n",
        "# iter = 20 -  Число эпох на обучение эмбеддинга\n",
        "# max_vocab_size = 1e5 -  Число слов в \"словарном запасе\" word2vec\n",
        "curTime = time.time()\n",
        "\n",
        "modelGENSIM = word2vec.Word2Vec(xTrain + xTest, size = embeddingSize, window = 10, min_count = 1, workers = 10, iter = 10, max_vocab_size = 1e5)\n",
        "print('Обучение GENSIM модели заняло: ', round(time.time() - curTime, 2), 'с.')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение GENSIM модели заняло:  17.47 с.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CXXGJZOwRlE",
        "outputId": "9ec4ccfc-c836-4584-f24c-beb71f4c026e"
      },
      "source": [
        "modelGENSIM['education'] # Пример превращения слова в вектор при помощи GENSIM"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.2154312 , -0.5298406 ,  2.155577  , -0.4374456 ,  0.67386866,\n",
              "        0.7269224 ,  1.4426969 ,  1.9769449 ,  1.1434984 ,  1.3292294 ,\n",
              "       -4.0356855 , -0.21189646, -0.10808229,  1.6741306 , -1.094256  ,\n",
              "        1.5311981 ,  1.5448023 ,  1.9651257 , -0.5191166 ,  1.421021  ,\n",
              "       -1.6495837 , -2.9194953 ,  1.1780385 ,  2.0927384 ,  2.5980332 ,\n",
              "       -1.2511398 ,  3.0788505 ,  0.3801587 , -1.5925753 ,  0.3489633 ,\n",
              "       -0.04976106,  2.056907  ,  0.9842874 , -1.6463654 ,  0.6465096 ,\n",
              "       -1.0147517 , -2.9270062 , -1.7677222 , -1.0815783 , -0.5335973 ,\n",
              "       -1.6391389 ,  0.83242804,  0.8930105 ,  1.4093379 , -0.62933856,\n",
              "       -0.5475573 , -0.04790112,  2.095309  ,  2.454906  ,  0.30066928,\n",
              "       -2.5687857 , -2.2330005 , -1.197821  ,  0.2989786 , -2.3574698 ,\n",
              "        1.2166109 , -0.9348499 , -1.1456035 , -1.2778476 ,  3.6232152 ,\n",
              "       -0.46689966, -2.5595548 ,  0.2635063 , -2.0429075 , -3.520094  ,\n",
              "        0.12303239, -0.55002004, -0.84671247,  2.057597  ,  2.2971797 ,\n",
              "       -1.5424188 , -1.2271225 , -1.1583213 ,  0.9539508 , -2.6554813 ,\n",
              "        1.2322818 , -1.2583268 ,  1.7325672 , -1.9503291 , -0.16365527,\n",
              "       -0.8388494 , -0.47977683,  0.267072  , -1.6435914 ,  0.51340175,\n",
              "        3.7184484 ,  1.9025855 , -1.2409421 , -1.3629287 , -2.1195028 ,\n",
              "       -0.4404973 ,  0.1537925 ,  1.6889291 ,  3.9517105 , -0.62597555,\n",
              "        0.863215  , -0.3629079 ,  1.1601727 ,  1.0186574 ,  1.0998572 ,\n",
              "       -1.1161757 ,  0.55560833,  0.1526834 ,  3.5918872 , -1.3127863 ,\n",
              "        2.3518395 , -0.45786163,  2.8078463 ,  0.72530985,  0.8606356 ,\n",
              "        0.10640972,  0.55567616,  0.71303284, -0.9565053 , -0.9021177 ,\n",
              "       -1.9959923 , -0.7814249 , -1.1398404 ,  0.7267346 ,  1.3539382 ,\n",
              "        0.5581689 , -1.4625617 ,  5.4881964 ,  3.2035356 , -1.4171925 ,\n",
              "       -1.1492168 ,  1.7068701 , -0.9088213 , -0.5188649 , -0.25034562,\n",
              "        1.8579153 ,  1.0114812 , -0.1350793 ,  2.0702517 ,  1.8351755 ,\n",
              "        1.89964   , -0.30436683,  2.8674245 ,  0.50299114, -0.3358684 ,\n",
              "        0.3721739 ,  0.8399507 ,  2.3301344 ,  1.2078737 ,  0.45745432,\n",
              "        3.421484  ,  0.22903563, -0.8038223 ,  0.73746735,  1.6883166 ,\n",
              "       -3.6444843 , -0.53591096, -1.7427292 , -2.4772894 ,  1.307811  ,\n",
              "        4.2669373 ,  2.301909  , -1.8923666 , -0.6656281 , -2.5556383 ,\n",
              "       -2.4150789 , -0.51724887,  0.8666346 , -1.7388653 ,  3.191844  ,\n",
              "        0.8606246 , -0.81314087,  0.88459575,  0.21128677,  1.4667916 ,\n",
              "       -4.621431  ,  0.78763014,  0.48665497,  1.1701119 , -0.33753088,\n",
              "       -2.7869015 ,  0.85758924, -0.11947564,  0.498026  , -1.607916  ,\n",
              "        0.3350247 ,  1.8517379 , -1.4973745 , -1.8071343 , -0.07457013,\n",
              "        0.30777618, -0.89064944,  1.3878866 , -1.8390948 , -0.8198315 ,\n",
              "        0.4815863 , -0.05561358,  0.13342634,  0.40962568,  0.16833453,\n",
              "       -0.13196993, -1.4554428 , -1.3569695 , -1.7260568 , -0.2110673 ,\n",
              "       -0.2636345 ,  2.72142   , -1.6621668 ,  0.9542202 , -0.18293259,\n",
              "        1.1289752 , -0.78965086,  2.6056929 , -2.079517  , -0.6506921 ,\n",
              "       -3.9550128 ,  1.7657702 , -1.297162  , -0.93163717, -1.1299299 ,\n",
              "        0.15064608,  2.6496067 , -0.7039158 , -3.390822  ,  1.2986566 ,\n",
              "       -0.18173625, -0.79566973, -1.4279827 , -0.8383473 , -2.1991503 ,\n",
              "       -2.8826196 ,  0.69689447,  1.5052693 , -1.8162493 ,  0.95911753,\n",
              "        0.46061715,  0.7458863 ,  1.740367  , -1.7084107 , -0.39636636,\n",
              "       -1.8354231 , -0.34140855,  2.370044  ,  1.7732826 , -1.8641298 ,\n",
              "        2.5243013 ,  0.9605847 , -0.4639032 ,  0.40697396, -0.33891016,\n",
              "        0.8867986 ,  0.7829099 ,  1.3572769 , -0.58161765,  0.26255208,\n",
              "        0.11245432,  0.42943943,  0.7164527 , -3.4511156 ,  0.28441793,\n",
              "       -4.2473187 ,  2.2637146 , -0.16781223, -1.1157151 ,  4.478067  ,\n",
              "        1.8430455 ,  0.48254827,  0.6309023 ,  0.46141157, -0.28848892,\n",
              "        1.7216018 , -0.21628314, -1.6535275 , -2.7224796 ,  1.7354941 ,\n",
              "       -2.7004285 , -1.2628897 , -1.7913067 ,  2.777279  ,  1.3033967 ,\n",
              "       -0.3887698 ,  0.24297187, -1.0614293 ,  0.64085364, -0.19577466,\n",
              "        1.208328  , -0.5486696 ,  1.6399328 , -0.6572912 ,  2.5857518 ,\n",
              "       -1.2074007 , -0.6839722 ,  2.0387688 , -0.8502172 , -2.2102926 ,\n",
              "       -1.9686428 , -0.9987588 , -0.9012566 ,  2.6319766 ,  0.5775808 ,\n",
              "       -1.286472  , -2.014591  ,  1.9418263 , -1.85474   ,  3.082681  ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOUuS0F7CPX4",
        "outputId": "4150dbbe-c88e-479e-ee53-84aa7026059c"
      },
      "source": [
        "GENSIMtrainX, GENSIMtrainY = getSets(modelGENSIM, xTrain, yTrain)\n",
        "GENSIMtestX, GENSIMtestY = getSets(modelGENSIM, xTest, yTest)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKYZvDrZfeQ9",
        "outputId": "c3835e9b-6961-40b8-fc49-ecd6bc6f7872"
      },
      "source": [
        "print('Размерности xTrain:', GENSIMtrainX.shape)\n",
        "print('Размерности yTrain:', GENSIMtrainY.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерности xTrain: (3301, 256, 300)\n",
            "Размерности yTrain: (3301, 256, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7djpTsWtsTPZ"
      },
      "source": [
        "# Train the networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpFOmij7sWaa"
      },
      "source": [
        "## **Linear Conv1d network**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRdgVq8tGukv",
        "outputId": "95fc1a2e-ac50-435e-9aff-ed942b01f89e"
      },
      "source": [
        "model_conv1d = create_Conv1d(xLen, embeddingSize) # Создаем модель\n",
        "model_conv1d.summary() # Выводим саммери"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 256, 300)]        0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 256, 16)           14416     \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 256, 16)           784       \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 256, 16)           784       \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 256, 11)           539       \n",
            "=================================================================\n",
            "Total params: 16,523\n",
            "Trainable params: 16,523\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oAJRdKiGtxD",
        "outputId": "80a7b1f0-54e4-4dae-cc23-52aa077fac22"
      },
      "source": [
        "history = model_conv1d.fit(GENSIMtrainX, GENSIMtrainY, epochs=50, batch_size=200, validation_data=(GENSIMtestX, GENSIMtestY)) # Обучаем модель на сверточной сети"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "17/17 [==============================] - 18s 54ms/step - loss: 0.3847 - dice_coef: 0.0238 - val_loss: 0.2592 - val_dice_coef: 0.0176\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3845 - dice_coef: 0.0238 - val_loss: 0.2590 - val_dice_coef: 0.0177\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3842 - dice_coef: 0.0238 - val_loss: 0.2589 - val_dice_coef: 0.0177\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3839 - dice_coef: 0.0239 - val_loss: 0.2587 - val_dice_coef: 0.0177\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3836 - dice_coef: 0.0238 - val_loss: 0.2585 - val_dice_coef: 0.0177\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3833 - dice_coef: 0.0239 - val_loss: 0.2584 - val_dice_coef: 0.0177\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3830 - dice_coef: 0.0239 - val_loss: 0.2582 - val_dice_coef: 0.0177\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.3827 - dice_coef: 0.0239 - val_loss: 0.2580 - val_dice_coef: 0.0177\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.3824 - dice_coef: 0.0239 - val_loss: 0.2579 - val_dice_coef: 0.0177\n",
            "Epoch 10/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3821 - dice_coef: 0.0238 - val_loss: 0.2577 - val_dice_coef: 0.0177\n",
            "Epoch 11/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3817 - dice_coef: 0.0239 - val_loss: 0.2575 - val_dice_coef: 0.0178\n",
            "Epoch 12/50\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.3814 - dice_coef: 0.0239 - val_loss: 0.2573 - val_dice_coef: 0.0178\n",
            "Epoch 13/50\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.3811 - dice_coef: 0.0240 - val_loss: 0.2572 - val_dice_coef: 0.0178\n",
            "Epoch 14/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3808 - dice_coef: 0.0239 - val_loss: 0.2570 - val_dice_coef: 0.0178\n",
            "Epoch 15/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3805 - dice_coef: 0.0240 - val_loss: 0.2568 - val_dice_coef: 0.0178\n",
            "Epoch 16/50\n",
            "17/17 [==============================] - 1s 41ms/step - loss: 0.3802 - dice_coef: 0.0239 - val_loss: 0.2567 - val_dice_coef: 0.0178\n",
            "Epoch 17/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3799 - dice_coef: 0.0240 - val_loss: 0.2565 - val_dice_coef: 0.0178\n",
            "Epoch 18/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3796 - dice_coef: 0.0241 - val_loss: 0.2563 - val_dice_coef: 0.0178\n",
            "Epoch 19/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3793 - dice_coef: 0.0241 - val_loss: 0.2561 - val_dice_coef: 0.0179\n",
            "Epoch 20/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3790 - dice_coef: 0.0240 - val_loss: 0.2560 - val_dice_coef: 0.0179\n",
            "Epoch 21/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3788 - dice_coef: 0.0241 - val_loss: 0.2558 - val_dice_coef: 0.0179\n",
            "Epoch 22/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3785 - dice_coef: 0.0240 - val_loss: 0.2556 - val_dice_coef: 0.0179\n",
            "Epoch 23/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3782 - dice_coef: 0.0241 - val_loss: 0.2554 - val_dice_coef: 0.0179\n",
            "Epoch 24/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3779 - dice_coef: 0.0243 - val_loss: 0.2553 - val_dice_coef: 0.0179\n",
            "Epoch 25/50\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.3776 - dice_coef: 0.0242 - val_loss: 0.2551 - val_dice_coef: 0.0179\n",
            "Epoch 26/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3773 - dice_coef: 0.0243 - val_loss: 0.2549 - val_dice_coef: 0.0179\n",
            "Epoch 27/50\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.3770 - dice_coef: 0.0242 - val_loss: 0.2548 - val_dice_coef: 0.0179\n",
            "Epoch 28/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3767 - dice_coef: 0.0242 - val_loss: 0.2546 - val_dice_coef: 0.0180\n",
            "Epoch 29/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3764 - dice_coef: 0.0242 - val_loss: 0.2544 - val_dice_coef: 0.0180\n",
            "Epoch 30/50\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.3762 - dice_coef: 0.0243 - val_loss: 0.2543 - val_dice_coef: 0.0180\n",
            "Epoch 31/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3759 - dice_coef: 0.0243 - val_loss: 0.2541 - val_dice_coef: 0.0180\n",
            "Epoch 32/50\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.3756 - dice_coef: 0.0242 - val_loss: 0.2539 - val_dice_coef: 0.0180\n",
            "Epoch 33/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3753 - dice_coef: 0.0242 - val_loss: 0.2537 - val_dice_coef: 0.0180\n",
            "Epoch 34/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3750 - dice_coef: 0.0243 - val_loss: 0.2536 - val_dice_coef: 0.0180\n",
            "Epoch 35/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3748 - dice_coef: 0.0244 - val_loss: 0.2534 - val_dice_coef: 0.0180\n",
            "Epoch 36/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3745 - dice_coef: 0.0244 - val_loss: 0.2532 - val_dice_coef: 0.0181\n",
            "Epoch 37/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3742 - dice_coef: 0.0242 - val_loss: 0.2531 - val_dice_coef: 0.0181\n",
            "Epoch 38/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3739 - dice_coef: 0.0243 - val_loss: 0.2529 - val_dice_coef: 0.0181\n",
            "Epoch 39/50\n",
            "17/17 [==============================] - 1s 36ms/step - loss: 0.3737 - dice_coef: 0.0245 - val_loss: 0.2527 - val_dice_coef: 0.0181\n",
            "Epoch 40/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3734 - dice_coef: 0.0243 - val_loss: 0.2525 - val_dice_coef: 0.0181\n",
            "Epoch 41/50\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.3731 - dice_coef: 0.0244 - val_loss: 0.2524 - val_dice_coef: 0.0181\n",
            "Epoch 42/50\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.3729 - dice_coef: 0.0242 - val_loss: 0.2522 - val_dice_coef: 0.0181\n",
            "Epoch 43/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3726 - dice_coef: 0.0244 - val_loss: 0.2521 - val_dice_coef: 0.0181\n",
            "Epoch 44/50\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.3724 - dice_coef: 0.0244 - val_loss: 0.2519 - val_dice_coef: 0.0182\n",
            "Epoch 45/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3721 - dice_coef: 0.0244 - val_loss: 0.2517 - val_dice_coef: 0.0182\n",
            "Epoch 46/50\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.3718 - dice_coef: 0.0245 - val_loss: 0.2516 - val_dice_coef: 0.0182\n",
            "Epoch 47/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3716 - dice_coef: 0.0243 - val_loss: 0.2514 - val_dice_coef: 0.0182\n",
            "Epoch 48/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3713 - dice_coef: 0.0243 - val_loss: 0.2512 - val_dice_coef: 0.0182\n",
            "Epoch 49/50\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.3711 - dice_coef: 0.0246 - val_loss: 0.2511 - val_dice_coef: 0.0182\n",
            "Epoch 50/50\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.3708 - dice_coef: 0.0246 - val_loss: 0.2509 - val_dice_coef: 0.0182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8mneom-sdDc"
      },
      "source": [
        "## **PSPnet**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff5hlxXXobZk"
      },
      "source": [
        "### Стандартная архитектура"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLLV9sr_jnCW",
        "outputId": "33639d45-69fe-43d9-b530-f8e674ed7328"
      },
      "source": [
        "model_b_PSPnet = create_PSPNet(input_shape=(xLen, embeddingSize))\n",
        "model_b_PSPnet.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 256, 300)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 256, 64)      57664       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 64)      256         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 256, 64)      0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 256, 64)      12352       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256, 64)      256         conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 256, 64)      0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 128, 64)      0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 64, 64)       0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 32, 64)       0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 16, 64)       0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 8, 64)        0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 128, 64)      12352       max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 64, 64)       12352       max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 32, 64)       12352       max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 16, 64)       12352       max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 8, 64)        12352       max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 128, 64)      0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64, 64)       0           conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 64)       0           conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 16, 64)       0           conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 8, 64)        0           conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose (Conv1DTranspo (None, 256, 64)      8256        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTrans (None, 256, 64)      16448       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTrans (None, 256, 64)      32832       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_3 (Conv1DTrans (None, 256, 64)      65600       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_4 (Conv1DTrans (None, 256, 64)      131136      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 256, 64)      0           conv1d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 256, 64)      0           conv1d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 256, 64)      0           conv1d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 256, 64)      0           conv1d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 256, 64)      0           conv1d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256, 620)     0           input_2[0][0]                    \n",
            "                                                                 activation_2[0][0]               \n",
            "                                                                 activation_3[0][0]               \n",
            "                                                                 activation_4[0][0]               \n",
            "                                                                 activation_5[0][0]               \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 256, 64)      119104      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 64)      256         conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 256, 64)      0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 256, 64)      12352       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 256, 64)      256         conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 256, 64)      0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 256, 11)      2123        activation_8[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 520,651\n",
            "Trainable params: 520,139\n",
            "Non-trainable params: 512\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJM0-dmMjrKi",
        "outputId": "5872e937-574d-4da6-ba4e-9ac4770f3dd2"
      },
      "source": [
        "history = model_b_PSPnet.fit(GENSIMtrainX, GENSIMtrainY, validation_data = (GENSIMtestX, GENSIMtestY), epochs=50, batch_size=64)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "52/52 [==============================] - 4s 43ms/step - loss: 0.3773 - dice_coef: 0.0271 - val_loss: 0.2458 - val_dice_coef: 0.0190\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.3743 - dice_coef: 0.0274 - val_loss: 0.2482 - val_dice_coef: 0.0190\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.3711 - dice_coef: 0.0276 - val_loss: 0.2496 - val_dice_coef: 0.0192\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.3681 - dice_coef: 0.0279 - val_loss: 0.2500 - val_dice_coef: 0.0193\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3650 - dice_coef: 0.0283 - val_loss: 0.2494 - val_dice_coef: 0.0195\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3618 - dice_coef: 0.0286 - val_loss: 0.2480 - val_dice_coef: 0.0198\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3585 - dice_coef: 0.0289 - val_loss: 0.2461 - val_dice_coef: 0.0200\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3553 - dice_coef: 0.0292 - val_loss: 0.2439 - val_dice_coef: 0.0203\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3521 - dice_coef: 0.0295 - val_loss: 0.2415 - val_dice_coef: 0.0205\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3486 - dice_coef: 0.0299 - val_loss: 0.2389 - val_dice_coef: 0.0208\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3454 - dice_coef: 0.0302 - val_loss: 0.2362 - val_dice_coef: 0.0210\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3421 - dice_coef: 0.0306 - val_loss: 0.2335 - val_dice_coef: 0.0213\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3389 - dice_coef: 0.0310 - val_loss: 0.2308 - val_dice_coef: 0.0215\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.3355 - dice_coef: 0.0313 - val_loss: 0.2281 - val_dice_coef: 0.0218\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3324 - dice_coef: 0.0316 - val_loss: 0.2254 - val_dice_coef: 0.0220\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3291 - dice_coef: 0.0319 - val_loss: 0.2227 - val_dice_coef: 0.0223\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3260 - dice_coef: 0.0324 - val_loss: 0.2200 - val_dice_coef: 0.0226\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3227 - dice_coef: 0.0327 - val_loss: 0.2174 - val_dice_coef: 0.0228\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.3197 - dice_coef: 0.0330 - val_loss: 0.2148 - val_dice_coef: 0.0231\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.3167 - dice_coef: 0.0333 - val_loss: 0.2123 - val_dice_coef: 0.0233\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3140 - dice_coef: 0.0336 - val_loss: 0.2099 - val_dice_coef: 0.0236\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.3110 - dice_coef: 0.0341 - val_loss: 0.2075 - val_dice_coef: 0.0238\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3081 - dice_coef: 0.0343 - val_loss: 0.2052 - val_dice_coef: 0.0240\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3052 - dice_coef: 0.0347 - val_loss: 0.2030 - val_dice_coef: 0.0243\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.3028 - dice_coef: 0.0350 - val_loss: 0.2008 - val_dice_coef: 0.0245\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3002 - dice_coef: 0.0352 - val_loss: 0.1987 - val_dice_coef: 0.0247\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2975 - dice_coef: 0.0356 - val_loss: 0.1967 - val_dice_coef: 0.0249\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2952 - dice_coef: 0.0360 - val_loss: 0.1948 - val_dice_coef: 0.0252\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.2926 - dice_coef: 0.0362 - val_loss: 0.1929 - val_dice_coef: 0.0254\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.2904 - dice_coef: 0.0365 - val_loss: 0.1911 - val_dice_coef: 0.0256\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2880 - dice_coef: 0.0368 - val_loss: 0.1894 - val_dice_coef: 0.0258\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2857 - dice_coef: 0.0372 - val_loss: 0.1877 - val_dice_coef: 0.0260\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2839 - dice_coef: 0.0374 - val_loss: 0.1861 - val_dice_coef: 0.0262\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2818 - dice_coef: 0.0378 - val_loss: 0.1846 - val_dice_coef: 0.0264\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2795 - dice_coef: 0.0380 - val_loss: 0.1831 - val_dice_coef: 0.0266\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2776 - dice_coef: 0.0383 - val_loss: 0.1816 - val_dice_coef: 0.0268\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2757 - dice_coef: 0.0387 - val_loss: 0.1803 - val_dice_coef: 0.0271\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2742 - dice_coef: 0.0390 - val_loss: 0.1790 - val_dice_coef: 0.0273\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2723 - dice_coef: 0.0393 - val_loss: 0.1777 - val_dice_coef: 0.0275\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2707 - dice_coef: 0.0396 - val_loss: 0.1765 - val_dice_coef: 0.0277\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.2690 - dice_coef: 0.0399 - val_loss: 0.1753 - val_dice_coef: 0.0279\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2673 - dice_coef: 0.0402 - val_loss: 0.1741 - val_dice_coef: 0.0281\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2659 - dice_coef: 0.0404 - val_loss: 0.1730 - val_dice_coef: 0.0283\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2644 - dice_coef: 0.0407 - val_loss: 0.1720 - val_dice_coef: 0.0285\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2627 - dice_coef: 0.0410 - val_loss: 0.1709 - val_dice_coef: 0.0287\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2617 - dice_coef: 0.0413 - val_loss: 0.1699 - val_dice_coef: 0.0289\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.2599 - dice_coef: 0.0417 - val_loss: 0.1690 - val_dice_coef: 0.0291\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.2588 - dice_coef: 0.0420 - val_loss: 0.1680 - val_dice_coef: 0.0294\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2575 - dice_coef: 0.0424 - val_loss: 0.1672 - val_dice_coef: 0.0296\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.2560 - dice_coef: 0.0426 - val_loss: 0.1663 - val_dice_coef: 0.0298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4OzPQwnoxUm"
      },
      "source": [
        "### 256 нейронов в свёрточном ядре"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P31-kSvUlmDh",
        "outputId": "15b5ef53-5322-4d23-efe7-86a85f3e427a"
      },
      "source": [
        "model_b_PSPnet = create_PSPNet(conv_size = 256, input_shape=(xLen, embeddingSize))\n",
        "model_b_PSPnet.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 256, 300)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 256, 256)     230656      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 256, 256)     1024        conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 256, 256)     0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 256, 256)     196864      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 256, 256)     1024        conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 256, 256)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 128, 256)     0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1D)  (None, 64, 256)      0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1D)  (None, 32, 256)      0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1D)  (None, 16, 256)      0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1D)  (None, 8, 256)       0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 128, 256)     196864      max_pooling1d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_17 (Conv1D)              (None, 64, 256)      196864      max_pooling1d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_18 (Conv1D)              (None, 32, 256)      196864      max_pooling1d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_19 (Conv1D)              (None, 16, 256)      196864      max_pooling1d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_20 (Conv1D)              (None, 8, 256)       196864      max_pooling1d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 128, 256)     0           conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 64, 256)      0           conv1d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 256)      0           conv1d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 16, 256)      0           conv1d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 8, 256)       0           conv1d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_5 (Conv1DTrans (None, 256, 256)     131328      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_6 (Conv1DTrans (None, 256, 256)     262400      dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_7 (Conv1DTrans (None, 256, 256)     524544      dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_8 (Conv1DTrans (None, 256, 256)     1048832     dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_9 (Conv1DTrans (None, 256, 256)     2097408     dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 256, 256)     0           conv1d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 256, 256)     0           conv1d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 256, 256)     0           conv1d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 256, 256)     0           conv1d_transpose_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 256, 256)     0           conv1d_transpose_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256, 1580)    0           input_3[0][0]                    \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_21 (Conv1D)              (None, 256, 256)     1213696     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 256, 256)     1024        conv1d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 256, 256)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_22 (Conv1D)              (None, 256, 256)     196864      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 256, 256)     1024        conv1d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 256, 256)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_23 (Conv1D)              (None, 256, 11)      8459        activation_17[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 6,899,467\n",
            "Trainable params: 6,897,419\n",
            "Non-trainable params: 2,048\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kYL0cISl-AK",
        "outputId": "38ec97eb-b973-469b-f704-60a273706904"
      },
      "source": [
        "history = model_b_PSPnet.fit(GENSIMtrainX, GENSIMtrainY, validation_data = (GENSIMtestX, GENSIMtestY), epochs=50, batch_size=64)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "52/52 [==============================] - 7s 87ms/step - loss: 0.4489 - dice_coef: 0.0216 - val_loss: 0.2640 - val_dice_coef: 0.0159\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.4319 - dice_coef: 0.0228 - val_loss: 0.2608 - val_dice_coef: 0.0164\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.4152 - dice_coef: 0.0242 - val_loss: 0.2563 - val_dice_coef: 0.0171\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.3996 - dice_coef: 0.0257 - val_loss: 0.2496 - val_dice_coef: 0.0180\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.3849 - dice_coef: 0.0271 - val_loss: 0.2414 - val_dice_coef: 0.0191\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.3706 - dice_coef: 0.0286 - val_loss: 0.2324 - val_dice_coef: 0.0202\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.3572 - dice_coef: 0.0301 - val_loss: 0.2232 - val_dice_coef: 0.0213\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.3444 - dice_coef: 0.0315 - val_loss: 0.2144 - val_dice_coef: 0.0223\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.3335 - dice_coef: 0.0329 - val_loss: 0.2063 - val_dice_coef: 0.0234\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.3228 - dice_coef: 0.0343 - val_loss: 0.1988 - val_dice_coef: 0.0244\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.3132 - dice_coef: 0.0356 - val_loss: 0.1921 - val_dice_coef: 0.0253\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.3046 - dice_coef: 0.0370 - val_loss: 0.1860 - val_dice_coef: 0.0263\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.2971 - dice_coef: 0.0381 - val_loss: 0.1807 - val_dice_coef: 0.0272\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 4s 71ms/step - loss: 0.2895 - dice_coef: 0.0394 - val_loss: 0.1759 - val_dice_coef: 0.0281\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.2831 - dice_coef: 0.0406 - val_loss: 0.1716 - val_dice_coef: 0.0290\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.2772 - dice_coef: 0.0419 - val_loss: 0.1676 - val_dice_coef: 0.0298\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2715 - dice_coef: 0.0432 - val_loss: 0.1641 - val_dice_coef: 0.0307\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2669 - dice_coef: 0.0443 - val_loss: 0.1609 - val_dice_coef: 0.0316\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 4s 71ms/step - loss: 0.2624 - dice_coef: 0.0454 - val_loss: 0.1579 - val_dice_coef: 0.0325\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2580 - dice_coef: 0.0467 - val_loss: 0.1552 - val_dice_coef: 0.0334\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2543 - dice_coef: 0.0479 - val_loss: 0.1526 - val_dice_coef: 0.0344\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2506 - dice_coef: 0.0492 - val_loss: 0.1503 - val_dice_coef: 0.0353\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2476 - dice_coef: 0.0506 - val_loss: 0.1481 - val_dice_coef: 0.0363\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2443 - dice_coef: 0.0519 - val_loss: 0.1461 - val_dice_coef: 0.0373\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2409 - dice_coef: 0.0532 - val_loss: 0.1442 - val_dice_coef: 0.0383\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2383 - dice_coef: 0.0546 - val_loss: 0.1425 - val_dice_coef: 0.0393\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.2358 - dice_coef: 0.0560 - val_loss: 0.1409 - val_dice_coef: 0.0404\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2334 - dice_coef: 0.0575 - val_loss: 0.1394 - val_dice_coef: 0.0415\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2310 - dice_coef: 0.0586 - val_loss: 0.1380 - val_dice_coef: 0.0426\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 4s 71ms/step - loss: 0.2288 - dice_coef: 0.0603 - val_loss: 0.1367 - val_dice_coef: 0.0438\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.2268 - dice_coef: 0.0620 - val_loss: 0.1354 - val_dice_coef: 0.0450\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.2249 - dice_coef: 0.0633 - val_loss: 0.1343 - val_dice_coef: 0.0462\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2229 - dice_coef: 0.0651 - val_loss: 0.1333 - val_dice_coef: 0.0474\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2209 - dice_coef: 0.0665 - val_loss: 0.1323 - val_dice_coef: 0.0487\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2196 - dice_coef: 0.0680 - val_loss: 0.1314 - val_dice_coef: 0.0500\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.2176 - dice_coef: 0.0699 - val_loss: 0.1305 - val_dice_coef: 0.0514\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2162 - dice_coef: 0.0716 - val_loss: 0.1297 - val_dice_coef: 0.0527\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.2151 - dice_coef: 0.0734 - val_loss: 0.1290 - val_dice_coef: 0.0542\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2136 - dice_coef: 0.0749 - val_loss: 0.1283 - val_dice_coef: 0.0556\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2123 - dice_coef: 0.0767 - val_loss: 0.1277 - val_dice_coef: 0.0571\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.2107 - dice_coef: 0.0786 - val_loss: 0.1271 - val_dice_coef: 0.0586\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2099 - dice_coef: 0.0803 - val_loss: 0.1266 - val_dice_coef: 0.0602\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2085 - dice_coef: 0.0822 - val_loss: 0.1261 - val_dice_coef: 0.0617\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.2071 - dice_coef: 0.0841 - val_loss: 0.1256 - val_dice_coef: 0.0633\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2063 - dice_coef: 0.0861 - val_loss: 0.1252 - val_dice_coef: 0.0650\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2053 - dice_coef: 0.0878 - val_loss: 0.1248 - val_dice_coef: 0.0667\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.2044 - dice_coef: 0.0896 - val_loss: 0.1244 - val_dice_coef: 0.0683\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.2033 - dice_coef: 0.0913 - val_loss: 0.1241 - val_dice_coef: 0.0700\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.2025 - dice_coef: 0.0933 - val_loss: 0.1239 - val_dice_coef: 0.0717\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 4s 72ms/step - loss: 0.2018 - dice_coef: 0.0955 - val_loss: 0.1236 - val_dice_coef: 0.0734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mphhZJA6o0vo"
      },
      "source": [
        "### 512 нейронов в свёрточном ядре"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODlkkEKKnRyL",
        "outputId": "177030d8-f6d9-4856-967d-80b947dae0fa"
      },
      "source": [
        "model_b_PSPnet = create_PSPNet(conv_size = 512, input_shape=(xLen, embeddingSize))\n",
        "model_b_PSPnet.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 256, 300)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_24 (Conv1D)              (None, 256, 512)     461312      input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 256, 512)     2048        conv1d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 256, 512)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_25 (Conv1D)              (None, 256, 512)     786944      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 256, 512)     2048        conv1d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 256, 512)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling1D) (None, 128, 512)     0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling1D) (None, 64, 512)      0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_12 (MaxPooling1D) (None, 32, 512)      0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_13 (MaxPooling1D) (None, 16, 512)      0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_14 (MaxPooling1D) (None, 8, 512)       0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_26 (Conv1D)              (None, 128, 512)     786944      max_pooling1d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 64, 512)      786944      max_pooling1d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 32, 512)      786944      max_pooling1d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 16, 512)      786944      max_pooling1d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_30 (Conv1D)              (None, 8, 512)       786944      max_pooling1d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 128, 512)     0           conv1d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 64, 512)      0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 512)      0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 16, 512)      0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 8, 512)       0           conv1d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_10 (Conv1DTran (None, 256, 512)     524800      dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_11 (Conv1DTran (None, 256, 512)     1049088     dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_12 (Conv1DTran (None, 256, 512)     2097664     dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_13 (Conv1DTran (None, 256, 512)     4194816     dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_14 (Conv1DTran (None, 256, 512)     8389120     dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 256, 512)     0           conv1d_transpose_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 256, 512)     0           conv1d_transpose_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 256, 512)     0           conv1d_transpose_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 256, 512)     0           conv1d_transpose_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 256, 512)     0           conv1d_transpose_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 256, 2860)    0           input_4[0][0]                    \n",
            "                                                                 activation_20[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_23[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_31 (Conv1D)              (None, 256, 512)     4393472     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 256, 512)     2048        conv1d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 256, 512)     0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_32 (Conv1D)              (None, 256, 512)     786944      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 256, 512)     2048        conv1d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 256, 512)     0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_33 (Conv1D)              (None, 256, 11)      16907       activation_26[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 26,643,979\n",
            "Trainable params: 26,639,883\n",
            "Non-trainable params: 4,096\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1LHG8Z_nRyR",
        "outputId": "f3d4b008-4cf5-459a-e053-2b348909f980"
      },
      "source": [
        "history = model_b_PSPnet.fit(GENSIMtrainX, GENSIMtrainY, validation_data = (GENSIMtestX, GENSIMtestY), epochs=50, batch_size=64)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "52/52 [==============================] - 13s 197ms/step - loss: 0.3717 - dice_coef: 0.0281 - val_loss: 0.2417 - val_dice_coef: 0.0183\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.3469 - dice_coef: 0.0301 - val_loss: 0.2290 - val_dice_coef: 0.0197\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.3264 - dice_coef: 0.0321 - val_loss: 0.2155 - val_dice_coef: 0.0213\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.3091 - dice_coef: 0.0339 - val_loss: 0.2024 - val_dice_coef: 0.0229\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2942 - dice_coef: 0.0356 - val_loss: 0.1912 - val_dice_coef: 0.0244\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2823 - dice_coef: 0.0373 - val_loss: 0.1816 - val_dice_coef: 0.0257\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2719 - dice_coef: 0.0388 - val_loss: 0.1735 - val_dice_coef: 0.0270\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2633 - dice_coef: 0.0403 - val_loss: 0.1667 - val_dice_coef: 0.0282\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2553 - dice_coef: 0.0420 - val_loss: 0.1608 - val_dice_coef: 0.0294\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2486 - dice_coef: 0.0437 - val_loss: 0.1557 - val_dice_coef: 0.0307\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2430 - dice_coef: 0.0451 - val_loss: 0.1512 - val_dice_coef: 0.0319\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 9s 175ms/step - loss: 0.2375 - dice_coef: 0.0470 - val_loss: 0.1471 - val_dice_coef: 0.0332\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2328 - dice_coef: 0.0487 - val_loss: 0.1435 - val_dice_coef: 0.0346\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2288 - dice_coef: 0.0505 - val_loss: 0.1402 - val_dice_coef: 0.0360\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2250 - dice_coef: 0.0526 - val_loss: 0.1372 - val_dice_coef: 0.0375\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2214 - dice_coef: 0.0545 - val_loss: 0.1345 - val_dice_coef: 0.0390\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2181 - dice_coef: 0.0566 - val_loss: 0.1321 - val_dice_coef: 0.0407\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 9s 177ms/step - loss: 0.2155 - dice_coef: 0.0587 - val_loss: 0.1298 - val_dice_coef: 0.0424\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2127 - dice_coef: 0.0610 - val_loss: 0.1278 - val_dice_coef: 0.0442\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2102 - dice_coef: 0.0636 - val_loss: 0.1259 - val_dice_coef: 0.0461\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 9s 177ms/step - loss: 0.2079 - dice_coef: 0.0659 - val_loss: 0.1242 - val_dice_coef: 0.0481\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2056 - dice_coef: 0.0686 - val_loss: 0.1226 - val_dice_coef: 0.0503\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2038 - dice_coef: 0.0712 - val_loss: 0.1212 - val_dice_coef: 0.0525\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2016 - dice_coef: 0.0741 - val_loss: 0.1199 - val_dice_coef: 0.0548\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.2002 - dice_coef: 0.0768 - val_loss: 0.1187 - val_dice_coef: 0.0572\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1983 - dice_coef: 0.0798 - val_loss: 0.1177 - val_dice_coef: 0.0597\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1967 - dice_coef: 0.0825 - val_loss: 0.1167 - val_dice_coef: 0.0622\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1957 - dice_coef: 0.0856 - val_loss: 0.1158 - val_dice_coef: 0.0649\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 9s 177ms/step - loss: 0.1941 - dice_coef: 0.0888 - val_loss: 0.1149 - val_dice_coef: 0.0677\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 9s 177ms/step - loss: 0.1927 - dice_coef: 0.0920 - val_loss: 0.1142 - val_dice_coef: 0.0705\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1919 - dice_coef: 0.0948 - val_loss: 0.1135 - val_dice_coef: 0.0734\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1904 - dice_coef: 0.0981 - val_loss: 0.1129 - val_dice_coef: 0.0763\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1898 - dice_coef: 0.1012 - val_loss: 0.1123 - val_dice_coef: 0.0794\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1884 - dice_coef: 0.1047 - val_loss: 0.1119 - val_dice_coef: 0.0824\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1874 - dice_coef: 0.1075 - val_loss: 0.1114 - val_dice_coef: 0.0854\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1870 - dice_coef: 0.1107 - val_loss: 0.1110 - val_dice_coef: 0.0885\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1862 - dice_coef: 0.1136 - val_loss: 0.1106 - val_dice_coef: 0.0915\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1855 - dice_coef: 0.1167 - val_loss: 0.1103 - val_dice_coef: 0.0946\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1839 - dice_coef: 0.1201 - val_loss: 0.1100 - val_dice_coef: 0.0976\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1835 - dice_coef: 0.1230 - val_loss: 0.1098 - val_dice_coef: 0.1005\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1828 - dice_coef: 0.1258 - val_loss: 0.1096 - val_dice_coef: 0.1034\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 9s 175ms/step - loss: 0.1824 - dice_coef: 0.1283 - val_loss: 0.1094 - val_dice_coef: 0.1062\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 9s 177ms/step - loss: 0.1821 - dice_coef: 0.1312 - val_loss: 0.1093 - val_dice_coef: 0.1091\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1811 - dice_coef: 0.1341 - val_loss: 0.1092 - val_dice_coef: 0.1118\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1808 - dice_coef: 0.1365 - val_loss: 0.1091 - val_dice_coef: 0.1144\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 9s 177ms/step - loss: 0.1801 - dice_coef: 0.1395 - val_loss: 0.1091 - val_dice_coef: 0.1170\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1798 - dice_coef: 0.1418 - val_loss: 0.1090 - val_dice_coef: 0.1196\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 9s 175ms/step - loss: 0.1795 - dice_coef: 0.1442 - val_loss: 0.1090 - val_dice_coef: 0.1221\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 9s 177ms/step - loss: 0.1789 - dice_coef: 0.1466 - val_loss: 0.1090 - val_dice_coef: 0.1244\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 9s 176ms/step - loss: 0.1786 - dice_coef: 0.1489 - val_loss: 0.1090 - val_dice_coef: 0.1268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6ERF_g_scvR"
      },
      "source": [
        "## **UNET**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9KQAjhVo-Q9"
      },
      "source": [
        "### Стандартная архитектура"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hNBg-fk49qP",
        "outputId": "9b8919ea-4ae9-4c68-a189-961bdf7c55d8"
      },
      "source": [
        "model_b_UNET = create_unet(input_shape=(xLen, embeddingSize))\n",
        "model_b_UNET.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 256, 300)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_34 (Conv1D)              (None, 256, 64)      57664       input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 256, 64)      256         conv1d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 256, 64)      0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_35 (Conv1D)              (None, 256, 64)      12352       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 256, 64)      256         conv1d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 256, 64)      0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_15 (MaxPooling1D) (None, 128, 64)      0           activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_36 (Conv1D)              (None, 128, 128)     24704       max_pooling1d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 128, 128)     512         conv1d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 128, 128)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_37 (Conv1D)              (None, 128, 128)     49280       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 128, 128)     512         conv1d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 128, 128)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_16 (MaxPooling1D) (None, 64, 128)      0           activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_38 (Conv1D)              (None, 64, 256)      98560       max_pooling1d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 64, 256)      1024        conv1d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 64, 256)      0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_39 (Conv1D)              (None, 64, 256)      196864      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 64, 256)      1024        conv1d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 64, 256)      0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_40 (Conv1D)              (None, 64, 256)      196864      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 64, 256)      1024        conv1d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 64, 256)      0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_17 (MaxPooling1D) (None, 32, 256)      0           activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_41 (Conv1D)              (None, 32, 512)      393728      max_pooling1d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 512)      2048        conv1d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 32, 512)      0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_42 (Conv1D)              (None, 32, 512)      786944      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 512)      2048        conv1d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 32, 512)      0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_43 (Conv1D)              (None, 32, 512)      786944      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 512)      2048        conv1d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 32, 512)      0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_15 (Conv1DTran (None, 64, 256)      393472      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 64, 256)      1024        conv1d_transpose_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 64, 256)      0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 64, 512)      0           activation_37[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_44 (Conv1D)              (None, 64, 256)      393472      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 64, 256)      1024        conv1d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 64, 256)      0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_45 (Conv1D)              (None, 64, 256)      196864      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 64, 256)      1024        conv1d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 64, 256)      0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_16 (Conv1DTran (None, 128, 128)     98432       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 128, 128)     512         conv1d_transpose_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 128, 128)     0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 128, 256)     0           activation_40[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_46 (Conv1D)              (None, 128, 128)     98432       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 128, 128)     512         conv1d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 128, 128)     0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_47 (Conv1D)              (None, 128, 128)     49280       activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 128, 128)     512         conv1d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 128, 128)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_transpose_17 (Conv1DTran (None, 256, 64)      24640       activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 256, 64)      256         conv1d_transpose_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 256, 64)      0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 256, 128)     0           activation_43[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_48 (Conv1D)              (None, 256, 64)      24640       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 256, 64)      256         conv1d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 256, 64)      0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_49 (Conv1D)              (None, 256, 64)      12352       activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 256, 64)      256         conv1d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 256, 64)      0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_50 (Conv1D)              (None, 256, 11)      2123        activation_45[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 3,913,739\n",
            "Trainable params: 3,905,675\n",
            "Non-trainable params: 8,064\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrhp50pn4_QI",
        "outputId": "58fdc9e5-6090-4f2b-f205-bbaa21bb8c60"
      },
      "source": [
        "history = model_b_UNET.fit(GENSIMtrainX, GENSIMtrainY, validation_data = (GENSIMtestX, GENSIMtestY), epochs=50, batch_size=64) # Feed the images divided among 2 classes to the model"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "52/52 [==============================] - 8s 63ms/step - loss: 0.2154 - dice_coef: 0.1516 - val_loss: 1.4593 - val_dice_coef: 0.0034\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 3s 48ms/step - loss: 0.2238 - dice_coef: 0.1888 - val_loss: 3.8799 - val_dice_coef: 0.0028\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.2322 - dice_coef: 0.1955 - val_loss: 0.3153 - val_dice_coef: 0.0134\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 3s 48ms/step - loss: 0.2937 - dice_coef: 0.1480 - val_loss: 0.2518 - val_dice_coef: 0.0741\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 3s 48ms/step - loss: 0.3432 - dice_coef: 0.1202 - val_loss: 0.3542 - val_dice_coef: 0.0225\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.3410 - dice_coef: 0.1227 - val_loss: 0.2456 - val_dice_coef: 0.0285\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 3s 48ms/step - loss: 0.3383 - dice_coef: 0.1239 - val_loss: 0.2436 - val_dice_coef: 0.0753\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3382 - dice_coef: 0.1240 - val_loss: 0.2413 - val_dice_coef: 0.1045\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3376 - dice_coef: 0.1237 - val_loss: 0.2395 - val_dice_coef: 0.0386\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 3s 48ms/step - loss: 0.3372 - dice_coef: 0.1196 - val_loss: 0.2443 - val_dice_coef: 0.0899\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 2s 47ms/step - loss: 0.3363 - dice_coef: 0.1188 - val_loss: 0.2536 - val_dice_coef: 0.0852\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 3s 48ms/step - loss: 0.3358 - dice_coef: 0.1163 - val_loss: 0.2489 - val_dice_coef: 0.0893\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.3374 - dice_coef: 0.1121 - val_loss: 0.2428 - val_dice_coef: 0.0815\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.3365 - dice_coef: 0.1024 - val_loss: 0.2574 - val_dice_coef: 0.0538\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.3316 - dice_coef: 0.1039 - val_loss: 0.2399 - val_dice_coef: 0.0826\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 3s 48ms/step - loss: 0.3303 - dice_coef: 0.0994 - val_loss: 0.2424 - val_dice_coef: 0.0748\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.3289 - dice_coef: 0.0945 - val_loss: 0.2488 - val_dice_coef: 0.0580\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3289 - dice_coef: 0.0889 - val_loss: 0.2437 - val_dice_coef: 0.0686\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3292 - dice_coef: 0.0836 - val_loss: 0.2541 - val_dice_coef: 0.0456\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.3290 - dice_coef: 0.0798 - val_loss: 0.2572 - val_dice_coef: 0.0502\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.3309 - dice_coef: 0.0652 - val_loss: 0.2491 - val_dice_coef: 0.0539\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3293 - dice_coef: 0.0637 - val_loss: 0.2420 - val_dice_coef: 0.0480\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3188 - dice_coef: 0.0700 - val_loss: 0.2310 - val_dice_coef: 0.0541\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3166 - dice_coef: 0.0684 - val_loss: 0.2369 - val_dice_coef: 0.0509\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 2s 47ms/step - loss: 0.3165 - dice_coef: 0.0623 - val_loss: 0.2290 - val_dice_coef: 0.0419\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.3152 - dice_coef: 0.0603 - val_loss: 0.2355 - val_dice_coef: 0.0476\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 3s 50ms/step - loss: 0.3143 - dice_coef: 0.0560 - val_loss: 0.2306 - val_dice_coef: 0.0403\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3142 - dice_coef: 0.0514 - val_loss: 0.2444 - val_dice_coef: 0.0342\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3139 - dice_coef: 0.0471 - val_loss: 0.2295 - val_dice_coef: 0.0332\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 3s 48ms/step - loss: 0.3138 - dice_coef: 0.0427 - val_loss: 0.2383 - val_dice_coef: 0.0318\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3134 - dice_coef: 0.0390 - val_loss: 0.2397 - val_dice_coef: 0.0303\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 3s 48ms/step - loss: 0.3131 - dice_coef: 0.0353 - val_loss: 0.2358 - val_dice_coef: 0.0276\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 3s 50ms/step - loss: 0.3129 - dice_coef: 0.0318 - val_loss: 0.2300 - val_dice_coef: 0.0253\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 3s 50ms/step - loss: 0.3126 - dice_coef: 0.0288 - val_loss: 0.2334 - val_dice_coef: 0.0210\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3129 - dice_coef: 0.0258 - val_loss: 0.2330 - val_dice_coef: 0.0210\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3125 - dice_coef: 0.0232 - val_loss: 0.2316 - val_dice_coef: 0.0192\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3123 - dice_coef: 0.0208 - val_loss: 0.2375 - val_dice_coef: 0.0167\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3120 - dice_coef: 0.0186 - val_loss: 0.2345 - val_dice_coef: 0.0146\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3118 - dice_coef: 0.0165 - val_loss: 0.2368 - val_dice_coef: 0.0144\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.3117 - dice_coef: 0.0147 - val_loss: 0.2349 - val_dice_coef: 0.0129\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3111 - dice_coef: 0.0132 - val_loss: 0.2362 - val_dice_coef: 0.0116\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.3114 - dice_coef: 0.0117 - val_loss: 0.2351 - val_dice_coef: 0.0102\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3110 - dice_coef: 0.0105 - val_loss: 0.2324 - val_dice_coef: 0.0099\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3108 - dice_coef: 0.0093 - val_loss: 0.2310 - val_dice_coef: 0.0087\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.3108 - dice_coef: 0.0083 - val_loss: 0.2257 - val_dice_coef: 0.0086\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.3107 - dice_coef: 0.0074 - val_loss: 0.2253 - val_dice_coef: 0.0081\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 3s 48ms/step - loss: 0.3103 - dice_coef: 0.0066 - val_loss: 0.2280 - val_dice_coef: 0.0069\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3102 - dice_coef: 0.0059 - val_loss: 0.2284 - val_dice_coef: 0.0066\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 3s 49ms/step - loss: 0.3100 - dice_coef: 0.0052 - val_loss: 0.2294 - val_dice_coef: 0.0060\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 3s 48ms/step - loss: 0.3100 - dice_coef: 0.0047 - val_loss: 0.2305 - val_dice_coef: 0.0055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFCKfUi1aH5p"
      },
      "source": [
        "# **Проверяем работу сети**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJHDSAktrswn"
      },
      "source": [
        "def recognizeSet(XX, YY, model, tags, length, value):\n",
        "  correct_list = np.array([0] * 11) #Инициализируем массив правильных ответов в нули (сколько раз правильно определили класс)\n",
        "  incorrect_list =  np.array([0] * 11)  #Инициализируем массив неправильных ответов в нули  (сколько раз неправильно определили класс)\n",
        "  XX_array = XX\n",
        "  YY_array = YY\n",
        "  pred = model.predict(XX_array)\n",
        "  pred[pred < value] = 0\n",
        "  pred[pred > value] = 1\n",
        "\n",
        "  for element in range(YY_array.shape[0]): # Проходим по всем примерам в батче\n",
        "    for word in range(YY_array.shape[1]):  # Проходим по каждому слову\n",
        "      for category in range(YY_array.shape[2]): # Проходим по каждой категории в слове\n",
        "        if pred[element][word][category] == YY_array[element][word][category]: # Если предсказанное значение совпадает с истинным:\n",
        "          correct_list[category] += 1 # Отмечаем, что мы правильно предсказали класс объекта\n",
        "        else:  # Если предсказанное значение НЕ совпадает с истенным:\n",
        "          incorrect_list[category] += 1 # Отмечаем, что мы не правильно предсказали класс объекта\n",
        "      \n",
        "  # Итоговая точность для каждого класса = кол. 100% * правильных/(кол. неправильных + кол. правильных)\n",
        "  for i in range(11):\n",
        "   print(\"Сеть распознала категорию  '{}' с точностью в {}%\".format(tags[i], round(100*correct_list[i]/(correct_list[i] + incorrect_list[i]), 2)))\n",
        "  total = round(100*np.mean(correct_list/(correct_list + incorrect_list)),2) \n",
        "  print(\"Средняя точность {}%\".format(total))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBG_7_WLIyhB",
        "outputId": "1f545d43-0c5f-4683-8153-4a95ed7fc0b4"
      },
      "source": [
        "print('Размер xTrain:', GENSIMtestX.shape)\n",
        "print('Размер yTrain:', GENSIMtestY.shape)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер xTrain: (135, 256, 300)\n",
            "Размер yTrain: (135, 256, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPxLnnCHpdjz"
      },
      "source": [
        "tags = ['S0', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10']"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tfPClRnUWnh",
        "outputId": "2eb03c7f-1ef7-464c-f9bc-07b85d9417af"
      },
      "source": [
        "recognizeSet(GENSIMtestX, GENSIMtestY, model_conv1d, tags, xLen, 0.5) # Проверяем conv1d архитектуру"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сеть распознала категорию  'S0' с точностью в 25.7%\n",
            "Сеть распознала категорию  'S1' с точностью в 32.99%\n",
            "Сеть распознала категорию  'S2' с точностью в 7.0%\n",
            "Сеть распознала категорию  'S3' с точностью в 96.73%\n",
            "Сеть распознала категорию  'S4' с точностью в 18.98%\n",
            "Сеть распознала категорию  'S5' с точностью в 38.02%\n",
            "Сеть распознала категорию  'S6' с точностью в 14.87%\n",
            "Сеть распознала категорию  'S7' с точностью в 59.69%\n",
            "Сеть распознала категорию  'S8' с точностью в 2.88%\n",
            "Сеть распознала категорию  'S9' с точностью в 39.61%\n",
            "Сеть распознала категорию  'S10' с точностью в 85.46%\n",
            "Средняя точность 38.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3UWWdrq7BOK",
        "outputId": "7ca5308c-b5e7-4c3d-cc70-d3e736342ded"
      },
      "source": [
        "recognizeSet(GENSIMtestX, GENSIMtestY, model_b_PSPnet, tags, xLen, 0.5) # Проверяем PSPnet архитектуру"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сеть распознала категорию  'S0' с точностью в 94.57%\n",
            "Сеть распознала категорию  'S1' с точностью в 91.79%\n",
            "Сеть распознала категорию  'S2' с точностью в 98.58%\n",
            "Сеть распознала категорию  'S3' с точностью в 98.5%\n",
            "Сеть распознала категорию  'S4' с точностью в 98.56%\n",
            "Сеть распознала категорию  'S5' с точностью в 92.83%\n",
            "Сеть распознала категорию  'S6' с точностью в 95.95%\n",
            "Сеть распознала категорию  'S7' с точностью в 92.29%\n",
            "Сеть распознала категорию  'S8' с точностью в 99.77%\n",
            "Сеть распознала категорию  'S9' с точностью в 99.67%\n",
            "Сеть распознала категорию  'S10' с точностью в 99.55%\n",
            "Средняя точность 96.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLvM8g1BcVJk",
        "outputId": "cc1694e6-a92d-4189-806d-af8a3e9a18f5"
      },
      "source": [
        "recognizeSet(GENSIMtestX, GENSIMtestY, model_b_UNET, tags, xLen, 0.1) # Проверяем UNET архитектуру"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сеть распознала категорию  'S0' с точностью в 99.61%\n",
            "Сеть распознала категорию  'S1' с точностью в 99.2%\n",
            "Сеть распознала категорию  'S2' с точностью в 98.63%\n",
            "Сеть распознала категорию  'S3' с точностью в 99.89%\n",
            "Сеть распознала категорию  'S4' с точностью в 99.97%\n",
            "Сеть распознала категорию  'S5' с точностью в 99.07%\n",
            "Сеть распознала категорию  'S6' с точностью в 98.72%\n",
            "Сеть распознала категорию  'S7' с точностью в 95.87%\n",
            "Сеть распознала категорию  'S8' с точностью в 99.49%\n",
            "Сеть распознала категорию  'S9' с точностью в 99.45%\n",
            "Сеть распознала категорию  'S10' с точностью в 100.0%\n",
            "Средняя точность 99.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heSsuxBNjt1l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}